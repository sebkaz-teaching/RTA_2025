---
title:  WykÅ‚ad 5

format:
  html:
    code-fold: true
jupyter: python3
---

## Algorytmy

Zanim zaprojektujesz rozwiÄ…zanie problemu biznesowego, warto zastanowiÄ‡ siÄ™ nad zÅ‚oÅ¼onoÅ›ciÄ… Twojego problemu.

### Klasyfikacja algorytmÃ³w

**1. Algorytmy przetwarzajÄ…ce duÅ¼e iloÅ›ci danych**  

Przetwarzanie ogromnych zbiorÃ³w danych wymaga odpowiedniego podejÅ›cia do ich organizacji i analizy. W sytuacji, gdy iloÅ›Ä‡ danych przekracza dostÄ™pnÄ… pamiÄ™Ä‡ jednostki obliczeniowej, czÄ™sto stosuje siÄ™ iteracyjne sposoby ich przetwarzania.


ğŸ”¹ PrzykÅ‚ad: System rekomendacji w e-commerce (np. Amazon, Netflix)

-	Analizuje ogromne zbiory danych o uÅ¼ytkownikach, ich historii zakupÃ³w i oglÄ…danych treÅ›ci.
-	Przetwarza dane w sposÃ³b iteracyjny (np. strumieniowe przetwarzanie w Apache Spark).
-	Wykorzystuje algorytmy filtracji kolaboratywnej lub algorytmy grafowe do przewidywania preferencji uÅ¼ytkownika.

ğŸ”¹ Inne zastosowania:

-	Analiza logÃ³w serwerowych w czasie rzeczywistym (np. wykrywanie atakÃ³w DDoS).
-	Monitoring sieci IoT (np. analiza danych z sensorÃ³w w inteligentnym mieÅ›cie).


 **2. Algorytmy dokonujÄ…ce wielu obliczeÅ„**  

WymagajÄ… duÅ¼ej mocy obliczeniowej, ale zazwyczaj nie operujÄ… na wielkich zbiorach danych. PrzykÅ‚adem moÅ¼e byÄ‡ algorytm wyszukujÄ…cy duÅ¼Ä… liczbÄ™ pierwszÄ…. CzÄ™sto wykorzystuje siÄ™ tutaj podziaÅ‚ obliczeÅ„ na rÃ³wnolegÅ‚e procesy w celu optymalizacji wydajnoÅ›ci.

ğŸ”¹ PrzykÅ‚ad: Kryptografia i znalezienie duÅ¼ej liczby pierwszej (np. RSA)

-	Algorytm generuje bardzo duÅ¼e liczby pierwsze, ktÃ³re sÄ… podstawÄ… dla szyfrowania RSA.
-	Proces wymaga intensywnych obliczeÅ„, ale nie operuje na ogromnych zbiorach danych.
-	CzÄ™sto wykorzystywane sÄ… metody rÃ³wnolegÅ‚e, np. algorytm probabilistyczny Millera-Rabina do testowania pierwszoÅ›ci.

ğŸ”¹ Inne zastosowania:

-	Symulacje fizyczne (np. prognozowanie pogody, modele klimatyczne).
-	Algorytmy optymalizacyjne (np. znajdowanie najkrÃ³tszej trasy w problemie komiwojaÅ¼era).


**3. Algorytmy przetwarzajÄ…ce duÅ¼e iloÅ›ci danych i dokonujÄ…ce wielu obliczeÅ„**  

ÅÄ…czÄ… wymagania obu poprzednich typÃ³w, potrzebujÄ…c zarÃ³wno duÅ¼ych zasobÃ³w obliczeniowych, jak i obsÅ‚ugi duÅ¼ych zbiorÃ³w danych. PrzykÅ‚adem moÅ¼e byÄ‡ analiza sentymentu w transmisjach wideo na Å¼ywo.

ğŸ”¹ PrzykÅ‚ad: Analiza sentymentu w transmisjach wideo na Å¼ywo (np. YouTube, Twitch)

- Algorytm analizuje zarÃ³wno tekst (czat), jak i obraz/wideo w czasie rzeczywistym.
- Wymaga zarÃ³wno duÅ¼ych zasobÃ³w obliczeniowych (przetwarzanie NLP i CV), jak i obsÅ‚ugi duÅ¼ej iloÅ›ci danych.
- MoÅ¼e wykorzystywaÄ‡ modele Transformer (np. BERT) do analizy tekstu oraz CNN/RNN do analizy obrazu i dÅºwiÄ™ku.

ğŸ”¹ Inne zastosowania:

- Autonomiczne pojazdy (analiza obrazu i decyzje w czasie rzeczywistym).
- Wyszukiwanie anomalii w ogromnych zbiorach danych finansowych (np. wykrywanie oszustw bankowych).


### Wymiar danych

Aby okreÅ›liÄ‡ wymiar danych problemu, nie wystarczy podaÄ‡ jedynie iloÅ›ci miejsca zajmowanego przez dane. Istotne sÄ… trzy gÅ‚Ã³wne aspekty:

1. **Rozmiar wejÅ›cia** â€“ oczekiwany rozmiar danych do przetwarzania.
2. **SzybkoÅ›Ä‡ narastania** â€“ tempo generowania nowych danych podczas dziaÅ‚ania algorytmu.
3. **RÃ³Å¼norodnoÅ›Ä‡ struktury** â€“ typy danych, jakie algorytm musi obsÅ‚uÅ¼yÄ‡.

### Wymiar obliczeniowy

Dotyczy zasobÃ³w procesowania i mocy obliczeniowej. Na przykÅ‚ad algorytmy uczenia gÅ‚Ä™bokiego (DL) wymagajÄ… duÅ¼ej mocy obliczeniowej, dlatego warto zapewniÄ‡ zrÃ³wnoleglonÄ… architekturÄ™, wykorzystujÄ…cÄ… GPU lub TPU, co znaczÄ…co przyspiesza obliczenia.

## WyjaÅ›nialnoÅ›Ä‡ algorytmÃ³w

W wielu przypadkach modelowanie jest wykorzystywane w sytuacjach krytycznych, np. w oprogramowaniu do podawania lekÃ³w. W takich sytuacjach kluczowe staje siÄ™ wyjaÅ›nienie przyczyny kaÅ¼dego wyniku dziaÅ‚ania algorytmu. Jest to konieczne, aby zapewniÄ‡, Å¼e decyzje podejmowane na jego podstawie sÄ… wolne od bÅ‚Ä™dÃ³w i uprzedzeÅ„.

ZdolnoÅ›Ä‡ algorytmu do wskazania mechanizmÃ³w generujÄ…cych wyniki nazywamy **moÅ¼liwoÅ›ciÄ… wyjaÅ›nienia**. Analiza etyczna stanowi standardowy element procesu walidacji algorytmu.

Uzyskanie wysokiej wyjaÅ›nialnoÅ›ci jest szczegÃ³lnie trudne w przypadku algorytmÃ³w uczenia maszynowego (ML) i gÅ‚Ä™bokiego uczenia (DL). Na przykÅ‚ad banki korzystajÄ…ce z algorytmÃ³w do podejmowania decyzji kredytowych muszÄ… zapewniÄ‡ transparentnoÅ›Ä‡ i wskazaÄ‡ powody wydanej decyzji.

JednÄ… z metod poprawy wyjaÅ›nialnoÅ›ci algorytmÃ³w jest **LIME** (*Local Interpretable Model-Agnostic Explanations*), opublikowana w 2016 roku. Metoda ta polega na wprowadzaniu niewielkich zmian w danych wejÅ›ciowych i analizowaniu ich wpÅ‚ywu na wynik, co pozwala okreÅ›liÄ‡ lokalne zasady podejmowania decyzji przez model.

```{python}
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from lime.lime_tabular import LimeTabularExplainer

# Wczytanie danych Iris
from sklearn.datasets import load_iris
iris = load_iris()
X = iris.data
y = iris.target

# PodziaÅ‚ na zbiÃ³r treningowy i testowy
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Trenowanie modelu
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Tworzenie obiektu LIME do interpretacji modelu
explainer = LimeTabularExplainer(X_train, feature_names=iris.feature_names, class_names=iris.target_names, discretize_continuous=True)

# Interpretacja losowego przykÅ‚adu ze zbioru testowego
i = np.random.randint(0, len(X_test))  # WybÃ³r losowego przykÅ‚adu
exp = explainer.explain_instance(X_test[i], model.predict_proba)

# WyÅ›wietlenie interpretacji
exp.show_in_notebook()

```

Jak dziaÅ‚a ten kod?
1.	Åadowanie danych i trenowanie modelu

- UÅ¼ywamy zbioru Iris, ktÃ³ry zawiera 150 przykÅ‚adÃ³w kwiatÃ³w z trzema gatunkami:
- Setosa
- Versicolor
- Virginica
- Model RandomForestClassifier trenuje siÄ™ na tych danych.

2.	Tworzenie interpretowalnego modelu za pomocÄ… LIME

- LIME generuje lokalne wyjaÅ›nienia, czyli interpretuje model dla pojedynczych predykcji.
- Wybieramy losowy przykÅ‚ad z danych testowych.

3.	Eksploracja wyniku dla jednego przykÅ‚adu

- LIME modyfikuje lekko wartoÅ›ci wejÅ›ciowe i obserwuje, jak zmienia siÄ™ wynik predykcji.
- Tworzy â€lokalnyâ€ model liniowy, ktÃ³ry pokazuje, ktÃ³re cechy miaÅ‚y najwiÄ™kszy wpÅ‚yw na decyzjÄ™.

ZaÅ‚Ã³Å¼my, Å¼e nasz model wybraÅ‚ przykÅ‚adowÄ… roÅ›linÄ™ i sklasyfikowaÅ‚ jÄ… jako Virginica. 

Oto interpretacja wynikÃ³w:

1.	NajwaÅ¼niejsze cechy wpÅ‚ywajÄ…ce na decyzjÄ™ modelu:

- DÅ‚ugoÅ›Ä‡ pÅ‚atka (petal length): najwiÄ™kszy wpÅ‚yw na predykcjÄ™ (np. im wiÄ™ksza, tym wiÄ™ksze prawdopodobieÅ„stwo, Å¼e to Virginica).
- SzerokoÅ›Ä‡ pÅ‚atka (petal width): rÃ³wnieÅ¼ istotny czynnik (np. powyÅ¼ej pewnej wartoÅ›ci sugeruje Virginica).
- DÅ‚ugoÅ›Ä‡ kielicha (sepal length): mniejszy wpÅ‚yw, ale nadal istotny.
- SzerokoÅ›Ä‡ kielicha (sepal width): zwykle najmniej istotna cecha.

2.	Wizualizacja wynikÃ³w

- LIME generuje wykres sÅ‚upkowy, ktÃ³ry pokazuje wpÅ‚yw kaÅ¼dej cechy na klasyfikacjÄ™.
- Na wykresie widaÄ‡, ktÃ³re cechy zwiÄ™kszaÅ‚y, a ktÃ³re zmniejszaÅ‚y prawdopodobieÅ„stwo przypisania do danej klasy.

3.	Co oznacza wynik?

- JeÅ›li model przewidziaÅ‚ klasÄ™ Virginica z wysokim prawdopodobieÅ„stwem, oznacza to, Å¼e kluczowe cechy (np. dÅ‚ugi pÅ‚atek) mocno wskazujÄ… na ten gatunek.
- JeÅ›li cechy miaÅ‚y zrÃ³Å¼nicowany wpÅ‚yw, oznacza to, Å¼e model miaÅ‚ pewne trudnoÅ›ci w klasyfikacji (np. szerokoÅ›Ä‡ pÅ‚atka nie byÅ‚a jednoznaczna).


## Detekcja anomalii 

### WartoÅ›Ä‡ odstajÄ…ca (Outlier)

**WartoÅ›Ä‡ odstajÄ…ca** (ang. *outlier*) to obserwacja (wiersz w tabeli danych), ktÃ³ra jest znacznie oddalona od pozostaÅ‚ych elementÃ³w prÃ³bki. Oznacza to, Å¼e zaleÅ¼noÅ›Ä‡ miÄ™dzy zmiennymi niezaleÅ¼nymi i zaleÅ¼nymi dla tej obserwacji moÅ¼e rÃ³Å¼niÄ‡ siÄ™ od pozostaÅ‚ych przypadkÃ³w.

Dla pojedynczych zmiennych wartoÅ›ci odstajÄ…ce moÅ¼na okreÅ›liÄ‡, korzystajÄ…c z wykresu pudeÅ‚kowego (*box plot*). Wykres ten bazuje na kwartylach:

- **Pierwszy kwartyl** $Q_1$ i **trzeci kwartyl** $Q_3$ wyznaczajÄ… boki pudeÅ‚ka,
- **Drugi kwartyl** $Q_2$ (mediana) jest zaznaczony wewnÄ…trz pudeÅ‚ka,

WartoÅ›ci odstajÄ…ce speÅ‚niajÄ… zaleÅ¼noÅ›Ä‡:
  
$$
 x_{out} < Q_1 - 1.5 \times IQR \quad \text{lub} \quad x_{out} > Q_3 + 1.5 \times IQR
$$

Gdzie:
$$
IQR = Q_3 - Q_1
$$


PrzykÅ‚adem wartoÅ›ci odstajÄ…cej moÅ¼e byÄ‡ bolid FormuÅ‚y 1 â€“ pod wzglÄ™dem prÄ™dkoÅ›ci jest on anomaliÄ… wÅ›rÃ³d zwykÅ‚ych samochodÃ³w.

### Wykorzystanie detekcji anomalii

Wykrywanie wartoÅ›ci odstajÄ…cych ma szerokie zastosowanie, np.:

- **Finanse** â€“ wykrywanie transakcji fraudowych w analizie danych bankowych,
- **CyberbezpieczeÅ„stwo** â€“ identyfikacja intruzÃ³w w sieci na podstawie zachowaÅ„ uÅ¼ytkownikÃ³w,
- **Medycyna** â€“ monitorowanie parametrÃ³w zdrowotnych i wykrywanie nieprawidÅ‚owoÅ›ci,
- **PrzemysÅ‚** â€“ wykrywanie wadliwych komponentÃ³w poprzez analizÄ™ obrazu.

### Metody wykrywania anomalii

#### 1. Metody nadzorowane (supervised learning)
Stosowane, gdy mamy oznaczone dane (np. przypadki oszustw w transakcjach).

- Sieci neuronowe,
- Algorytm K-najbliÅ¼szych sÄ…siadÃ³w (KNN),
- Sieci Bayesowskie.

#### 2. Metody nienadzorowane (unsupervised learning)
ZakÅ‚adajÄ…, Å¼e wiÄ™kszoÅ›Ä‡ danych jest poprawna, a anomalie to niewielki odsetek przypadkÃ³w.

- Klasteryzacja metodÄ… K-Å›rednich (*K-Means*),
- Autoenkodery w sieciach neuronowych,
- Testy statystyczne.


### Metoda klasyczna â€“ detekcja na podstawie prawdopodobieÅ„stwa

Aby okreÅ›liÄ‡, czy dana obserwacja jest anomaliÄ…, moÅ¼na uÅ¼yÄ‡ prawdopodobieÅ„stwa $p(x)$:

- JeÅ›li $p(x) < \epsilon$, uznajemy wartoÅ›Ä‡ za odstajÄ…cÄ….
- W praktyce zakÅ‚adamy, Å¼e dane majÄ… **rozkÅ‚ad normalny** $N(\mu, \sigma)$.
- Szacujemy parametry $\mu$ (Å›rednia) i $\sigma^2$ (wariancja) na podstawie prÃ³bki.
- NastÄ™pnie dla kaÅ¼dej wartoÅ›ci obliczamy prawdopodobieÅ„stwo jej wystÄ…pienia i porÃ³wnujemy z $\epsilon$.

**PrzykÅ‚ad: Analiza wynagrodzeÅ„ w firmie**

Wykrywamy, czy w danej firmie sÄ… osoby o wynagrodzeniach znacznie odbiegajÄ…cych od Å›redniej.

```{python}
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# PrzykÅ‚adowe wynagrodzenia w firmie (w tysiÄ…cach)
salaries = [40, 42, 45, 47, 50, 55, 60, 70, 90, 150]  # 150 to outlier

# Obliczenie kwartylÃ³w
Q1 = np.percentile(salaries, 25)
Q3 = np.percentile(salaries, 75)
IQR = Q3 - Q1

# Definicja wartoÅ›ci odstajÄ…cych
outlier_threshold_low = Q1 - 1.5 * IQR
outlier_threshold_high = Q3 + 1.5 * IQR

# Znalezienie outlierÃ³w
outliers = [x for x in salaries if x < outlier_threshold_low or x > outlier_threshold_high]

print(f"Outliers: {outliers}")

# Wizualizacja
sns.boxplot(salaries)
plt.title("Wykres pudeÅ‚kowy wynagrodzeÅ„")
plt.show()
```

Wynik: Na wykresie pudeÅ‚kowym widaÄ‡, Å¼e 150 tys. to anomalia.

### Isolation Forest â€“ detekcja anomalii za pomocÄ… lasu izolacyjnego

**Isolation Forest** to algorytm bazujÄ…cy na drzewach decyzyjnych, zaproponowany przez Fei Tony Liu, Kai Ming Ting oraz Zhi-Hua Zhou w 2008 roku.
 Identyfikuje anomalie poprzez izolowanie wartoÅ›ci odstajÄ…cych w procesie podziaÅ‚u danych:

- Wybiera losowo cechÄ™ oraz wartoÅ›Ä‡ podziaÅ‚u,
- WartoÅ›ci odstajÄ…ce szybciej zostajÄ… odizolowane (sÄ… bliÅ¼ej korzenia drzewa),
- Wynik jest agregowany na podstawie wielu drzew.

Jego zalety to **niskie wymagania obliczeniowe** i skutecznoÅ›Ä‡ w analizie wielowymiarowych danych.

 [Metody detekcji anomalii sklearn](https://scikit-learn.org/0.20/auto_examples/plot_anomaly_comparison.html)

**PrzykÅ‚ad: Wykrywanie oszustw bankowych**

Bank analizuje transakcje kartÄ… kredytowÄ… i wykrywa te, ktÃ³re mogÄ… byÄ‡ nieautoryzowane.

```{python}
import numpy as np
import pandas as pd
from sklearn.ensemble import IsolationForest

# PrzykÅ‚adowe dane transakcji (kwota, liczba transakcji w tygodniu)
data = np.array([
    [100, 5], [120, 6], [130, 5], [110, 4], [5000, 1],  # Outlier (duÅ¼a kwota, rzadkoÅ›Ä‡)
    [125, 5], [115, 5], [140, 7], [135, 6], [145, 5]
])

# Model Isolation Forest
clf = IsolationForest(contamination=0.1)  # 10% transakcji uznajemy za anomalie
clf.fit(data)

# Predykcja (1 = normalna transakcja, -1 = oszustwo)
predictions = clf.predict(data)
df = pd.DataFrame(data, columns=["Kwota", "Liczba transakcji"])
df["Anomalia"] = predictions

print(df)
```

Wynik: Transakcja 5000 zÅ‚ zostanie wykryta jako anomalia.
