{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title:  Wykład 2\n",
        "format:\n",
        "  html:\n",
        "    code-fold: true\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " \n",
        "⏳ Czas trwania: 1,5h\n",
        "*🎯 Cel wykładu* \n",
        "\n",
        "zrozumienie, jak dane ewoluowały w różnych branżach i jakie narzędzia są dziś wykorzystywane do ich analizy.\n",
        "\n",
        "---\n",
        "\n",
        "Na tym wykładzie przedstawimy ewolucję analizy danych, pokazując, jak zmieniały się technologie i podejścia do przetwarzania danych na przestrzeni lat. \n",
        "Rozpoczniemy od klasycznych struktur tabelarycznych, przez bardziej zaawansowane modele grafowe i tekstowe, aż po nowoczesne podejście do strumieniowego przetwarzania danych. \n",
        "\n",
        "\n",
        "# Ewolucja danych \n",
        "\n",
        "##  Dane tabelaryczne (tabele SQL)\n",
        "Początkowo dane były przechowywane w postaci tabel, gdzie każda tabela zawierała zorganizowane informacje w kolumnach i wierszach (np. bazy danych SQL).  \n",
        "Modele takie doskonale nadawały się do danych **ustrukturyzowanych**.  \n",
        "\n",
        "### 📌 Cechy:\n",
        "✅ Dane podzielone na kolumny o stałej strukturze.  \n",
        "✅ Możliwość stosowania operacji CRUD (Create, Read, Update, Delete).  \n",
        "✅ Ścisłe reguły spójności i normalizacji.  \n",
        "\n",
        "### 📌 Przykłady:  \n",
        "➡️ Systemy bankowe, e-commerce, ERP, systemy CRM.  \n",
        "\n",
        "### 🖥️ Przykładowy kod w Pythonie (SQLite):  \n",
        "```python\n",
        "import sqlite3\n",
        "conn = sqlite3.connect(':memory:')\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT, age INTEGER)\")\n",
        "cursor.execute(\"INSERT INTO users (name, age) VALUES ('Alice', 30)\")\n",
        "cursor.execute(\"SELECT * FROM users\")\n",
        "print(cursor.fetchall())\n",
        "conn.close()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Dane grafowe  \n",
        "Wraz z rozwojem potrzeb biznesowych pojawiły się **dane grafowe**, w których relacje między obiektami są reprezentowane jako **wierzchołki i krawędzie**.  \n",
        "\n",
        "### 📌 Cechy:  \n",
        "✅ Dane opisujące relacje i powiązania.  \n",
        "✅ Elastyczna struktura (grafy zamiast tabel).  \n",
        "✅ Możliwość analizy połączeń (np. algorytmy PageRank, centralność).  \n",
        "\n",
        "### 📌 Przykłady:  \n",
        "➡️ Sieci społecznościowe (Facebook, LinkedIn), wyszukiwarki (Google), systemy rekomendacji (Netflix, Amazon).  \n",
        "\n",
        "### 🖥️ Przykładowy kod w Pythonie (Graf Karate - NetworkX): \n"
      ],
      "id": "1afd0631"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import networkx as nx\n",
        "G = nx.karate_club_graph()\n",
        "nx.draw(G, with_labels=True)"
      ],
      "id": "50fbdc1e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Dane półstrukturyzowane (JSON, XML, YAML)  \n",
        "Dane te nie są w pełni ustrukturyzowane jak w bazach SQL, ale mają pewien schemat.  \n",
        "\n",
        "### 📌 Cechy:  \n",
        "✅ Hierarchiczna struktura (np. klucz-wartość, obiekty zagnieżdżone).  \n",
        "✅ Brak ścisłego schematu (możliwość dodawania nowych pól).  \n",
        "✅ Popularność w systemach NoSQL i API.  \n",
        "\n",
        "### 📌 Przykłady:  \n",
        "➡️ Dokumenty w MongoDB, pliki konfiguracyjne, REST API, pliki logów.  \n",
        "\n",
        "### 🖥️ Przykładowy kod w Pythonie (JSON):  \n"
      ],
      "id": "572224be"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "data = {'name': 'Alice', 'age': 30, 'city': 'New York'}\n",
        "json_str = json.dumps(data)\n",
        "print(json.loads(json_str))"
      ],
      "id": "aac2cacb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Dane tekstowe (NLP) \n",
        "Tekst stał się kluczowym źródłem informacji, szczególnie w analizie opinii, chatbotach czy wyszukiwarkach.  \n",
        "\n",
        "### 📌 Cechy:\n",
        "✅ Nieustrukturyzowane dane wymagające przekształcenia.  \n",
        "✅ Stosowanie **embeddingów** (np. Word2Vec, BERT, GPT).  \n",
        "✅ Duże zastosowanie w analizie sentymentu i chatbotach.  \n",
        "\n",
        "### 📌 Przykłady:  \n",
        "➡️ Media społecznościowe, e-maile, chatboty, tłumaczenie maszynowe.  \n",
        "\n",
        "### 🖥️ Przykładowy kod w Pythonie:  \n"
      ],
      "id": "9cd8ea10"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import ollama\n",
        "\n",
        "# Przykładowe zdanie\n",
        "sentence = \"Sztuczna inteligencja zmienia świat.\"\n",
        "response = ollama.embeddings(model='llama3.2', prompt=sentence)\n",
        "embedding = response['embedding']\n",
        "print(embedding[:4])"
      ],
      "id": "37c92b4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Dane multimedialne (obrazy, dźwięk, wideo)\n",
        "Nowoczesne systemy analizy danych wykorzystują również obrazy i dźwięk.  \n",
        "\n",
        "### 📌 Cechy:  \n",
        "✅ Wymagają dużej mocy obliczeniowej (sztuczna inteligencja, deep learning).  \n",
        "✅ Przetwarzane przez modele CNN (obrazy) i RNN/Transformers (dźwięk).  \n",
        "\n",
        "### 📌 Przykłady:  \n",
        "➡️ Rozpoznawanie twarzy, analiza mowy, biometria, analiza treści wideo.  \n",
        "\n",
        "### 🖥️ Przykładowy kod w Pythonie (Obraz - OpenCV):  \n",
        "```python\n",
        "import cv2\n",
        "image = cv2.imread('cloud.jpeg')\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Dane strumieniowe\n",
        "Obecnie najbardziej dynamicznie rozwija się analiza **danych strumieniowych**, gdzie dane są analizowane na bieżąco, w miarę ich napływania.  \n",
        "\n",
        "### 📌 Cechy:  \n",
        "✅ Przetwarzanie w czasie rzeczywistym.  \n",
        "✅ Wykorzystanie technologii takich jak Apache Kafka, Flink, Spark Streaming.  \n",
        "\n",
        "### 📌 Przykłady:  \n",
        "➡️ Transakcje bankowe (detekcja oszustw), analiza social media, IoT.  \n",
        "\n",
        "### 🖥️ Przykładowy kod w Pythonie (Strumieniowe transakcje bankowe):  \n"
      ],
      "id": "7645d0eb"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "transactions = [{'id': 1, 'amount': 100}, {'id': 2, 'amount': 200}]\n",
        "for transaction in transactions:\n",
        "    print(f\"Processing transaction: {transaction}\")\n",
        "    time.sleep(1)"
      ],
      "id": "5a463f48",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "\n",
        "## Dane sensoryczne i IoT \n",
        "Dane z czujników i urządzeń IoT są kolejnym krokiem w ewolucji.  \n",
        "\n",
        "### 📌 Cechy:  \n",
        "✅ Często pochodzą z miliardów urządzeń (big data).  \n",
        "✅ Wymagają analizy brzegowej (_edge computing_).  \n",
        "\n",
        "### 📌 Przykłady:  \n",
        "➡️ Smart home, wearables, samochody autonomiczne, systemy przemysłowe.  \n",
        "\n",
        "### 🖥️ Przykładowy kod w Pythonie (Sensor - temperatura):  \n"
      ],
      "id": "16066c05"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import random\n",
        "def get_temperature():\n",
        "    return round(random.uniform(20.0, 25.0), 2)\n",
        "print(f\"Current temperature: {get_temperature()}°C\")"
      ],
      "id": "39acaf9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rzeczywisty proces generowania danych\n",
        "\n",
        "Dane generowane są w postaci nieograniczonej - pojawiają się na skutek ciągłych działań systemów.\n",
        "W swoim telefonie wygenerowałeś dziś (a nawet na tych zajęciach!) wiele danych.\n",
        "Czy na następnych zajęciach lub też jutro nie będziesz ich generował?\n",
        "\n",
        "> Dane zawsze generowane są jako forma strumienia danych.\n",
        "\n",
        "📌 Systemy obsługujące strumienie danych:\n",
        "\n",
        "- Hurtownie danych\n",
        "- Systemy monitorujące działania urządzeń (IoT)\n",
        "- Systemy transakcyjne\n",
        "- Systemy analityczne stron www\n",
        "- Reklamy on-line\n",
        "- Media społecznościowe\n",
        "- Systemy logowania\n",
        "\n",
        "> Firma to organizacja, która generuje i odpowiada na ciągły strumień danych.\n",
        "\n",
        "W przetwarzaniu wsadowym źródłem (ale i wynikiem przetwarzania) danych jest **plik**.\n",
        "\n",
        "Jest on zapisywany raz i można się do niego odwołać (może na nim działać wiele procesów - zadań).\n",
        "\n",
        "Nazwa pliku to element identyfikujący zbiór rekordów.\n",
        "\n",
        "W przypadku strumienia zdarzenie jest generowane tylko raz przez tzw. producenta (zwanego też nadawcą lub dostawcą).\n",
        "Powstałe zdarzenie przetwarzane może być przez wielu tzw. konsumentów (odbiorców).\n",
        "Zdarzenia strumieniowe grupowane są w tzw. tematy (ang. topics).\n",
        "\n",
        "\n",
        "# Duże dane \n",
        "\n",
        "Kiedy podjąć decyzję biznesową ?\n",
        "\n",
        "<img alt=\"Batch Processing\" src=\"img/batch0.png\" class=\"center\" />\n",
        "\n",
        "## Hadoop Map-Reduce – Skalowanie obliczeń na Big Data\n",
        "\n",
        "Kiedy mówimy o skalowalnym przetwarzaniu danych, pierwszym skojarzeniem może być Google.  \n",
        "Ale co tak naprawdę sprawia, że możemy wyszukiwać informacje w ułamku sekundy, przetwarzając petabajty danych?  \n",
        "\n",
        "👉 Czy wiesz, że nazwa \"Google\" pochodzi od słowa \"Googol\", czyli liczby równej 10¹⁰⁰?  \n",
        "To więcej niż liczba atomów w znanym Wszechświecie! 🌌  \n",
        "\n",
        "### 🔥 Wyzwanie: Czy uda Ci się zapisać liczbę Googol do końca zajęć?  \n",
        "\n",
        "---  \n",
        "\n",
        "## 🔍 Dlaczego SQL i klasyczne algorytmy nie wystarczają? \n",
        "\n",
        "Tradycyjne **bazy danych SQL** czy **jednowątkowe algorytmy** zawodzą, gdy skala danych przekracza pojedynczy komputer.  \n",
        "W tym miejscu pojawia się **MapReduce** – rewolucyjny model obliczeniowy stworzony przez Google.  \n",
        "\n",
        "### 🛠️ Rozwiązania Google dla Big Data:  \n",
        "✅ **Google File System (GFS)** – rozproszony system plików.  \n",
        "✅ **Bigtable** – system do przechowywania ogromnych ilości ustrukturyzowanych danych.  \n",
        "✅ **MapReduce** – algorytm podziału pracy na wiele maszyn.  \n",
        "\n",
        "## Graficzne przedstawienie MapReduce\n",
        "\n",
        "###  Mapowanie rozdziela zadania (Map)\n",
        "Każde wejście dzielone jest na mniejsze części i przetwarzane równolegle.  \n",
        "\n",
        "🌍 Wyobraź sobie, że masz **książkę telefoniczną** i chcesz znaleźć wszystkie osoby o nazwisku \"Nowak\".  \n",
        "➡️ **Podziel książkę na fragmenty i daj każdemu do przeanalizowania jeden fragment.**  \n",
        "\n",
        "### Redukcja zbiera wyniki (Reduce)  \n",
        "Wszystkie częściowe wyniki są łączone w jedną, końcową odpowiedź.  \n",
        "\n",
        "🔄 Wszyscy uczniowie zgłaszają swoje wyniki, a jeden student zbiera i podsumowuje odpowiedź.  \n",
        "\n",
        "<img alt=\"MapReduce w działaniu – rozdzielanie i agregowanie danych\" src=\"img/mapreduce_flow.png\" class=\"center\" />\n",
        "\n",
        "---  \n",
        "\n",
        "## 💡 Klasyczny przykład: Liczenie słów w tekście  \n",
        "Załóżmy, że mamy miliony książek i chcemy policzyć, ile razy występuje każde słowo.  \n",
        "\n",
        "### 🖥️ Kod MapReduce w Pythonie (z użyciem multiprocessing)  \n",
        "\n",
        "```python\n",
        "from multiprocessing import Pool\n",
        "from collections import Counter\n",
        "\n",
        "# Funkcja Map (podział tekstu na słowa)\n",
        "def map_function(text):\n",
        "    words = text.split()\n",
        "    return Counter(words)\n",
        "\n",
        "# Funkcja Reduce (sumowanie wyników)\n",
        "def reduce_function(counters):\n",
        "    total_count = Counter()\n",
        "    for counter in counters:\n",
        "        total_count.update(counter)\n",
        "    return total_count\n",
        "\n",
        "texts = [\n",
        "        \"big data is amazing\",\n",
        "        \"data science and big data\",\n",
        "        \"big data is everywhere\"\n",
        "    ]\n",
        "if __name__ == '__main__':    \n",
        "    with Pool() as pool:\n",
        "        mapped_results = pool.map(map_function, texts)\n",
        "    \n",
        "    final_result = reduce_function(mapped_results)\n",
        "    print(final_result)\n",
        "\n",
        "# Counter({'data': 4, 'big': 3, 'is': 2, 'amazing': 1, 'science': 1, 'and': 1, 'everywhere': 1})\n",
        "```\n",
        "\n",
        "### 🔹 Co tu się dzieje?  \n",
        "✅ Każdy fragment tekstu jest przetwarzany niezależnie (**map**).  \n",
        "✅ Wyniki są zbierane i sumowane (**reduce**).  \n",
        "✅ **Efekt:** Możemy przetwarzać **terabajty tekstu równolegle**!  \n",
        "\n",
        "<img alt=\"Batch Processing\" src=\"../img/batch3.png\" class=\"center\" />\n",
        "\n",
        "---  \n",
        "\n",
        "\n",
        "## 🎨 Wizualizacja – Porównanie klasycznego podejścia i MapReduce  \n",
        "\n",
        "📊 **Stare podejście** – Jeden komputer wykonuje wszystko sekwencyjnie.  \n",
        "📊 **Nowe podejście (MapReduce)** – Każda maszyna liczy fragment i wyniki są agregowane.  \n",
        "\n",
        "\n",
        "<img alt=\"MapReduce Processing\" src=\"../img/mapreduce_vs_classic.png\" class=\"center\" />\n",
        "\n",
        "---  \n",
        "\n",
        "## 🚀 Wyzwanie dla Ciebie! \n",
        "\n",
        "🔹 **Znajdź i uruchom swój własny algorytm MapReduce w dowolnym języku!**  \n",
        "🔹 **Czy potrafisz zaimplementować własny MapReduce do innego zadania?** (np. analiza logów, zliczanie kliknięć na stronie)  \n",
        "\n",
        "\n",
        "## Big Data\n",
        "\n",
        "Systemy Big data mogą być częścią (źródłem) dla hurtowni danych (np. Data Lake, Enterprise Data Hub)\n",
        "\n",
        "Ale Hurtownie danych nie są systemami Big Data!\n",
        "\n",
        "1. Hurtownie danych\n",
        "- przetrzymywanie danych wysoko strukturyzowanych\n",
        "- skupione na analizach i procesie raportowania\n",
        "- 100\\% accuracy\n",
        "\n",
        "2. Big Data\n",
        "- dane o dowolnej strukturze\n",
        "- służy do różnorodnych celów opartych na danych (analityka, data science ...)\n",
        "- poniżej 100\\% accuracy\n",
        "\n",
        "> _,,Big Data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so every one claims they are doing it.''_ — Dan Ariely, Professor of Psychology and Behavioral Economics, Duke University\n",
        "\n",
        "### one, two, ... four V\n",
        "\n",
        "1. **Volume**  (Objętość) - rozmiar danych produkowanych na całym świecie przyrasta w tempie wykładniczym.\n",
        "2. **Velocity** (Szybkość) - tempo produkowania danych, szybkości ich przesyłania i przetwarzania.\n",
        "3. **Variety** (Zróżnicowanie) - tradycyjne dane kojarzą się nam z postacią alfanumeryczną złożoną z liter i cyfr. Obecnie mamy do dyspozycji obrazy, dźwięki, pliki wideo, strumienie danych z IoT\n",
        "4. **Veracity** (Wiarygodność) - Czy dane są kompletne i poprawne? Czy obiektywnie odzwierciedlają rzeczywistość? Czy są podstawą do podejmowania decyzji?\n",
        "5. **Value** - The value that the data actually holds. In the end, it's all about cost and benefits.\n",
        "\n",
        "> _Celem obliczeń nie są liczby, lecz ich zrozumienie_ R.W. Hamming 1962. \n",
        "\n",
        "\n",
        "## Modele przetwarzania danych\n",
        "\n",
        "Dane w biznesie przetwarzane są praktycznie od zawsze. \n",
        "W ciągu ostatnich dziesięcioleci ilość przetwarzanych danych systematycznie rośnie co wpływa na proces przygotowania i przetwarzania danych.\n",
        "\n",
        "### Trochę historii\n",
        "\n",
        "- Lata 60-te : Kolekcje danych, bazy danych\n",
        "- Lata 70-te : Relacyjne modele danych i ich implementacja w systemach OLTP\n",
        "- 1975 : Pierwsze komputery osobiste \n",
        "- Lata 80-te : Zaawansowane modele danych, extended-relational, objective oriented, aplikacyjno-zorientowane itp.\n",
        "- 1983 : Początek internetu\n",
        "- Lata 90-te : Data mining, hurtownie danych, systemy OLAP\n",
        "- Później : NoSQL, Hadoop, SPARK, data lake\n",
        "- 2002 : AWS , 2005: Hadoop, Cloud computing \n",
        "\n",
        "\n",
        "Większość danych przechowywana jest w bazach lub hurtowniach danych.\n",
        "Standardowo dostęp do danych sprowadza się najczęściej do realizacji zapytań poprzez aplikację.\n",
        "\n",
        "Sposób wykorzystania i realizacji procesu dostępu do bazy danych nazywamy **modelem przetwarzania**.\n",
        "Najczęściej używane są dwie implementacje:\n",
        "\n",
        "### Model Tradycyjny\n",
        "\n",
        "**Model tradycyjny** - przetwarzanie transakcyjne w trybie on-line, OLTP (on-line transaction processing).\n",
        "Świetnie sprawdza się w przypadku obsługi bieżącej np. obsługa klienta, rejestr zamówień, obsługa sprzedaży itp.\n",
        "Wykorzystywany w systemach Enterprise Resource Planning (ERP) Systems, Customer Relationship Management (CRM) software, and web-based applications.\n",
        "\n",
        "![](../img/baza1.png){.center}\n",
        "\n",
        "Model ten dostarcza efektywnych rozwiązań m.in do:\n",
        "\n",
        "- efektywnego i bezpiecznego przechowywania danych,\n",
        "- transakcyjnego odtwarzanie danych po awarii,\n",
        "- optymalizacji dostępu do danych,\n",
        "- zarządzania współbieżnością,\n",
        "- przetwarzania zdarzeń -> odczyt -> zapis\n",
        "\n",
        "Co w przypadku gdy mamy do czynienia z:\n",
        "\n",
        "- agregacjami danych z wielu systemów (np. dla wielu sklepów),\n",
        "- raportowanie i podsumowania danych,\n",
        "- optymalizacja złożonych zapytań,\n",
        "- wspomaganie decyzji biznesowych.\n",
        "\n",
        "Badania nad tego typu zagadnieniami doprowadziły do sformułowania nowego modelu przetwarzania danych oraz nowego typu baz danych - **Hurtownie Danych** _(Data warehouse)_.\n",
        "\n",
        "### Model OLAP\n",
        "\n",
        "**Przetwarzanie analityczne on-line OLAP (on-line analytic processing).**\n",
        "\n",
        " Wspieranie procesów analizy i dostarczanie narzędzi umożliwiających analizę wielowymiarową (`czas`, `miejsce`, `produkt`).\n",
        "\n",
        " Proces zrzucania danych z różnych systemów do jednej bazy nazywamy Extract-Transform-Load (ETL) (normalizacja i encoding and schema transaction).\n",
        "\n",
        " Analiza danych z hurtowni to przede wszystkim obliczanie **agregatów** (podsumowań) dotyczących wymiarów hurtowni.\n",
        " Proces ten jest całkowicie sterowany przez użytkownika.\n",
        "\n",
        "**Przykład**\n",
        "\n",
        "Załóżmy, że mamy dostęp do hurtowni danych gdzie przechowywane są informacje dotyczące sprzedaży produktów w supermarkecie.\n",
        "Jak przeanalizować zapytania:\n",
        "\n",
        "1. Jaka jest łączna sprzedaż produktów w kolejnych kwartałach, miesiącach, tygodniach ?\n",
        "2. Jaka jest sprzedaż produktów z podziałem na rodzaje produktów ?\n",
        "3. Jaka jest sprzedaż produktów z podziałem na oddziały supermarketu ?\n",
        "\n",
        "Odpowiedzi na te pytania pozwalają określić `wąskie gardła` sprzedaży produktów przynoszących deficyt, zaplanować zapasy w magazynach czy porównać sprzedaż różnych grup w różnych oddziałach supermarketu.\n",
        "\n",
        "W ramach Hurtowni Danych najczęściej wykonuje się dwa rodzaje zapytań(oba w trybie batchowym):\n",
        "1. Wykonywane okresowo w czasie zapytania raportowe obliczające biznesowe statystyki\n",
        "2. Wykonywane ad-hoc zapytania wspomagające krytyczne decyzje biznesowe.\n",
        "\n",
        "![](../img/baza2.png){.center}\n"
      ],
      "id": "6e8d7435"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/seba/Documents/GitHub/RTA_2025/venv/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}