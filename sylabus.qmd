---
title: Sylabus
---

> Nazwa przedmiotu: Analiza danych w czasie rzeczywistym
> 
> Jednostka: Szkoła Główna Handlowa w Warszawie
> 
> Kod przedmiotu: 222890-D, 222890-S
>
> Punkty ECTS: 3
>
> Język prowadzenia: polski
>
> Poziom przedmiotu: średnio-zaawansowany


**Prowadzący:** [Sebastian Zając](https://sebastianzajac.pl), 
  [sebastian.zajac@sgh.waw.pl](mailto:sebastian.zajac@sgh.waw.pl)


**Website:**
  [https://sebkaz-teaching.github.io/RTA_2025/](https://sebkaz-teaching.github.io/RTA_2025/)



## Cel Przedmiotu

Współczesny biznes opiera się na podejmowaniu decyzji opartych na danych. 
Coraz większa ilość informacji, rosnące wymagania rynku oraz potrzeba natychmiastowej reakcji sprawiają, że analiza danych w czasie rzeczywistym staje się kluczowym elementem nowoczesnych procesów biznesowych.

Na zajęciach studenci zapoznają się z metodami i technologiami umożliwiającymi przetwarzanie danych w czasie rzeczywistym. 
Szczególną uwagę poświęcimy zastosowaniu uczenia maszynowego (machine learning), sztucznej inteligencji (artificial intelligence) oraz głębokich sieci neuronowych (deep learning) w analizie danych. 
Zrozumienie tych metod pozwala nie tylko lepiej interpretować zjawiska biznesowe, ale także podejmować szybkie i trafne decyzje.

W ramach kursu omówimy zarówno dane ustrukturyzowane, jak i nieustrukturyzowane (obrazy, dźwięk, strumieniowanie wideo). 
Studenci poznają architektury przetwarzania danych, takie jak lambda i kappa, wykorzystywane w systemach data lake, a także wyzwania związane z modelowaniem danych w czasie rzeczywistym na dużą skalę.

Kurs obejmuje część teoretyczną oraz praktyczne laboratoria, podczas których studenci będą pracować z rzeczywistymi danymi w środowiskach takich jak: JupyterLab, PyTorch, Apache Spark, Apache Kafka. 
Dzięki temu studenci nie tylko zdobędą wiedzę na temat metod analitycznych, ale także nauczą się korzystać z najnowszych technologii informatycznych stosowanych w analizie danych w czasie rzeczywistym.

## Program przedmiotu

1. Modelowanie, uczenie i predykcja w trybie wsadowym (offline learning) i przyrostowym (online learning). Problemy przyrostowego uczenia maszynowego.
2. Modele przetwarzania danych w Big Data. Od plików płaskich do Data Lake. Mity i fakty przetwarzania danych w czasie rzeczywistym. (Wykład)
3. Systemy NRT (near real-time systems), pozyskiwanie danych, streaming, analityka.
4. Algorytmy estymacji parametrów modelu w trybie przyrostowym. Stochastic Gradient Descent.
5. Architektura Lambda i Kappa. Zaprojektowanie architektury IT dla przetwarzania danych w czasie rzeczywistym.
6. Przygotowanie mikroserwisu z modelem ML do zastosowania produkcyjnego.
7. Strukturyzowane i niestrukturyzowane dane. Relacyjne bazy danych i bazy NoSQL
8. Agregacje i raportowanie w bazach NoSQL (na przykładzie bazy Cassandra).
9. Podstawy obiektowego programowania w Pythonie w analizie regresji liniowej, logistycznej oraz sieci neuronowych z wykorzystaniem biblioteki sklearn, TensorFLow i Keras
10. Architektura IT przetwarzania Big Data. Przygotowanie wirtualnego środowiska dla Sparka. Pierwszy program w PySpark. Wykorzystanie przygotowanego środowiska do analizy danych z serwisu Twitter.
11. Analiza 1 Detekcja wyłudzeń w zgłoszeniach szkód samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego środowiska. Cz 1.
12. Analiza 1 Detekcja wyłudzeń w zgłoszeniach szkód samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego środowiska. Cz 2.
13. Przygotowanie środowiska Microsoft Azure. Detekcja anomalii i wartości odstających w logowanych zdarzeniach sieci Ethernet cz 1.
14. Analiza 2 Detekcja anomalii i wartości odstających w logowanych zdarzeniach sieci Ethernet cz 2. Inne narzędzia IT do szybkiej analizy logów.
15. Narzędzia SAS do strumieniowego przetwarzania danych

## Efekty kształcenia

1. Wiedza:

- Zna historię i filozofię modeli przetwarzania danych

Powiązania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W02, (OGL)O2_W04, (OGL)O2_W07

Metody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)

Metody dokumentacji: wykaz pytań z kolokwium

- Zna typy danych ustrukturyzowanych jak i nieustrukturyzowanych

Powiązania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W04, (OGL)O2_W04, (OGL) O2_W07

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

- Zna możliwości i obszary zastosowania procesowania danych w czasie rzeczywistym

Powiązania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W02, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W08

Metody weryfikacji: egzamin pisemny (pytania otwarte, zadania)

Metody dokumentacji: wykaz pytań egzaminacyjnych

- Zna teoretyczne aspekty struktury lambda i kappa

Powiązania: (Analiza danych - Big Data)K2A_W03, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W04, (OGL) O2_W06, (OGL)O2_W08

Metody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)

Metody dokumentacji: wykaz pytań z kolokwium

- Umie wybrać strukturę IT dla danego problemu biznesowego

Powiązania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

- Rozumie potrzeby biznesowe podejmowania decyzji w bardzo krótkim czasie

Powiązania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

2. Umiejętności:

- Rozróżnia typy danych strukturyzowanych jak i niestrukturyzowanych

Powiązania: K2A_U02, K2A_U07, K2A_U10, O2_U02

Metody weryfikacji: test

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

- Umie przygotować, przetwarzać oraz zachowywać dane generowane w czasie rzeczywistym

Powiązania:  K2A_U03, K2A_U05, K2A_U09, O2_U02, O2_U04

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

- Rozumie ograniczenia wynikające z czasu przetwarzania przez urządzenia oraz systemy informatyczne

Powiązania:  K2A_U01, K2A_U07, K2A_U11, O2_U02

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

- Umie zastosować i skonstruować system do przetwarzania w czasie rzeczywistym

Powiązania:  K2A_U05, K2A_U10, O2_U05, O2_U06, O2_U07

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

- Umie przygotować raportowanie dla systemu przetwarzania w czasie rzeczywistym

Powiązania: K2A_U02, K2A_U08, K2A_U10, O2_U06, O2_U07

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)

3. Kompetencje:

- Formułuje problem analityczny wraz z jego informatycznym rozwiązaniem

Powiązania: K2A_K01, K2A_K03, O2_K02,  O2_K06, O2_K07

Metody weryfikacji: projekt, prezentacja

Metody dokumentacji: prace pisemne studenta (w trakcie semestru, zaliczeniowe, egzaminacyjne)

- Utrwala umiejętność samodzielnego uzupełniania wiedzy teoretycznej jak i praktycznej w zakresie programowania,
modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym. 

Powiązania: K2A_K02, K2A_K04, (OGL)O2_K01, (OGL) O2_K02, (OGL)O2_K05, (OGL)O2_K06

Metody weryfikacji: projekt

Metody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)


## Realizacja przedmiotu

- egzamin testowy 20%
- Zadania 40% 
- Projekt 40%


## Literatura


1️⃣ Zając S. (red.), Modelowanie dla biznesu, Analityka w czasie rzeczywistym - narzędzia informatyczne i biznesowe, SGH, Warszawa 2022.

2️⃣ Frątczak E. (red.), Modelowanie dla biznesu: Regresja logistyczna, Regresja Poissona, Survival Data Mining, CRM, Credit Scoring, SGH, Warszawa 2019.

3️⃣ Bellemare A., Mikrousługi oparte na zdarzeniach. Wykorzystanie danych w organizacji na dużą skalę, O'Reilly 2021.

4️⃣ Shapira G., Palino T., Sivaram R., Petty K., Kafka: The Definitive Guide. Real-time data and stream processing at scale, O'Reilly 2022.

5️⃣ Lakshmanan V., Robinson S., Munn M., Wzorce projektowe uczenia maszynowego. Rozwiązania typowych problemów dotyczących przygotowania danych, konstruowania modeli i MLOps, O'Reilly 2021.

6️⃣ Gift N., Deza A., Practical MLOps: Operationalizing Machine Learning Models, O'Reilly 2022.

7️⃣ Tiark Rompf, Streaming Systems: The What, Where, When, and How of Large-Scale Data Processing, O'Reilly 2018.

8️⃣ Sebastián Ramírez, FastAPI: Modern Web APIs with Python, Manning (w przygotowaniu, aktualnie dostępna online).

9️⃣ Trevor Hastie, Robert Tibshirani, Jerome Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer 2017.

🔟 Anirudh Koul, Siddha Ganju, Meher Kasam, Practical Deep Learning for Cloud, Mobile & Edge, O'Reilly 2019.


## Nowy program przedmiotu

1. Batch vs. Real-Time vs. Streaming Analytics – Różnice między trybami przetwarzania danych, kluczowe koncepcje i zastosowania.
2. Modele przetwarzania danych w Big Data – Od plików płaskich do Data Lake, wady i zalety podejścia real-time. Mity i fakty o przetwarzaniu w czasie rzeczywistym.
3. Architektura IT dla przetwarzania w czasie rzeczywistym – Omówienie architektur Lambda i Kappa w kontekście strumieniowego przetwarzania danych.
4. Systemy przetwarzania danych w czasie rzeczywistym – Przegląd technologii: Apache Kafka, Apache Spark Streaming, Apache Flink i ich zastosowania w Pythonie.
5. Podstawy uczenia maszynowego w czasie rzeczywistym – Porównanie offline learning vs. online learning, problemy związane z przyrostowym uczeniem maszynowym.

🧑‍🏫 Wykłady (teoria + case study z biznesu)

1️⃣ Wprowadzenie: Ewolucja analizy danych
Dane strukturyzowane (SQL, Pandas) vs. nieustrukturyzowane (teksty, obrazy, grafy).
Przetwarzanie wsadowe (batch processing) vs. strumieniowe (stream processing).
Case study: Jak firmy przechodzą od tabel do analizy strumieniowej?

2️⃣ Systemy przetwarzania danych w czasie rzeczywistym
Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka).
Lambda i Kappa Architecture – różnice i zastosowania.
Case study: Rekomendacje produktowe w e-commerce.

3️⃣ Modele ML/DL dla danych w czasie rzeczywistym
Uczenie wsadowe (batch) vs. przyrostowe (online learning).
Stochastic Gradient Descent (SGD) – podstawa ML na strumieniach.
Case study: Klasyfikacja oszustw w czasie rzeczywistym.

4️⃣ Obiektowe programowanie w Pythonie w kontekście ML
Struktury klasowe dla modeli ML.
Tworzenie pipeline'ów ML w Pythonie.
Case study: Klasyfikacja wiadomości jako SPAM/NON-SPAM w strumieniu tekstów.

5️⃣ Tworzenie API z regułami decyzyjnymi i ML
Budowa API w FastAPI dla modelu ML.
Integracja modelu klasyfikacji z systemem decyzyjnym.
Case study: System wykrywania anomalii w logach serwerowych.

