[
  {
    "objectID": "plan.html",
    "href": "plan.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "Lecture 1: Introduction to Real-Time Data Analysis\nLecture 2: Data Ingestion and Processing for Real-Time Analysis\nLecture 3: Real-Time Data Analysis Techniques\nLecture 4: Real-Time Data Visualization and Communication\nLecture 5: Case Studies and Implementation\nThroughout the lectures, Iâ€™ll incorporate interactive elements, such as:\nThis comprehensive lecture plan will provide students with a solid foundation in real-time data analysis, covering the technical aspects of data ingestion, processing, and visualization, as well as practical applications and best practices."
  },
  {
    "objectID": "plan.html#nowy-program-przedmiotu",
    "href": "plan.html#nowy-program-przedmiotu",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "Nowy program przedmiotu",
    "text": "Nowy program przedmiotu\n\nBatch vs.Â Real-Time vs.Â Streaming Analytics â€“ RÃ³Å¼nice miÄ™dzy trybami przetwarzania danych, kluczowe koncepcje i zastosowania.\nModele przetwarzania danych w Big Data â€“ Od plikÃ³w pÅ‚askich do Data Lake, wady i zalety podejÅ›cia real-time. Mity i fakty o przetwarzaniu w czasie rzeczywistym.\nArchitektura IT dla przetwarzania w czasie rzeczywistym â€“ OmÃ³wienie architektur Lambda i Kappa w kontekÅ›cie strumieniowego przetwarzania danych.\nSystemy przetwarzania danych w czasie rzeczywistym â€“ PrzeglÄ…d technologii: Apache Kafka, Apache Spark Streaming, Apache Flink i ich zastosowania w Pythonie.\nPodstawy uczenia maszynowego w czasie rzeczywistym â€“ PorÃ³wnanie offline learning vs.Â online learning, problemy zwiÄ…zane z przyrostowym uczeniem maszynowym.\n\nğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej?\n2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce.\n3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym.\n4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w.\n5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych."
  },
  {
    "objectID": "indexS.html",
    "href": "indexS.html",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-S\nSemestr zimowy 2024/2025, SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nSzczegÃ³Å‚owy opis znajdziesz w sylabusie. Znajdziesz w nim opis wszystkich wykÅ‚adÃ³w i Ä‡wiczeÅ„ oraz proponowanÄ… literaturÄ™.\nInne ksiÄ…Å¼ki zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki"
  },
  {
    "objectID": "indexS.html#analiza-danych-w-czasie-rzeczywistym",
    "href": "indexS.html#analiza-danych-w-czasie-rzeczywistym",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-S\nSemestr zimowy 2024/2025, SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nSzczegÃ³Å‚owy opis znajdziesz w sylabusie. Znajdziesz w nim opis wszystkich wykÅ‚adÃ³w i Ä‡wiczeÅ„ oraz proponowanÄ… literaturÄ™.\nInne ksiÄ…Å¼ki zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki"
  },
  {
    "objectID": "indexS.html#kalendarz",
    "href": "indexS.html#kalendarz",
    "title": "Informacje ogÃ³lne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykÅ‚ad\n\n22-02-2025 (sobota) 08:00-09:30 - WykÅ‚ad 1\n08-03-2025 (sobota) 08:00-09:30 - WykÅ‚ad 2\n\n\n\nLaboratoria\n\nLab1\n22-03-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n23-03-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab2\n05-04-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n06-04-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab3\n26-04-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n27-04-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab4\n17-05-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n18-05-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab5\n31-05-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n01-06-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\n\nZaliczenie i Egzamin\nWykÅ‚ady zakoÅ„czÄ… siÄ™ testem (podczas ostatnich zajÄ™Ä‡) 20 pytaÅ„.\nAby zaliczyÄ‡ test, naleÅ¼y zdobyÄ‡ wiÄ™cej niÅ¼ 13 punktÃ³w â€“ jest to warunek konieczny do uczestnictwa w Ä‡wiczeniach.\nLaboratoria\nPodczas laboratoriÃ³w bÄ™dÄ… zadawane prace domowe, ktÃ³re naleÅ¼y przesyÅ‚aÄ‡ za poÅ›rednictwem MS Teams. KaÅ¼dy brak pracy domowej obniÅ¼a koÅ„cowÄ… ocenÄ™ o 0,5 stopnia.\n\nProjekt\nProjekty naleÅ¼y realizowaÄ‡ w grupach maksymalnie 5-osobowych.\nWymagania projektu\n\nProjekt powinien rozwiÄ…zywaÄ‡ realny problem biznesowy, ktÃ³ry moÅ¼na opracowaÄ‡ przy uÅ¼yciu danych przetwarzanych w trybie online. (Nie wyklucza to uÅ¼ycia przetwarzania wsadowego, np. do generowania modelu).\nDane powinny byÄ‡ przesyÅ‚ane do Apache Kafka, skÄ…d bÄ™dÄ… poddawane dalszemu przetwarzaniu i analizie.\nMoÅ¼na uÅ¼ywaÄ‡ dowolnego jÄ™zyka programowania w kaÅ¼dym komponencie projektu.\nMoÅ¼na wykorzystaÄ‡ narzÄ™dzia BI.\nÅ¹rÃ³dÅ‚em danych moÅ¼e byÄ‡ dowolne API, sztucznie generowane dane, IoT itp."
  },
  {
    "objectID": "indexS.html#technologie",
    "href": "indexS.html#technologie",
    "title": "Informacje ogÃ³lne",
    "section": "Technologie",
    "text": "Technologie\nUczestniczÄ…c w zajÄ™ciach musisz opanowaÄ‡ i przynajmniej w podstawowym zakresie posÅ‚ugiwaÄ‡ siÄ™ nastÄ™pujÄ…cymi technologiami informatycznymi:\n\nGIT\nPython, Jupyter notebook, Jupyter lab, Colab\nDocker\nApache Spark, Apache Kafka\nDatabricks Community edition Web page."
  },
  {
    "objectID": "old_lectures/old_wyklad1.html",
    "href": "old_lectures/old_wyklad1.html",
    "title": "Od plikoÌw pÅ‚askich do Data Mash",
    "section": "",
    "text": "RozwÃ³j technologii informatycznych spowodowaÅ‚ dostÄ™p do niewyobraÅ¼alnych iloÅ›ci nowego zasobu jakim sÄ… ustrukturyzowane jak i nieustrukturyzowane dane.\nDane przyczyniÅ‚y siÄ™ do powstania tysiÄ™cy nowych narzÄ™dzi do generowania, zbierania, przechowywania i przetwarzania informacji na niespotykanÄ… dotÄ…d skalÄ™.\nZasÃ³b ten nie jest nowoÅ›ciÄ… i dostÄ™pny jest od bardzo dawna. Jednak dopiero po wprowadzeniu systemu pisma moÅ¼na byÅ‚o zaczÄ…Ä‡ prowadziÄ‡ zapis i przetwarzanie w postaci rachunkowoÅ›ci czy rejestrÃ³w rÃ³Å¼nych rzeczy takich jak: zaludnienie w krajach, spisy rzek, jezior, najgÅ‚Ä™bsze miejsca itp.\nPojawienie siÄ™ nowych wyzwaÅ„ naukowych i biznesowych staje siÄ™ moÅ¼liwe do realizacji dziÄ™ki budowie systemÃ³w opartych na otwartym oprogramowaniu, jak rÃ³wnieÅ¼ dziÄ™ki wykorzystaniu klastrÃ³w komputerÃ³w do wspomagania przetwarzania ogromnych iloÅ›ci danych.\nDziÅ› systemy takie jak SAS, Apache Hadoop,Apache Kafka , Apache Spark, Apache Flink i ich chmurowe odpowiedniki, uÅ¼ywane sÄ… na szerokÄ… skalÄ™ w wielu instytucjach i firmach niemal w kaÅ¼dej dziedzinie. NarzÄ™dzia te wykorzystywane sÄ… w bankowoÅ›ci, opiece zdrowotnej, naukach przyrodniczych, produkcji, sektorze publicznym czy sprzedaÅ¼y.\nEpoka danych stawia przed nami coraz to nowsze wyzwania zwiÄ…zane nie tylko z iloÅ›ciÄ…, ale i z czasem przetwarzania danych.\nNowe wyzwania biznesowe to miÄ™dzy innymi:\n\ninteligentna reklama tysiÄ™cy produktÃ³w dla milionÃ³w klientÃ³w,\nprzetwarzanie danych o genach, RNA czy teÅ¼ biaÅ‚kach genus,\ninteligentne wykrywanie rÃ³Å¼norodnych sposobÃ³w naduÅ¼yÄ‡ wÅ›rÃ³d setek miliardÃ³w transakcji kart kredytowych,\nsymulacje gieÅ‚dowe oparte o tysiÄ…ce instrumentÃ³w finansowych\nâ€¦\n\n\n\nDane ustrukturyzowane zorganizowane sÄ… w kolumnach cech charakteryzujÄ…cych kaÅ¼dÄ… obserwacjÄ™ (wiersze). Kolumny posiadajÄ… etykietÄ™, ktÃ³ra wskazuje na ich interpretacjÄ™.\nPrzykÅ‚adem kolumn mogÄ… byÄ‡ takie cechy jak: pÅ‚eÄ‡, wzrost czy iloÅ›Ä‡ kedytÃ³w, na podstawie ktÃ³rych moÅ¼na przewidywaÄ‡ czy klient bÄ™dzie spÅ‚acaÅ‚ kredyt czy teÅ¼ nie.\n\n\nCode\ndane_klientow = {\"sex\":[\"m\",\"f\",\"m\",\"m\",\"f\"],\n \"height\":[160, 172, 158, 174, 192],\n \"credits\":[0,0,1,3,1]\n }\n\ndf = pd.DataFrame(dane_klientow)\nprint(df)\n\n\n  sex  height  credits\n0   m     160        0\n1   f     172        0\n2   m     158        1\n3   m     174        3\n4   f     192        1\n\n\nTakie przewidywanie rÃ³wnieÅ¼ oznaczane jest jako cecha (ang. target).\n\n\nCode\ndf['target'] = [0,1,1,0,0]\nprint(df)\n\n\n  sex  height  credits  target\n0   m     160        0       0\n1   f     172        0       1\n2   m     158        1       1\n3   m     174        3       0\n4   f     192        1       0\n\n\n\n\n\nW wielu jÄ™zykach programowania domyÅ›lnym pojemnikiem na przechowywanie wartoÅ›ci sÄ… zmienne.\nwiek = 47\nstan_cywilny = 'kawaler'\nNie sÄ… one jednak praktycznÄ… formÄ… do przechowywania i manipulowania danymi.\nJednym z rozwiÄ…zaÅ„ jest przechowywanie wszystkich cech (np. klienta) w jednym obiekcie.\nW Pythonie zadanie to moze realizowaÄ‡ obiekt listy, ktÃ³ry pozwala przechowywaÄ‡ rÃ³zne typy danych w jednym obiekcie.\n\nklient = [38, 'kawaler', 1, 56.3]\nprint(f\"dane klienta {klient} w obiekcie: {type(klient)}\")\n\ndane klienta [38, 'kawaler', 1, 56.3] w obiekcie: &lt;class 'list'&gt;\n\n\nZ punktu widzenia przerwarzania i modelowania mozliwoÅ›Ä‡ ta wprowadza wiÄ™cej problemÃ³w niz korzyÅ›ci. SprawdÅºmy domyÅ›lne operacje:\n\n\nCode\na = [1,2,3]\nb = [4,5,6]\nprint(f\"a={a}, b={b}\")\nprint(f\"a+b={a+b}\")\n\n\na=[1, 2, 3], b=[4, 5, 6]\na+b=[1, 2, 3, 4, 5, 6]\n\n\nnatomiast:\n\n\nCode\nprint(f\"a={a}, b={b}\")\nprint(f\"a*b\")\ntry:\n    print(f\"a*b= {a*b}\")\nexcept TypeError:\n    print(\"operacja niezdefiniowana\")\n\n\na=[1, 2, 3], b=[4, 5, 6]\na*b\noperacja niezdefiniowana\n\n\nBiblioteka Numpy:\n\nimport numpy as np\naa = np.array([1,2,3])\nbb = np.array([4,5,6])\n\nprint(type(aa))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\nCode\nprint(f\"aa={aa}, bb={bb}\")\nprint(f\"aa+bb={aa+bb}\")\nprint(f\"aa*bb={aa*bb}\")\n\n\naa=[1 2 3], bb=[4 5 6]\naa+bb=[5 7 9]\naa*bb=[ 4 10 18]\n\n\nDziÄ™ki tak otrzymanym tabelom cech moÅ¼emy stosowaÄ‡ algorytmy tj. XGBoost lub regresji logistycznej w celu wyznaczenia odpowiedniej kombinacji zmiennych wpÅ‚ywajÄ…cych na prawdopodobieÅ„stwo dobrego albo i zÅ‚ego klienta.\nPodstawowe systemy bazodanowe zwiÄ…zane z jÄ™zykiem SQL rÃ³wnieÅ¼ realizujÄ… modele danych, w ktÃ³rych dane Å‚adnowane sÄ… do (ustrukturyzowanych) tabel. \nDane nieustrukturyzowane to takie, ktÃ³re nie sÄ… uÅ‚oÅ¼one w tabelarycznej postaci.\n\n!Uwaga - nie oznacza to, iÅ¼ dane nie moÅ¼emy przetworzyÄ‡ do jakiejÅ› postaci tabelarzycznej.\n\nPrzykÅ‚adem moÅ¼e byÄ‡ dÅºwiÄ™k, obrazczy tekst. PoszczegÃ³lne litery, czÄ™stotliwoÅ›ci czy piksele nie niosÄ… ze sobÄ… Å¼adnych informacji. Nie tworzÄ… osobnych cech, co jest kluczowe dla odrÃ³Å¼nienia ich od danych ustrukturyzowanych.\n\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych (K2A_W02, K2A_W04, O2_W04, O2_W07)"
  },
  {
    "objectID": "old_lectures/old_wyklad1.html#dane",
    "href": "old_lectures/old_wyklad1.html#dane",
    "title": "Od plikoÌw pÅ‚askich do Data Mash",
    "section": "",
    "text": "RozwÃ³j technologii informatycznych spowodowaÅ‚ dostÄ™p do niewyobraÅ¼alnych iloÅ›ci nowego zasobu jakim sÄ… ustrukturyzowane jak i nieustrukturyzowane dane.\nDane przyczyniÅ‚y siÄ™ do powstania tysiÄ™cy nowych narzÄ™dzi do generowania, zbierania, przechowywania i przetwarzania informacji na niespotykanÄ… dotÄ…d skalÄ™.\nZasÃ³b ten nie jest nowoÅ›ciÄ… i dostÄ™pny jest od bardzo dawna. Jednak dopiero po wprowadzeniu systemu pisma moÅ¼na byÅ‚o zaczÄ…Ä‡ prowadziÄ‡ zapis i przetwarzanie w postaci rachunkowoÅ›ci czy rejestrÃ³w rÃ³Å¼nych rzeczy takich jak: zaludnienie w krajach, spisy rzek, jezior, najgÅ‚Ä™bsze miejsca itp.\nPojawienie siÄ™ nowych wyzwaÅ„ naukowych i biznesowych staje siÄ™ moÅ¼liwe do realizacji dziÄ™ki budowie systemÃ³w opartych na otwartym oprogramowaniu, jak rÃ³wnieÅ¼ dziÄ™ki wykorzystaniu klastrÃ³w komputerÃ³w do wspomagania przetwarzania ogromnych iloÅ›ci danych.\nDziÅ› systemy takie jak SAS, Apache Hadoop,Apache Kafka , Apache Spark, Apache Flink i ich chmurowe odpowiedniki, uÅ¼ywane sÄ… na szerokÄ… skalÄ™ w wielu instytucjach i firmach niemal w kaÅ¼dej dziedzinie. NarzÄ™dzia te wykorzystywane sÄ… w bankowoÅ›ci, opiece zdrowotnej, naukach przyrodniczych, produkcji, sektorze publicznym czy sprzedaÅ¼y.\nEpoka danych stawia przed nami coraz to nowsze wyzwania zwiÄ…zane nie tylko z iloÅ›ciÄ…, ale i z czasem przetwarzania danych.\nNowe wyzwania biznesowe to miÄ™dzy innymi:\n\ninteligentna reklama tysiÄ™cy produktÃ³w dla milionÃ³w klientÃ³w,\nprzetwarzanie danych o genach, RNA czy teÅ¼ biaÅ‚kach genus,\ninteligentne wykrywanie rÃ³Å¼norodnych sposobÃ³w naduÅ¼yÄ‡ wÅ›rÃ³d setek miliardÃ³w transakcji kart kredytowych,\nsymulacje gieÅ‚dowe oparte o tysiÄ…ce instrumentÃ³w finansowych\nâ€¦\n\n\n\nDane ustrukturyzowane zorganizowane sÄ… w kolumnach cech charakteryzujÄ…cych kaÅ¼dÄ… obserwacjÄ™ (wiersze). Kolumny posiadajÄ… etykietÄ™, ktÃ³ra wskazuje na ich interpretacjÄ™.\nPrzykÅ‚adem kolumn mogÄ… byÄ‡ takie cechy jak: pÅ‚eÄ‡, wzrost czy iloÅ›Ä‡ kedytÃ³w, na podstawie ktÃ³rych moÅ¼na przewidywaÄ‡ czy klient bÄ™dzie spÅ‚acaÅ‚ kredyt czy teÅ¼ nie.\n\n\nCode\ndane_klientow = {\"sex\":[\"m\",\"f\",\"m\",\"m\",\"f\"],\n \"height\":[160, 172, 158, 174, 192],\n \"credits\":[0,0,1,3,1]\n }\n\ndf = pd.DataFrame(dane_klientow)\nprint(df)\n\n\n  sex  height  credits\n0   m     160        0\n1   f     172        0\n2   m     158        1\n3   m     174        3\n4   f     192        1\n\n\nTakie przewidywanie rÃ³wnieÅ¼ oznaczane jest jako cecha (ang. target).\n\n\nCode\ndf['target'] = [0,1,1,0,0]\nprint(df)\n\n\n  sex  height  credits  target\n0   m     160        0       0\n1   f     172        0       1\n2   m     158        1       1\n3   m     174        3       0\n4   f     192        1       0\n\n\n\n\n\nW wielu jÄ™zykach programowania domyÅ›lnym pojemnikiem na przechowywanie wartoÅ›ci sÄ… zmienne.\nwiek = 47\nstan_cywilny = 'kawaler'\nNie sÄ… one jednak praktycznÄ… formÄ… do przechowywania i manipulowania danymi.\nJednym z rozwiÄ…zaÅ„ jest przechowywanie wszystkich cech (np. klienta) w jednym obiekcie.\nW Pythonie zadanie to moze realizowaÄ‡ obiekt listy, ktÃ³ry pozwala przechowywaÄ‡ rÃ³zne typy danych w jednym obiekcie.\n\nklient = [38, 'kawaler', 1, 56.3]\nprint(f\"dane klienta {klient} w obiekcie: {type(klient)}\")\n\ndane klienta [38, 'kawaler', 1, 56.3] w obiekcie: &lt;class 'list'&gt;\n\n\nZ punktu widzenia przerwarzania i modelowania mozliwoÅ›Ä‡ ta wprowadza wiÄ™cej problemÃ³w niz korzyÅ›ci. SprawdÅºmy domyÅ›lne operacje:\n\n\nCode\na = [1,2,3]\nb = [4,5,6]\nprint(f\"a={a}, b={b}\")\nprint(f\"a+b={a+b}\")\n\n\na=[1, 2, 3], b=[4, 5, 6]\na+b=[1, 2, 3, 4, 5, 6]\n\n\nnatomiast:\n\n\nCode\nprint(f\"a={a}, b={b}\")\nprint(f\"a*b\")\ntry:\n    print(f\"a*b= {a*b}\")\nexcept TypeError:\n    print(\"operacja niezdefiniowana\")\n\n\na=[1, 2, 3], b=[4, 5, 6]\na*b\noperacja niezdefiniowana\n\n\nBiblioteka Numpy:\n\nimport numpy as np\naa = np.array([1,2,3])\nbb = np.array([4,5,6])\n\nprint(type(aa))\n\n&lt;class 'numpy.ndarray'&gt;\n\n\n\n\nCode\nprint(f\"aa={aa}, bb={bb}\")\nprint(f\"aa+bb={aa+bb}\")\nprint(f\"aa*bb={aa*bb}\")\n\n\naa=[1 2 3], bb=[4 5 6]\naa+bb=[5 7 9]\naa*bb=[ 4 10 18]\n\n\nDziÄ™ki tak otrzymanym tabelom cech moÅ¼emy stosowaÄ‡ algorytmy tj. XGBoost lub regresji logistycznej w celu wyznaczenia odpowiedniej kombinacji zmiennych wpÅ‚ywajÄ…cych na prawdopodobieÅ„stwo dobrego albo i zÅ‚ego klienta.\nPodstawowe systemy bazodanowe zwiÄ…zane z jÄ™zykiem SQL rÃ³wnieÅ¼ realizujÄ… modele danych, w ktÃ³rych dane Å‚adnowane sÄ… do (ustrukturyzowanych) tabel. \nDane nieustrukturyzowane to takie, ktÃ³re nie sÄ… uÅ‚oÅ¼one w tabelarycznej postaci.\n\n!Uwaga - nie oznacza to, iÅ¼ dane nie moÅ¼emy przetworzyÄ‡ do jakiejÅ› postaci tabelarzycznej.\n\nPrzykÅ‚adem moÅ¼e byÄ‡ dÅºwiÄ™k, obrazczy tekst. PoszczegÃ³lne litery, czÄ™stotliwoÅ›ci czy piksele nie niosÄ… ze sobÄ… Å¼adnych informacji. Nie tworzÄ… osobnych cech, co jest kluczowe dla odrÃ³Å¼nienia ich od danych ustrukturyzowanych.\n\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych (K2A_W02, K2A_W04, O2_W04, O2_W07)"
  },
  {
    "objectID": "old_lectures/old_wyklad1.html#ÅºrÃ³dÅ‚a-danych",
    "href": "old_lectures/old_wyklad1.html#ÅºrÃ³dÅ‚a-danych",
    "title": "Od plikoÌw pÅ‚askich do Data Mash",
    "section": "Å¹rÃ³dÅ‚a danych",
    "text": "Å¹rÃ³dÅ‚a danych\nDo trzech najwiÄ™kszych â€œgeneratorÃ³wâ€ danych naleÅ¼Ä…:\n\ndane spoÅ‚eczne w formie tekstÃ³w (tweety, wpisy w portalach spoÅ‚ecznoÅ›ciowych, komentarze), zdjÄ™Ä‡ czy plikÃ³w wideo. Przydatne do problemÃ³w biznesowych realizujÄ…cych ocenÄ™ zachowaÅ„ i nastrojÃ³w konsumentÃ³w w analizach marketingowych.\nIoT: dane pochodzÄ…ce z czujnikÃ³w, czy teÅ¼ logi dziaÅ‚ania urzÄ…dzeÅ„ i uÅ¼ytkownikÃ³w (np. na stronie www).\ndane transakcyjne: czyli ogÃ³lnie to co w kaÅ¼dej chwili generowane jest jako transakcje pojawiajÄ…ce siÄ™ zarÃ³wno w trybie online jak i w trybie offline.\n\n\nRzeczywisty proces generowania danych\nDane generowane sÄ… w postaci nieograniczonej - pojawiajÄ… siÄ™ na skutek ciÄ…gÅ‚ych dziaÅ‚aÅ„ systemÃ³w. W swoim telefonie wygenerowaÅ‚eÅ› dziÅ› (a nawet na tych zajÄ™ciach!) wiele danych. Czy na nastÄ™pnych zajÄ™ciach lub tez jutro nie bÄ™dziesz ich generowaÅ‚?\nDane zawsze generowane sÄ… jako jakaÅ› forma strumienia danych.\nSystemy obsÅ‚ugujÄ…ce strumienie danych: - hurtownie danych - systemy monitorujÄ…ce dziaÅ‚ania urzÄ…dzeÅ„ (IoT) - systemy transakcyjne - systemy analityczne stron www - reklamy on-line - media spoÅ‚ecznoÅ›ciowe - systemy logowania - â€¦.\n\nfirma to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ danych. Zobacz\n\nW przetwarzaniu wsadowym ÅºrÃ³dÅ‚em (ale i wynikiem przetwarzania) danych jest plik. Jest on zapisywany raz i moÅ¼na siÄ™ do niego odwoÅ‚aÄ‡ (moÅ¼e na nim dziaÅ‚aÄ‡ wiele procesÃ³w - zadaÅ„). Nazwa pliku to element identyfikujÄ…cy zbiÃ³r rekordÃ³w.\nW przypadku strumienia zdarzenie jest generowane tylko raz przez tzw. producenta (zwanego teÅ¼ nadawcÄ… lub dostawcÄ…). PowstaÅ‚e zdarzenie przetwarzane moÅ¼e byÄ‡ przez wielu tzw. konsumentÃ³w (odbiorcÃ³w). Zdarzenia strumieniowe grupowane sÄ… w tzw. tematy (ang. topics)."
  },
  {
    "objectID": "old_lectures/old_wyklad1.html#big-data",
    "href": "old_lectures/old_wyklad1.html#big-data",
    "title": "Od plikoÌw pÅ‚askich do Data Mash",
    "section": "Big Data",
    "text": "Big Data\n\n,,Big Data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so every one claims they are doing it.â€™â€™ â€” Dan Ariely, Professor of Psychology and Behavioral Economics, Duke University\n\n\none, two, â€¦ four V\n\nVolume (ObjÄ™toÅ›Ä‡) - rozmiar danych produkowanych na caÅ‚ym Å›wiecie przyrasta w tempie wykÅ‚adniczym.\nVelocity (SzybkoÅ›Ä‡) - tempo produkowania danych, szybkoÅ›ci ich przesyÅ‚ania i przetwarzania.\nVariety (ZrÃ³Å¼nicowanie) - tradycyjne dane kojarzÄ… siÄ™ nam z postaciÄ… alfanumerycznÄ… zÅ‚oÅ¼onÄ… z liter i cyfr. Obecnie mamy do dyspozycji obrazy, dÅºwiÄ™ki, pliki wideo, strumienie danych z IoT\nVeracity (WiarygodnoÅ›Ä‡) - Czy dane sÄ… kompletne i poprawne? Czy obiektywnie odzwierciedlajÄ… rzeczywistoÅ›Ä‡? Czy sÄ… podstawÄ… do podejmowania decyzji?\nValue - The value that the data actually holds. In the end, itâ€™s all about cost and benefits.\n\n\nCelem obliczeÅ„ nie sÄ… liczby, lecz ich zrozumienie R.W. Hamming 1962."
  },
  {
    "objectID": "old_lectures/old_wyklad1.html#modele-przetwarzania-danych",
    "href": "old_lectures/old_wyklad1.html#modele-przetwarzania-danych",
    "title": "Od plikoÌw pÅ‚askich do Data Mash",
    "section": "Modele przetwarzania danych",
    "text": "Modele przetwarzania danych\nDane w biznesie przetwarzane sÄ… praktycznie od zawsze. W ciÄ…gu ostatnich dziesiÄ™cioleci iloÅ›Ä‡ przetwarzanych danych systematycznie roÅ›nie co wpÅ‚ywa na proces przygotowania i przetwarzania danych.\n\nTrochÄ™ historii\n\nLata 60-te : Kolekcje danych, bazy danych\nLata 70-te : Relacyjne modele danych i ich implementacja w systemach OLTP\n1975 : Pierwsze komputery osobiste\nLata 80-te : Zaawansowane modele danych, extended-relational, objective oriented, aplikacyjno-zorientowane itp.\n1983 : PoczÄ…tek internetu\nLata 90-te : Data mining, hurtownie danych, systemy OLAP\nPÃ³Åºniej : NoSQL, Hadoop, SPARK, data lake\n2002 : AWS , 2005: Hadoop, Cloud computing\n\nWiÄ™kszoÅ›Ä‡ danych przechowywana jest w bazach lub hurtowniach danych. Standardowo dostÄ™p do danych sprowadza siÄ™ najczÄ™Å›ciej do realizacji zapytaÅ„ poprzez aplikacjÄ™.\nSposÃ³b wykorzystania i realizacji procesu dostÄ™pu do bazy danych nazywamy modelem przetwarzania. NajczÄ™Å›ciej uÅ¼ywane sÄ… dwie implementacje:\n\n\nModel Tradycyjny\nModel tradycyjny - przetwarzanie transakcyjne w trybie on-line, OLTP (on-line transaction processing). Åšwietnie sprawdza siÄ™ w przypadku obsÅ‚ugi bieÅ¼Ä…cej np. obsÅ‚uga klienta, rejestr zamÃ³wieÅ„, obsÅ‚uga sprzedaÅ¼y itp. Wykorzystywany w systemach Enterprise Resource Planning (ERP) Systems, Customer Relationship Management (CRM) software, and web-based applications.\n\nModel ten dostarcza efektywnych rozwiÄ…zaÅ„ m.in do:\n\nefektywnego i bezpiecznego przechowywania danych,\ntransakcyjnego odtwarzanie danych po awarii,\noptymalizacji dostÄ™pu do danych,\nzarzÄ…dzania wspÃ³Å‚bieÅ¼noÅ›ciÄ…,\nprzetwarzania zdarzeÅ„ -&gt; odczyt -&gt; zapis\n\nCo w przypadku gdy mamy do czynienia z:\n\nagregacjami danych z wielu systemÃ³w (np. dla wielu sklepÃ³w),\nraportowanie i podsumowania danych,\noptymalizacja zÅ‚oÅ¼onych zapytaÅ„,\nwspomaganie decyzji biznesowych.\n\nBadania nad tego typu zagadnieniami doprowadziÅ‚y do sformuÅ‚owania nowego modelu przetwarzania danych oraz nowego typu baz danych - Hurtownie Danych (Data warehouse).\n\n\nModel OLAP\nPrzetwarzanie analityczne on-line OLAP (on-line analytic processing).\nWspieranie procesÃ³w analizy i dostarczanie narzÄ™dzi umoÅ¼liwiajÄ…cych analizÄ™ wielowymiarowÄ… (czas, miejsce, produkt).\nProces zrzucania danych z rÃ³Å¼nych systemÃ³w do jednej bazy nazywamy Extract-Transform-Load (ETL) (normalizacja i encoding and schema transaction).\nAnaliza danych z hurtowni to przede wszystkim obliczanie agregatÃ³w (podsumowaÅ„) dotyczÄ…cych wymiarÃ³w hurtowni. Proces ten jest caÅ‚kowicie sterowany przez uÅ¼ytkownika.\nPrzykÅ‚ad\nZaÅ‚Ã³Å¼my, Å¼e mamy dostÄ™p do hurtowni danych gdzie przechowywane sÄ… informacje dotyczÄ…ce sprzedaÅ¼y produktÃ³w w supermarkecie. Jak przeanalizowaÄ‡ zapytania:\n\nJaka jest Å‚Ä…czna sprzedaÅ¼ produktÃ³w w kolejnych kwartaÅ‚ach, miesiÄ…cach, tygodniach ?\nJaka jest sprzedaÅ¼ produktÃ³w z podziaÅ‚em na rodzaje produktÃ³w ?\nJaka jest sprzedaÅ¼ produktÃ³w z podziaÅ‚em na oddziaÅ‚y supermarketu ?\n\nOdpowiedzi na te pytania pozwalajÄ… okreÅ›liÄ‡ wÄ…skie gardÅ‚a sprzedaÅ¼y produktÃ³w przynoszÄ…cych deficyt, zaplanowaÄ‡ zapasy w magazynach czy porÃ³wnaÄ‡ sprzedaÅ¼ rÃ³Å¼nych grup w rÃ³Å¼nych oddziaÅ‚ach supermarketu.\nW ramach Hurtowni Danych najczÄ™Å›ciej wykonuje siÄ™ dwa rodzaje zapytaÅ„(oba w trybie batchowym): 1. Wykonywane okresowo w czasie zapytania raportowe obliczajÄ…ce biznesowe statystyki 2. Wykonywane ad-hoc zapytania wspomagajÄ…ce krytyczne decyzje biznesowe.\n\n\nWiedza:\n\nZna historieÌ¨ i filozofieÌ¨ modeli przetwarzania danych.\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych\n\n\n\nUmiejÄ™tnoÅ›ci:\n\nRozroÌzÌ‡nia typy danych strukturyzowanych jak i niestrukturyzowanych\n\n\n\nKompetencje:\n\nUtrwala umiejeÌ¨tnosÌcÌ samodzielnego uzupeÅ‚niania wiedzy teoretycznej jak i praktycznej w zakresie programowania, modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym."
  },
  {
    "objectID": "old_lectures/wyklad3.html",
    "href": "old_lectures/wyklad3.html",
    "title": "Mikroserwisy",
    "section": "",
    "text": "Komunikacja sieciowa, relacyjne bazy danych, rozwiÄ…zania chmurowe i big data znaczÄ…co zmieniÅ‚y sposÃ³b budowania systemÃ³w informatycznych i wykonywnia na niach pracy.\nPorÃ³wnaj to jak â€œnarzÄ™dziaâ€ do realizacji przekazu (gazeta, radio, telewizja, internet, komunikatory, media spoÅ‚ecznoÅ›ciowe) zmieniÅ‚y interakcje miÄ™dzyludzkie i struktury spoÅ‚eczne.\nKoncepcja mikrousÅ‚ugi (mikroserwisu) jest bardzo popularnym sposobem budowania systemÃ³w informatycznych jak i koncepcjÄ… przy tworzeniu oprogramowania czy realizacji firmy w duchu Data-Driven. Koncepcja ta pozwala zachowaÄ‡ wydajnoÅ›Ä‡ (rÃ³b jednÄ… rzecz ale dobrze), elastycznoÅ›Ä‡ i jasnÄ… postaÄ‡ caÅ‚ej struktury.\nChociaÅ¼ istniejÄ… inne sposoby architektury projektÃ³w oprogramowania, â€mikroserwisyâ€ sÄ… czÄ™sto uÅ¼ywane nie bez powodu. Idea mikroserwisÃ³w tkwi w nazwie: oprogramowanie jest reprezentowane jako wiele maÅ‚ych usÅ‚ug, ktÃ³re dziaÅ‚ajÄ… indywidualnie. PatrzÄ…c na ogÃ³lnÄ… architekturÄ™, kaÅ¼da mikrousÅ‚uga znajduje siÄ™ w maÅ‚ej czarnej skrzynce z jasno zdefiniowanymi wejÅ›ciami i wyjÅ›ciami. MoÅ¼esz porÃ³wnaÄ‡ tego typu zachowanie do â€œczystej funkcjiâ€ w programowaniu funkcyjnym.\nW celu umoÅ¼liwienia komunikacji rÃ³Å¼nych mikroserwisÃ³w czÄ™sto wybieranym rozwiÄ…zaniem jest wykorzystanie Application Programming Interfaces API ."
  },
  {
    "objectID": "old_lectures/wyklad3.html#komunikacja-przez-api",
    "href": "old_lectures/wyklad3.html#komunikacja-przez-api",
    "title": "Mikroserwisy",
    "section": "Komunikacja przez API",
    "text": "Komunikacja przez API\nCentralnym elementem architektury mikrousÅ‚ug jest wykorzystanie interfejsÃ³w API. API to czÄ™Å›Ä‡, ktÃ³ra pozwala na poÅ‚Ä…czenie dwÃ³ch mikroserwisÃ³w. Interfejsy API sÄ… bardzo podobne do stron internetowych. Podobnie jak strona internetowa, serwer wysyÅ‚a do Ciebie kod reprezentujÄ…cy stronÄ™ internetowÄ…. Twoja przeglÄ…darka internetowa interpretuje ten kod i wyÅ›wietla stronÄ™ internetowÄ….\nWeÅºmy przypadek biznesowy z modelem ML jako usÅ‚ugÄ…. ZaÅ‚Ã³Å¼my, Å¼e pracujesz dla firmy sprzedajÄ…cej mieszkania w Bostonie. Chcesz zwiÄ™kszaÄ‡ sprzedaÅ¼ i oferowaÄ‡ naszym klientom lepszÄ… jakoÅ›Ä‡ usÅ‚ug dziÄ™ki nowej aplikacji mobilnej, z ktÃ³rej moÅ¼e korzystaÄ‡ nawet 1 000 000 osÃ³b jednoczeÅ›nie. MoÅ¼emy to osiÄ…gnÄ…Ä‡, udostÄ™pniajÄ…c prognozÄ™ wartoÅ›ci domu, gdy uÅ¼ytkownik prosi o wycenÄ™ przez Internet.\n\nCzym jest serwowanie modelu ML\n\nSzkolenie dobrego modelu ML to TYLKO pierwsza czÄ™Å›Ä‡ caÅ‚ego procesu: Musisz udostÄ™pniÄ‡ swÃ³j model uÅ¼ytkownikom koÅ„cowym. Robisz to, zapewniajÄ…c dostÄ™p do modelu na swoim serwerze.\nAby udostÄ™pniÄ‡ model potrzebujesz: modelu, interpretera, danych wsadowych.\nWaÅ¼ne metryki\n\n\nczas oczekiwania,\nkoszty,\nliczba zapytaÄ‡ w jednostce czasu\n\n\nUdostÄ™pnianie danych miÄ™dzy dwoma lub wiÄ™cej systemami zawsze byÅ‚o podstawowym wymogiem tworzenia oprogramowania â€“ DevOps vs.Â MLOps.\n\nGdy wywoÅ‚asz interfejs API, otrzyma on Twoje Å¼Ä…danie. Å»Ä…danie wyzwala kod do uruchomienia na serwerze i generuje odpowiedÅº odesÅ‚anÄ… do Ciebie. JeÅ›li coÅ› pÃ³jdzie nie tak, moÅ¼esz nie otrzymaÄ‡ Å¼adnej odpowiedzi lub otrzymaÄ‡ kod bÅ‚Ä™du jako kod stanu HTTP.\n\nKlient-Serwer: Klient (system A) przesyÅ‚a Å¼Ä…danie przez HTTP do adresu URL hostowanego przez system B, ktÃ³ry zwraca odpowiedÅº. Identycznie dziaÅ‚a np przeglÄ…darka internetowa. Å»Ä…danie jest kierowane do serwera WWW, ktÃ³ry zwraca tekstowÄ… stronÄ™ HTML.\n\n\nBezstanowe: Å»Ä…danie klienta powinno zawieraÄ‡ wszystkie informacje niezbÄ™dne do udzielenia peÅ‚nej odpowiedzi.\n\nInterfejsy API moÅ¼na wywoÅ‚ywaÄ‡ za pomocÄ… wielu rÃ³Å¼nych narzÄ™dzi. Czasami moÅ¼esz nawet uÅ¼yÄ‡ przeglÄ…darki internetowej. NarzÄ™dzia takie jak CURL wykonujÄ… zadanie w wierszu poleceÅ„. MoÅ¼esz uÅ¼ywaÄ‡ narzÄ™dzi, takich jak Postman, do wywoÅ‚ywania interfejsÃ³w API za pomocÄ… interfejsu uÅ¼ytkownika.\n\nCaÅ‚a komunikacja jest objÄ™ta ustalonymi zasadami i praktykami, ktÃ³re sÄ… nazywane protokoÅ‚em HTTP.\n\n\n\nZapytanie - Request\n\nAdres URL (np. http://mydomain:8000/getapi?&val1=43&val2=3) zawiera:\n- domenÄ™, \n- port, \n- dodatkowe Å›cieÅ¼ki, \n- zapytanie\nMetody HTTP:\n- GET, \n- POST\nNagÅ‚Ã³wki HTTP zawierajÄ…:\n- informacje o autoryzacji, \n- cookies metadata\n\nCaÅ‚a informacja zawarta jest w Content-Type: application/json, text â€¦ Accept: application/json, Authorization: Basic abase64string, Tokens 4. CiaÅ‚o zapytania\nNajczÄ™Å›ciej wybieranym formatem dla wymiany informacji miÄ™dzy serwisami jest format JavaScript Object Notation (JSON). Przypomina on pythonowy obiekt sÅ‚ownika - â€œkluczâ€: â€œwartoÅ›Ä‡â€.\n{\n\"RAD\": 1,\n\"PTRATIO\": 15.3, \"INDUS\": 2.31, \"B\": 396.9,\n\"ZN\": 18,\n\"DIS\": 4.09, \"CRIM\": 0.00632, \"RM\": 6.575, \n\"AGE\": 65.2, \"CHAS\": 0, \"NOX\": 0.538, \n\"TAX\": 296, \"LSTAT\": 4.98\n}\n\n\nOdpowiedÅº - Response\n\nTreÅ›Ä‡ odpowiedzi przekazywana jest razem z nagÅ‚Ã³wkiem oraz statusem:\n\n200 OK\nContent-Encoding: gzip\nContent-Type: text/html; charset=utf-8\nDate: Mon, 18 Jul 2016 16:06:00 GMT Server: Apache\nPath=/;\n\nnp.: â€œContent-Typeâ€ =&gt; â€application/json; charset=utf-8â€, â€Serverâ€ =&gt; â€Genie/Julia/1.8.5â€\nTreÅ›Ä‡ (ciaÅ‚o) odpowiedzi:\n\n{\":input\":{\"RAD\":1,\"PTRATIO\":15.3,\"INDUS\":2.31,.....}}, {\":prediction\":[29.919737211857683]}\n\nHTTP status code:\n\n\n200 OK - prawidÅ‚owe wykonanie zapytania,\n40X Access Denied\n50X Internal server error\n\n\nWyszukaj informacje czym jest REST API.\n\n\nWiedza:\n\nZna mozÌ‡liwosÌci i obszary zastosowania procesowania danych w czasie rzeczywistym\nUmie wybracÌ struktureÌ¨ IT dla danego problemu biznesowego\nRozumie potrzeby biznesowe podejmowania decyzji w bardzo kroÌtkim czasie\n\n\n\nUmiejÄ™tnoÅ›ci:\n\nRozroÌzÌ‡nia typy danych strukturyzowanych jak i niestrukturyzowanych\n\n\n\nKompetencje:\n\nUtrwala umiejeÌ¨tnosÌcÌ samodzielnego uzupeÅ‚niania wiedzy teoretycznej jak i praktycznej w zakresie programowania, modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym."
  },
  {
    "objectID": "old_lectures/wyklad1S.html",
    "href": "old_lectures/wyklad1S.html",
    "title": "WykÅ‚ad 1",
    "section": "",
    "text": "RozwÃ³j technologii informatycznych spowodowaÅ‚ dostÄ™p do niewyobraÅ¼alnych iloÅ›ci nowego zasobu jakim sÄ… ustrukturyzowane jak i nieustrukturyzowane dane.\n\nDane przyczyniÅ‚y siÄ™ do powstania tysiÄ™cy nowych narzÄ™dzi do generowania, zbierania, przechowywania i przetwarzania informacji na niespotykanÄ… dotÄ…d skalÄ™.\nZasÃ³b ten nie jest nowoÅ›ciÄ… i dostÄ™pny jest od bardzo dawna. Jednak dopiero po wprowadzeniu systemu pisma moÅ¼na byÅ‚o zaczÄ…Ä‡ prowadziÄ‡ zapis i przetwarzanie w postaci rachunkowoÅ›ci czy rejestrÃ³w rÃ³Å¼nych rzeczy takich jak: zaludnienie w krajach, spisy rzek, jezior, najgÅ‚Ä™bsze miejsca itp.\nPojawienie siÄ™ nowych wyzwaÅ„ naukowych czy biznesowych staje siÄ™ moÅ¼liwe do realizacji dziÄ™ki budowie systemÃ³w opartych na otwartym oprogramowaniu, jak rÃ³wnieÅ¼ dziÄ™ki wykorzystaniu domowych komputerÃ³w do wspomagania przetwarzania ogromnych iloÅ›ci danych.\nDziÅ› systemy takie jak SAS, Apache Hadoop, Apache Spark, Apache Flink dziÄ™ki rozwiÄ…zaniom chmurowym uÅ¼ywane sÄ… na szerokÄ… skalÄ™ w wielu instytucjach i firmach niemal w kaÅ¼dej dziedzinie. NarzÄ™dzia te wykorzystywane sÄ… w bankowoÅ›ci, opiece zdrowotnej, naukach przyrodniczych, produkcji, sektorze publicznym czy sprzedaÅ¼y.\nEpoka danych stawia przed nami coraz to nowsze wyzwania zwiÄ…zane nie tylko z iloÅ›ciÄ…, ale i z czasem przetwarzania danych.\nNowe wyzwania biznesowe to miÄ™dzy innymi:\n\ninteligentna reklama tysiÄ™cy produktÃ³w dla milionÃ³w klientÃ³w,\nprzetwarzanie danych o genach, RNA czy teÅ¼ biaÅ‚kach genus,\ninteligentne wykrywanie rÃ³Å¼norodnych sposobÃ³w naduÅ¼yÄ‡ wÅ›rÃ³d setek miliardÃ³w transakcji kart kredytowych,\nsymulacje gieÅ‚dowe oparte o tysiÄ…ce instrumentÃ³w finansowych\nâ€¦\n\nWszystkie algorytmy uczenia maszynowego wymagajÄ… danych ustrukturyzowanych zapisanych w tabelarycznej postaci (tensory).\nZorganizowane sÄ… one w kolumnach cech charakteryzujÄ…cych kaÅ¼dÄ… obserwacjÄ™ (wiersze). PrzykÅ‚adem mogÄ… byÄ‡ takie cechy jak: pÅ‚eÄ‡, wzrost czy iloÅ›Ä‡ posiadanych samochodÃ³w, na podstawie ktÃ³rych moÅ¼na przewidywaÄ‡ czy klient bÄ™dzie spÅ‚acaÅ‚ kredyt czy teÅ¼ nie. Takie przewidywanie rÃ³wnieÅ¼ oznaczane jest jako cecha. Zmienne te dobierane sÄ… tak, by Å‚atwo moÅ¼na je byÅ‚o pozyskaÄ‡. DziÄ™ki tak otrzymanym tabelom cech moÅ¼emy stosowaÄ‡ algorytmy tj. XGBoost lub regresji logistycznej w celu wyznaczenia odpowiedniej kombinacji zmiennych wpÅ‚ywajÄ…cych na prawdopodobieÅ„stwo dobrego albo i zÅ‚ego klienta.\nPodstawowe systemy bazodanowe zwiÄ…zane z jÄ™zykiem SQL rÃ³wnieÅ¼ realizujÄ… modele danych, w ktÃ³rych dane Å‚adnowane sÄ… do (ustrukturyzowanych) tabel.\nDane nieustrukturyzowane to takie, ktÃ³re nie sÄ… uÅ‚oÅ¼one w~tabelarycznej postaci. &gt; !Uwaga - nie oznacza to, iÅ¼ dane nie moÅ¼emy przetworzyÄ‡ do jakiejÅ› postaci tabelarzycnzej.\nPrzykÅ‚adem moÅ¼e byÄ‡ dÅºwiÄ™k, obrazczy tekst. PoszczegÃ³lne litery, czÄ™stotliwoÅ›ci~czy piksele nie niosÄ… ze sobÄ… Å¼adnych informacji. Nie tworzÄ… osobnych cech, co jest kluczowe dla odrÃ³Å¼nienia ich od danych ustrukturyzowanych.\n\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych (K2A_W02, K2A_W04, O2_W04, O2_W07)"
  },
  {
    "objectID": "old_lectures/wyklad1S.html#od-plikow-pÅ‚askich-do-data-lake",
    "href": "old_lectures/wyklad1S.html#od-plikow-pÅ‚askich-do-data-lake",
    "title": "WykÅ‚ad 1",
    "section": "",
    "text": "RozwÃ³j technologii informatycznych spowodowaÅ‚ dostÄ™p do niewyobraÅ¼alnych iloÅ›ci nowego zasobu jakim sÄ… ustrukturyzowane jak i nieustrukturyzowane dane.\n\nDane przyczyniÅ‚y siÄ™ do powstania tysiÄ™cy nowych narzÄ™dzi do generowania, zbierania, przechowywania i przetwarzania informacji na niespotykanÄ… dotÄ…d skalÄ™.\nZasÃ³b ten nie jest nowoÅ›ciÄ… i dostÄ™pny jest od bardzo dawna. Jednak dopiero po wprowadzeniu systemu pisma moÅ¼na byÅ‚o zaczÄ…Ä‡ prowadziÄ‡ zapis i przetwarzanie w postaci rachunkowoÅ›ci czy rejestrÃ³w rÃ³Å¼nych rzeczy takich jak: zaludnienie w krajach, spisy rzek, jezior, najgÅ‚Ä™bsze miejsca itp.\nPojawienie siÄ™ nowych wyzwaÅ„ naukowych czy biznesowych staje siÄ™ moÅ¼liwe do realizacji dziÄ™ki budowie systemÃ³w opartych na otwartym oprogramowaniu, jak rÃ³wnieÅ¼ dziÄ™ki wykorzystaniu domowych komputerÃ³w do wspomagania przetwarzania ogromnych iloÅ›ci danych.\nDziÅ› systemy takie jak SAS, Apache Hadoop, Apache Spark, Apache Flink dziÄ™ki rozwiÄ…zaniom chmurowym uÅ¼ywane sÄ… na szerokÄ… skalÄ™ w wielu instytucjach i firmach niemal w kaÅ¼dej dziedzinie. NarzÄ™dzia te wykorzystywane sÄ… w bankowoÅ›ci, opiece zdrowotnej, naukach przyrodniczych, produkcji, sektorze publicznym czy sprzedaÅ¼y.\nEpoka danych stawia przed nami coraz to nowsze wyzwania zwiÄ…zane nie tylko z iloÅ›ciÄ…, ale i z czasem przetwarzania danych.\nNowe wyzwania biznesowe to miÄ™dzy innymi:\n\ninteligentna reklama tysiÄ™cy produktÃ³w dla milionÃ³w klientÃ³w,\nprzetwarzanie danych o genach, RNA czy teÅ¼ biaÅ‚kach genus,\ninteligentne wykrywanie rÃ³Å¼norodnych sposobÃ³w naduÅ¼yÄ‡ wÅ›rÃ³d setek miliardÃ³w transakcji kart kredytowych,\nsymulacje gieÅ‚dowe oparte o tysiÄ…ce instrumentÃ³w finansowych\nâ€¦\n\nWszystkie algorytmy uczenia maszynowego wymagajÄ… danych ustrukturyzowanych zapisanych w tabelarycznej postaci (tensory).\nZorganizowane sÄ… one w kolumnach cech charakteryzujÄ…cych kaÅ¼dÄ… obserwacjÄ™ (wiersze). PrzykÅ‚adem mogÄ… byÄ‡ takie cechy jak: pÅ‚eÄ‡, wzrost czy iloÅ›Ä‡ posiadanych samochodÃ³w, na podstawie ktÃ³rych moÅ¼na przewidywaÄ‡ czy klient bÄ™dzie spÅ‚acaÅ‚ kredyt czy teÅ¼ nie. Takie przewidywanie rÃ³wnieÅ¼ oznaczane jest jako cecha. Zmienne te dobierane sÄ… tak, by Å‚atwo moÅ¼na je byÅ‚o pozyskaÄ‡. DziÄ™ki tak otrzymanym tabelom cech moÅ¼emy stosowaÄ‡ algorytmy tj. XGBoost lub regresji logistycznej w celu wyznaczenia odpowiedniej kombinacji zmiennych wpÅ‚ywajÄ…cych na prawdopodobieÅ„stwo dobrego albo i zÅ‚ego klienta.\nPodstawowe systemy bazodanowe zwiÄ…zane z jÄ™zykiem SQL rÃ³wnieÅ¼ realizujÄ… modele danych, w ktÃ³rych dane Å‚adnowane sÄ… do (ustrukturyzowanych) tabel.\nDane nieustrukturyzowane to takie, ktÃ³re nie sÄ… uÅ‚oÅ¼one w~tabelarycznej postaci. &gt; !Uwaga - nie oznacza to, iÅ¼ dane nie moÅ¼emy przetworzyÄ‡ do jakiejÅ› postaci tabelarzycnzej.\nPrzykÅ‚adem moÅ¼e byÄ‡ dÅºwiÄ™k, obrazczy tekst. PoszczegÃ³lne litery, czÄ™stotliwoÅ›ci~czy piksele nie niosÄ… ze sobÄ… Å¼adnych informacji. Nie tworzÄ… osobnych cech, co jest kluczowe dla odrÃ³Å¼nienia ich od danych ustrukturyzowanych.\n\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych (K2A_W02, K2A_W04, O2_W04, O2_W07)"
  },
  {
    "objectID": "old_lectures/wyklad1S.html#ÅºrÃ³dÅ‚a-danych",
    "href": "old_lectures/wyklad1S.html#ÅºrÃ³dÅ‚a-danych",
    "title": "WykÅ‚ad 1",
    "section": "Å¹rÃ³dÅ‚a danych",
    "text": "Å¹rÃ³dÅ‚a danych\nDo trzech najwiÄ™kszych â€œgeneratorÃ³wâ€ danych naleÅ¼Ä…:\n\ndane spoÅ‚eczne w formie tekstÃ³w (tweety, wpisy w~portalach spoÅ‚ecznoÅ›ciowych, komentarze), zdjÄ™Ä‡ czy plikÃ³w wideo. Przydatne do problemÃ³w biznesowych realizujÄ…cych ocenÄ™ zachowaÅ„ i nastrojÃ³w konsumentÃ³w w analizach marketingowych.\nIoT: dane pochodzÄ…ce z czujnikÃ³w, czy teÅ¼ logi dziaÅ‚ania urzÄ…dzeÅ„ i uÅ¼ytkownikÃ³w (np. na stronie www).\nDane transakcyjne: czyli ogÃ³lnie to co w kaÅ¼dej chwili generowane jest jako transakcje pojawiajÄ…ce siÄ™ zarÃ³wno w trybie online jak i w trybie offline.\n\n\nRzeczywisty proces generowania danych\nDane generowane sÄ… w postaci nieograniczonej - pojawiajÄ… siÄ™ na skutek ciÄ…gÅ‚ych dziaÅ‚aÅ„ systemÃ³w. W swoim telefonie wygenerowaÅ‚eÅ› dziÅ› (a nawet na tych zajÄ™ciach!) wiele danych. Czy na nastÄ™pnych zajÄ™ciach lub tez jutro nie bÄ™dziesz ich generowaÅ‚?\nDane zawsze generowane sÄ… jako jakaÅ› forma strumienia danych.\nSystemy obsÅ‚ugujÄ…ce strumienie danych: - hurtownie danych - systemy monitorujÄ…ce dziaÅ‚ania urzÄ…dzeÅ„ (IoT) - systemy transakcyjne - systemy analityczne stron www - reklamy on-line - media spoÅ‚ecznoÅ›ciowe - systemy logowania - â€¦.\n\nfirma to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ danych. Zobacz\n\nW przetwarzaniu wsadowym ÅºrÃ³dÅ‚em (ale i wynikiem przetwarzania) danych jest plik. Jest on zapisywany raz i moÅ¼na siÄ™ do niego odwoÅ‚aÄ‡ (moÅ¼e na nim dziaÅ‚aÄ‡ wiele procesÃ³w - zadaÅ„). Nazwa pliku to element identyfikujÄ…cy zbiÃ³r rekordÃ³w.\nW przypadku strumienia zdarzenie jest generowane tylko raz przez tzw. producenta (zwanego teÅ¼ nadawcÄ… lub dostawcÄ…). PowstaÅ‚e zdarzenie przetwarzane moÅ¼e byÄ‡ przez wielu tzw. konsumentÃ³w (odbiorcÃ³w). Zdarzenia strumieniowe grupowane sÄ… w tzw. tematy (ang. topics)."
  },
  {
    "objectID": "old_lectures/wyklad1S.html#big-data",
    "href": "old_lectures/wyklad1S.html#big-data",
    "title": "WykÅ‚ad 1",
    "section": "Big Data",
    "text": "Big Data\n\n,,Big Data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so every one claims they are doing it.â€™â€™ â€” Dan Ariely, Professor of Psychology and Behavioral Economics, Duke University\n\n\none, two, â€¦ four V\n\nVolume (ObjÄ™toÅ›Ä‡) - rozmiar danych produkowanych na caÅ‚ym Å›wiecie przyrasta w tempie wykÅ‚adniczym.\nVelocity (SzybkoÅ›Ä‡) - tempo produkowania danych, szybkoÅ›ci ich przesyÅ‚ania i przetwarzania.\nVariety (ZrÃ³Å¼nicowanie) - tradycyjne dane kojarzÄ… siÄ™ nam z postaciÄ… alfanumerycznÄ… zÅ‚oÅ¼onÄ… z liter i cyfr. Obecnie mamy do dyspozycji obrazy, dÅºwiÄ™ki, pliki wideo, strumienie danych z IoT\nVeracity (WiarygodnoÅ›Ä‡) - Czy dane sÄ… kompletne i poprawne? Czy obiektywnie odzwierciedlajÄ… rzeczywistoÅ›Ä‡? Czy sÄ… podstawÄ… do podejmowania decyzji?\nValue - The value that the data actually holds. In the end, itâ€™s all about cost and benefits.\n\n\nCelem obliczeÅ„ nie sÄ… liczby, lecz ich zrozumienie R.W. Hamming 1962."
  },
  {
    "objectID": "old_lectures/wyklad1S.html#modele-przetwarzania-danych",
    "href": "old_lectures/wyklad1S.html#modele-przetwarzania-danych",
    "title": "WykÅ‚ad 1",
    "section": "Modele przetwarzania danych",
    "text": "Modele przetwarzania danych\nDane w biznesie przetwarzane sÄ… praktycznie od zawsze. W ciÄ…gu ostatnich dziesiÄ™cioleci iloÅ›Ä‡ przetwarzanych danych systematycznie roÅ›nie co wpÅ‚ywa na proces przygotowania i przetwarzania danych.\n\nTrochÄ™ historii\n\nLata 60-te : Kolekcje danych, bazy danych\nLata 70-te : Relacyjne modele danych i ich implementacja w systemach OLTP\n1975 : Pierwsze komputery osobiste\nLata 80-te : Zaawansowane modele danych, extended-relational, objective oriented, aplikacyjno-zorientowane itp.\n1983 : PoczÄ…tek internetu\nLata 90-te : Data mining, hurtownie danych, systemy OLAP\nPÃ³Åºniej : NoSQL, Hadoop, SPARK, data lake\n2002 : AWS , 2005: Hadoop, Cloud computing\n\nWiÄ™kszoÅ›Ä‡ danych przechowywana jest w bazach lub hurtowniach danych. Standardowo dostÄ™p do danych sprowadza siÄ™ najczÄ™Å›ciej do realizacji zapytaÅ„ poprzez aplikacjÄ™.\nSposÃ³b wykorzystania i realizacji procesu dostÄ™pu do bazy danych nazywamy modelem przetwarzania. NajczÄ™Å›ciej uÅ¼ywane sÄ… dwie implementacje:\n\n\nModel Tradycyjny\nModel tradycyjny - przetwarzanie transakcyjne w trybie on-line, OLTP (on-line transaction processing). Åšwietnie sprawdza siÄ™ w przypadku obsÅ‚ugi bieÅ¼Ä…cej np. obsÅ‚uga klienta, rejestr zamÃ³wieÅ„, obsÅ‚uga sprzedaÅ¼y itp. Wykorzystywany w systemach Enterprise Resource Planning (ERP) Systems, Customer Relationship Management (CRM) software, and web-based applications.\n\nModel ten dostarcza efektywnych rozwiÄ…zaÅ„ m.in do:\n\nefektywnego i bezpiecznego przechowywania danych,\ntransakcyjnego odtwarzanie danych po awarii,\noptymalizacji dostÄ™pu do danych,\nzarzÄ…dzania wspÃ³Å‚bieÅ¼noÅ›ciÄ…,\nprzetwarzania zdarzeÅ„ -&gt; odczyt -&gt; zapis\n\nCo w przypadku gdy mamy do czynienia z:\n\nagregacjami danych z wielu systemÃ³w (np. dla wielu sklepÃ³w),\nraportowanie i podsumowania danych,\noptymalizacja zÅ‚oÅ¼onych zapytaÅ„,\nwspomaganie decyzji biznesowych.\n\nBadania nad tego typu zagadnieniami doprowadziÅ‚y do sformuÅ‚owania nowego modelu przetwarzania danych oraz nowego typu baz danych - Hurtownie Danych (Data warehouse).\n\n\nModel OLAP\nPrzetwarzanie analityczne on-line OLAP (on-line analytic processing).\nWspieranie procesÃ³w analizy i dostarczanie narzÄ™dzi umoÅ¼liwiajÄ…cych analizÄ™ wielowymiarowÄ… (czas, miejsce, produkt).\nProces zrzucania danych z rÃ³Å¼nych systemÃ³w do jednej bazy nazywamy Extract-Transform-Load (ETL) (normalizacja i encoding and schema transaction).\nAnaliza danych z hurtowni to przede wszystkim obliczanie agregatÃ³w (podsumowaÅ„) dotyczÄ…cych wymiarÃ³w hurtowni. Proces ten jest caÅ‚kowicie sterowany przez uÅ¼ytkownika.\nPrzykÅ‚ad\nZaÅ‚Ã³Å¼my, Å¼e mamy dostÄ™p do hurtowni danych gdzie przechowywane sÄ… informacje dotyczÄ…ce sprzedaÅ¼y produktÃ³w w supermarkecie. Jak przeanalizowaÄ‡ zapytania:\n\nJaka jest Å‚Ä…czna sprzedaÅ¼ produktÃ³w w kolejnych kwartaÅ‚ach, miesiÄ…cach, tygodniach ?\nJaka jest sprzedaÅ¼ produktÃ³w z podziaÅ‚em na rodzaje produktÃ³w ?\nJaka jest sprzedaÅ¼ produktÃ³w z podziaÅ‚em na oddziaÅ‚y supermarketu ?\n\nOdpowiedzi na te pytania pozwalajÄ… okreÅ›liÄ‡ wÄ…skie gardÅ‚a sprzedaÅ¼y produktÃ³w przynoszÄ…cych deficyt, zaplanowaÄ‡ zapasy w magazynach czy porÃ³wnaÄ‡ sprzedaÅ¼ rÃ³Å¼nych grup w rÃ³Å¼nych oddziaÅ‚ach supermarketu.\nW ramach Hurtowni Danych najczÄ™Å›ciej wykonuje siÄ™ dwa rodzaje zapytaÅ„(oba w trybie batchowym): 1. Wykonywane okresowo w czasie zapytania raportowe obliczajÄ…ce biznesowe statystyki 2. Wykonywane ad-hoc zapytania wspomagajÄ…ce krytyczne decyzje biznesowe."
  },
  {
    "objectID": "old_lectures/wyklad1S.html#ÅºrÃ³dÅ‚a-danych-przesyÅ‚anych-strumieniowo-obejmujÄ…",
    "href": "old_lectures/wyklad1S.html#ÅºrÃ³dÅ‚a-danych-przesyÅ‚anych-strumieniowo-obejmujÄ…",
    "title": "WykÅ‚ad 1",
    "section": "Å¹rÃ³dÅ‚a danych przesyÅ‚anych strumieniowo obejmujÄ…:",
    "text": "Å¹rÃ³dÅ‚a danych przesyÅ‚anych strumieniowo obejmujÄ…:\n\nczujniki sprzÄ™tu,\nstrumienie klikniÄ™Ä‡,\nÅ›ledzenie lokalizacji\ninterackcja z uÅ¼ytkownikiem: co robiÄ… uÅ¼ytkownicy Twojej witryny?\nkanaÅ‚y mediÃ³w spoÅ‚ecznoÅ›ciowych,\nnotowania gieÅ‚dowe,\naktywnoÅ›Ä‡ w aplikacjach\ninne.\n\nFirmy wykorzystujÄ… analitykÄ™ strumieniowÄ… do odkrywania i interpretowania wzorcÃ³w, tworzenia wizualizacji, przekazywania spostrzeÅ¼eÅ„ i alertÃ³w oraz uruchamiania procesÃ³w w czasie rzeczywistym lub zbliÅ¼onym do rzeczywistego.\n\nAnaliza danych w czasie rzeczywistym a przetwarzanie strumienia zdarzeÅ„\nÅatwo jest poÅ‚Ä…czyÄ‡ analizÄ™ w czasie rzeczywistym i analizÄ™ strumieniowÄ… (lub przetwarzanie strumienia zdarzeÅ„). Ale chociaÅ¼ technologie analizy strumieniowej mogÄ… umoÅ¼liwiaÄ‡ analizÄ™ w czasie rzeczywistym, to nie to samo!\nAnaliza strumieniowa polega na przetwarzaniu danych w ruchu. Analityka w czasie rzeczywistym to dowolna metoda przetwarzania danych, ktÃ³ra skutkuje okresem opÃ³Åºnienia okreÅ›lanym jako â€w czasie rzeczywistymâ€.\nZazwyczaj systemy analizy czasu rzeczywistego sÄ… definiowane jako twarde i miÄ™kkie systemy czasu rzeczywistego. Niedotrzymanie terminu w twardych systemach czasu rzeczywistego, takich jak samolot, jest katastrofalne, a w miÄ™kkich systemach czasu rzeczywistego, takich jak stacja pogodowa, niedotrzymanie terminÃ³w moÅ¼e prowadziÄ‡ do bezuÅ¼ytecznych danych.\nPonadto, podczas gdy analiza strumieniowa implikuje istnienie architektury strumieniowej, analiza w czasie rzeczywistym nie implikuje Å¼adnej konkretnej architektury.\nWszystko, co implikuje analityka w czasie rzeczywistym, polega na tym, Å¼e tworzenie i przetwarzanie danych odbywa siÄ™ w dowolnym czasie, ktÃ³ry firma definiuje jako â€w czasie rzeczywistymâ€."
  },
  {
    "objectID": "old_lectures/wyklad1S.html#uzasadnienie-biznesowe",
    "href": "old_lectures/wyklad1S.html#uzasadnienie-biznesowe",
    "title": "WykÅ‚ad 1",
    "section": "Uzasadnienie biznesowe",
    "text": "Uzasadnienie biznesowe\nAnalityka sÅ‚uÅ¼y do znajdowania znaczÄ…cych wzorcÃ³w w danych i odkrywania nowej wiedzy. Dotyczy to zarÃ³wno transmisji strumieniowych, jak i tradycyjnych analiz.\nAle w dzisiejszym Å›wiecie natura â€znajdowania sensownych wzorcÃ³w w danychâ€ ulegÅ‚a zmianie, poniewaÅ¼ zmieniÅ‚ siÄ™ charakter danych. SzybkoÅ›Ä‡, objÄ™toÅ›Ä‡ i rodzaje danych eksplodowaÅ‚y.\nTwitter produkuje ponad 500 milionÃ³w tweetÃ³w dziennie. IDC przewiduje, Å¼e do 2025 roku urzÄ…dzenia Internetu rzeczy (IoT) bÄ™dÄ… w stanie wygenerowaÄ‡ 79,4 zettabajtÃ³w (ZB) danych. I te trendy nie wykazujÄ… oznak spowolnienia.\nBiorÄ…c pod uwagÄ™ nowy charakter danych, gÅ‚Ã³wnÄ… zaletÄ… analizy strumieniowej jest to, Å¼e pomaga ona firmom znajdowaÄ‡ znaczÄ…ce wzorce w danych i odkrywaÄ‡ nowÄ… wiedzÄ™ ,,w czasie rzeczywistymâ€ lub zbliÅ¼onym do rzeczywistego.\n\nktÃ³ry pojazd firmowej floty ma prawie pusty bak i~gdzie wysÅ‚aÄ‡ prowadzÄ…cego pojazd do tankowania.\nKtÃ³ry pojazd floty zuÅ¼ywa najwiÄ™cej paliwa i~dlaczego?\nKtÃ³re urzÄ…dzenia w~zakÅ‚adzie czy fabryce mogÄ… ulec awarii w~ciÄ…gu najbliÅ¼szych dni?\nJakie czÄ™Å›ci zamienne trzeba bÄ™dzie wymieniÄ‡ iwktÃ³rych maszynach w~najbliÅ¼szym czasie ?\nIlu klientÃ³w aktualnie robi zakupy w~sklepie i~czy moÅ¼na im coÅ› zaproponowaÄ‡ ?\nCzy klient dzwoni w~celu zerwania umowy ?\ni wiele wiele innych.\n\n8 najlepszych przykÅ‚adÃ³w\nBiznesowe zastosowania"
  },
  {
    "objectID": "old_lectures/wyklad1S.html#definicje",
    "href": "old_lectures/wyklad1S.html#definicje",
    "title": "WykÅ‚ad 1",
    "section": "Definicje",
    "text": "Definicje\nZapoznaj siÄ™ z tematem danych strumieniowych\n\nDefinicja 1 - Zdarzenie czyli wszystko co moÅ¼emy zaobserwowaÄ‡ w pewnej chwili czasu. Definicja 2 - W przypadku danych zdarzenie rozumiemy jako niezmienialny rekord w strumieniu danych zakodowany jako JSON, XML, CSV lub binarnie. Definicja 3 - CiÄ…gÅ‚y strumieÅ„ zdarzeÅ„ to nieskoÅ„czony zbiÃ³r pojedynczych zdarzeÅ„ uporzÄ…dkowanych w czasie np. logi z urzÄ…dzenia.\n\n\nPrzedsiÄ™biorstwo to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„.\n\n\nDefinicja 4 - StrumieÅ„ danych to dane tworzone przyrostowo w czasie, generowane ze statycznych danych (baza danych, czytanie lini z pliku) bÄ…dÅº w sposÃ³b dynamiczny (logi, sensory, funkcje).\n\nAnalityka strumieniowa (ang. stream analytics) nazywana jest rÃ³wnieÅ¼ przetwarzaniem strumieniowym zdarzen (ang. event stream processing) - przetwarzanie duÅ¼ej iloÅ›ci danych juÅ¼ na etapie ich generowania.\nGenerowane sÄ… jako bezpoÅ›redni skutek dziaÅ‚ania.\nNiezaleÅ¼nie od zastosowanej technologi wszystkie dane powstajÄ… jako ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„ (dziaÅ‚ania uÅ¼ytkownikÃ³w na stronie www, logi systemowe, pomiary z sensorÃ³w)."
  },
  {
    "objectID": "old_lectures/wyklad1S.html#aplikacje-dla-strumieniowania-danych",
    "href": "old_lectures/wyklad1S.html#aplikacje-dla-strumieniowania-danych",
    "title": "WykÅ‚ad 1",
    "section": "Aplikacje dla strumieniowania danych",
    "text": "Aplikacje dla strumieniowania danych\nAplikacja przetwarzajÄ…ca strumieÅ„ zdarzeÅ„ powinna umoÅ¼liwiaÄ‡ przetworzenie i zapisanie zdarzenia oraz dostÄ™p (w tym samym czasie) do innych danych tak by mÃ³c dane zdarzenie przetworzyÄ‡ (wykonaÄ‡ na nim dowolne przeliczenie) i zapisaÄ‡ jako stan lokalny. Stan ten moÅ¼e byÄ‡ zapisywany w wielu miejscach np. zmienne w programie, pliki lokalne, wew i zew bazy danych. JednÄ… z najbardziej znanych aplikacji tego typu jest Apache Kafka, ktÃ³rÄ… moÅ¼na Å‚Ä…czyÄ‡ np. z Apache Spark bÄ…dÅº Apache Flink.\nPorÃ³wnanie z aplikacjÄ… w trybie batch"
  },
  {
    "objectID": "info.html",
    "href": "info.html",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3.11 -m venv &lt;name of env&gt;\n# dla linux i mac os\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n# dla windows \n# &lt;name of env&gt;\\Scripts\\activate\n(venv)$ \nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#python",
    "href": "info.html#python",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3.11 -m venv &lt;name of env&gt;\n# dla linux i mac os\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n# dla windows \n# &lt;name of env&gt;\\Scripts\\activate\n(venv)$ \nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "href": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z serwisu GitHub",
    "text": "Zacznij korzystaÄ‡ z serwisu GitHub\n\n\n\nTekst na podstawie strony jak korzystaÄ‡ z serwisu github\nPracujÄ…c nad projektem np. praca magisterska, (samodzielnie lub w zespole) czÄ™sto potrzebujesz sprawdziÄ‡ jakie zmiany, kiedy i przez kogo zostaÅ‚y wprowadzone do projektu. W zadaniu tym Å›wietnie sprawdza siÄ™ system kontroli wersji czyli GIT.\nGit moÅ¼esz pobraÄ‡ i zainstalowaÄ‡ jak zwykÅ‚y program na dowolnym komputerze. Jednak najczÄ™Å›ciej (maÅ‚e projekty) korzysta siÄ™ z serwisÃ³w z jakimÅ› systemem git. Jednym z najbardziej rozpoznawanych jest GitHub dziÄ™ki ktÃ³remu moÅ¼esz korzystaÄ‡ z systemu git bez jego instalacji na swoim komputerze.\nW darmowej wersji serwisu GitHub swoje pliki moÅ¼esz przechowywaÄ‡ w publicznych (dostÄ™p majÄ… wszyscy) repozytoriach.\nSkupimy siÄ™ wyÅ‚Ä…cznie na darmowej wersji serwisu GitHub.\ngit --version\n\nStruktura GitHuba\nNa najwyÅ¼szym poziomie znajdujÄ… siÄ™ konta indywidualne np http://github.com/sebkaz, bÄ…dÅº zakÅ‚adane przez organizacje. UÅ¼ytkownicy indywidualni mogÄ… tworzyÄ‡ repozytoria publiczne (public ) bÄ…dÅº prywatne (private).\nJeden plik nie powinien przekraczaÄ‡ 100 MB.\nRepo (skrÃ³t do repozytorium) tworzymy za pomocÄ… Create a new repository. KaÅ¼de repo powinno mieÄ‡ swojÄ… indywidualnÄ… nazwÄ™.\n\n\nBranche\nGÅ‚Ã³wna (tworzona domyÅ›lnie) gaÅ‚Ä…Åº rapozytorium ma nazwÄ™ master.\n\n\nNajwaÅ¼niejsze polecnia do zapamiÄ™tania\n\nÅ›ciÄ…ganie repozytorium z sieci\n\ngit clone https://adres_repo.git\n\nW przypadku githuba moÅ¼esz pobraÄ‡ repozytorium jako plik zip.\n\n\nTworzenie repozytorium dla lokalnego katalogu\n\n# tworzenie nowego katalogu\nmkdir datamining\n# przejÅ›cie do katalogu\ncd datamining\n# inicjalizacja repozytorium w katalogu\ngit init\n# powinien pojawiÄ‡ siÄ™ ukryty katalog .git\n# dodajmy plik\necho \"Info \" &gt;&gt; README.md\n\nPoÅ‚Ä…cz lokalne repozytorium z kontem na githubie\n\ngit remote add origin https://github.com/&lt;twojGit&gt;/nazwa.git\n\nObsÅ‚uga w 3 krokach\n\n# sprawdÅº zmiany jakie zostaÅ‚y dokonane\ngit status\n# 1. dodaj wszystkie zmiany\ngit add .\n# 2. zapisz bierzÄ…cy stan wraz z informacjÄ… co zrobiÅ‚eÅ›\ngit commit -m \" opis \"\n# 3. potem juÅ¼ zostaje tylko\ngit push origin master\nWarto obejrzeÄ‡ Youtube course.\nCiekawe i proste wprowadzenie mozna znaleÅºÄ‡ tutaj"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "href": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z Dockera",
    "text": "Zacznij korzystaÄ‡ z Dockera\n\n\n\nW celu pobrania oprogramowania docker na swÃ³j system przejdÅº do strony.\nJeÅ¼li wszystko zainstalowaÅ‚o siÄ™ prawidÅ‚owo wykonaj nastÄ™pujÄ…ce polecenia:\n\nSprawdÅº zainstalowanÄ… wersjÄ™\n\ndocker --version\n\nÅšciÄ…gnij i uruchom obraz Hello World i\n\ndocker run hello-world\n\nPrzeglÄ…d Å›ciÄ…gnietych obrazÃ³w:\n\ndocker image ls\n\ndocker images\n\nPrzeglÄ…d uruchomionych kontenerÃ³w:\n\ndocker ps \n\ndocker ps -all\n\nZatrzymanie uruchomionego kontenera:\n\ndocker stop &lt;CONTAINER ID&gt;\n\nUsuniÄ™cie kontenera\n\ndocker rm -f &lt;CONTAINER ID&gt;\nPolecam rÃ³wnieÅ¼ krÃ³tkie intro"
  },
  {
    "objectID": "wyklad2.html",
    "href": "wyklad2.html",
    "title": "WykÅ‚ad 2",
    "section": "",
    "text": "â³ Czas trwania: 1,5h ğŸ¯ Cel wykÅ‚adu\nzrozumienie, jak dane ewoluowaÅ‚y w rÃ³Å¼nych branÅ¼ach i jakie narzÄ™dzia sÄ… dziÅ› wykorzystywane do ich analizy.\nW tym wstÄ™pie przedstawimy ewolucjÄ™ analizy danych, pokazujÄ…c, jak zmieniaÅ‚y siÄ™ technologie i podejÅ›cia do przetwarzania danych na przestrzeni lat. Rozpoczniemy od klasycznych struktur tabelarycznych, przez bardziej zaawansowane modele grafowe i tekstowe, aÅ¼ po nowoczesne podejÅ›cie do strumieniowego przetwarzania danych."
  },
  {
    "objectID": "wyklad2.html#zmiany-w-analizie-danych",
    "href": "wyklad2.html#zmiany-w-analizie-danych",
    "title": "WykÅ‚ad 2",
    "section": "Zmiany w analizie danych:",
    "text": "Zmiany w analizie danych:\n\nDane tabelaryczne (tabele SQL):\nPoczÄ…tkowo dane byÅ‚y przechowywane w postaci tabel, gdzie kaÅ¼da tabela zawieraÅ‚a zorganizowane informacje w kolumnach i wierszach (np. bazy danych SQL). Modele takie doskonale nadawaÅ‚y siÄ™ do danych ustrukturyzowanych.\n\n\nDane grafowe:\nWraz z rozwojem potrzeb biznesowych pojawiÅ‚y siÄ™ dane grafowe, w ktÃ³rych relacje miÄ™dzy obiektami (np. uÅ¼ytkownikami, produktami) sÄ… reprezentowane jako wierzchoÅ‚ki i krawÄ™dzie grafu. PrzykÅ‚ady takich danych to sieci spoÅ‚ecznoÅ›ciowe, linki internetowe czy zaleÅ¼noÅ›ci miÄ™dzy produktami.\n\n\nDane tekstowe:\nKolejnym etapem byÅ‚a analiza danych tekstowych, ktÃ³re zaczÄ™Å‚y odgrywaÄ‡ istotnÄ… rolÄ™ w analizie danych z mediÃ³w spoÅ‚ecznoÅ›ciowych, e-maili, forÃ³w czy opinii. Technologie takie jak NLP (przetwarzanie jÄ™zyka naturalnego) pozwalajÄ… wydobywaÄ‡ sens z nieustrukturyzowanego tekstu.\n\n\nDane strumieniowe:\nObecnie najbardziej dynamicznie rozwija siÄ™ analiza danych strumieniowych, gdzie dane sÄ… analizowane na bieÅ¼Ä…co, w miarÄ™ ich napÅ‚ywania. PrzykÅ‚adem takiego podejÅ›cia jest monitorowanie zdarzeÅ„ w czasie rzeczywistym, np. transakcje finansowe, analiza social media, detekcja oszustw."
  },
  {
    "objectID": "wyklad2.html#popularne-narzÄ™dzia-analiz-danych",
    "href": "wyklad2.html#popularne-narzÄ™dzia-analiz-danych",
    "title": "WykÅ‚ad 2",
    "section": "Popularne narzÄ™dzia analiz danych:",
    "text": "Popularne narzÄ™dzia analiz danych:\n\nSQL:\nTradycyjne bazy danych SQL sÄ… idealne do pracy z danymi ustrukturyzowanymi, ktÃ³re wymagajÄ… Å›cisÅ‚ej struktury tabel (np. dane o transakcjach, klientach). SQL jest standardem w analizie takich danych, ale nie jest wystarczajÄ…cy w przypadku pracy z duÅ¼ymi iloÅ›ciami danych nieustrukturyzowanych.\n\n\nNoSQL:\nBazy danych NoSQL, takie jak MongoDB, Cassandra, pozwalajÄ… na bardziej elastyczne podejÅ›cie do danych, ktÃ³re mogÄ… przybieraÄ‡ rÃ³Å¼ne formy (np. dokumenty JSON, dane z sensorÃ³w, obrazy). NoSQL Å›wietnie sprawdza siÄ™ w przypadku danych, ktÃ³re nie pasujÄ… do tradycyjnych struktur tabelarycznych.\n\n\nData Lake:\nData Lake to systemy przechowywania ogromnych zbiorÃ³w danych, zarÃ³wno ustrukturyzowanych, jak i nieustrukturyzowanych. DziÄ™ki Data Lake organizacje mogÄ… przechowywaÄ‡ dane w pierwotnej formie i analizowaÄ‡ je pÃ³Åºniej w miarÄ™ potrzeb, bez potrzeby wczeÅ›niejszego przetwarzania. ### Apache Kafka: Kafka to system przetwarzania strumieniowego, ktÃ³ry umoÅ¼liwia zbieranie, przechowywanie i przetwarzanie danych w czasie rzeczywistym. Jest szeroko wykorzystywany w aplikacjach wymagajÄ…cych szybkiej reakcji na dane napÅ‚ywajÄ…ce w czasie rzeczywistym. ### Apache Flink: Apache Flink to narzÄ™dzie do przetwarzania strumieniowego, ktÃ³re umoÅ¼liwia analizowanie danych w czasie rzeczywistym z minimalnym opÃ³Åºnieniem. W przeciwieÅ„stwie do Kafki, Flink nie tylko zbiera dane, ale takÅ¼e je przetwarza, co jest szczegÃ³lnie przydatne w analizach zÅ‚oÅ¼onych.\n\n\nPrzykÅ‚ad: Jak Netflix analizuje dane w czasie rzeczywistym?\nNetflix to doskonaÅ‚y przykÅ‚ad firmy, ktÃ³ra z powodzeniem wykorzystuje dane strumieniowe w celu dostarczania uÅ¼ytkownikom spersonalizowanych rekomendacji i analizowania ich zachowaÅ„. DziÄ™ki technologii strumieniowej, Netflix monitoruje dziaÅ‚ania swoich uÅ¼ytkownikÃ³w (co oglÄ…dajÄ…, jakie treÅ›ci przewijajÄ…, jak dÅ‚ugo oglÄ…dajÄ…), analizujÄ…c te dane w czasie rzeczywistym. Na podstawie tej analizy Netflix jest w stanie dostarczaÄ‡ rekomendacje filmÃ³w i seriali w czasie rzeczywistym, dostosowujÄ…c je do zmieniajÄ…cych siÄ™ preferencji uÅ¼ytkownika."
  },
  {
    "objectID": "wyklad2.html#przykÅ‚ad-strumieniowego-przetwarzania-w-netflix",
    "href": "wyklad2.html#przykÅ‚ad-strumieniowego-przetwarzania-w-netflix",
    "title": "WykÅ‚ad 2",
    "section": "PrzykÅ‚ad strumieniowego przetwarzania w Netflix:",
    "text": "PrzykÅ‚ad strumieniowego przetwarzania w Netflix:\nKiedy uÅ¼ytkownik zaczyna oglÄ…daÄ‡ film, system Å›ledzi jego reakcje (np. przerwanie filmu, przewijanie) i dostosowuje rekomendacje do jego preferencji. Takie dane mogÄ… byÄ‡ przesyÅ‚ane do systemu analitycznego za pomocÄ… narzÄ™dzi takich jak Apache Kafka i przetwarzane na Å¼ywo w Apache Flink."
  },
  {
    "objectID": "wyklad2.html#podsumowanie",
    "href": "wyklad2.html#podsumowanie",
    "title": "WykÅ‚ad 2",
    "section": "Podsumowanie",
    "text": "Podsumowanie\nDziÄ™ki ewolucji technologii, analiza danych przeszÅ‚a dÅ‚ugÄ… drogÄ™, od prostych tabel SQL, przez zÅ‚oÅ¼one dane grafowe i tekstowe, aÅ¼ do analiz strumieniowych. Zrozumienie rÃ³Å¼nic miÄ™dzy tymi podejÅ›ciami pozwala na lepsze dobieranie narzÄ™dzi do odpowiednich typÃ³w analiz, w tym wykorzystania nowoczesnych systemÃ³w przetwarzania danych w czasie rzeczywistym, takich jak Kafka i Flink."
  },
  {
    "objectID": "wyklad2.html#ewolucja-analizy-danych-od-struktur-tabelarycznych-do-strumieni",
    "href": "wyklad2.html#ewolucja-analizy-danych-od-struktur-tabelarycznych-do-strumieni",
    "title": "WykÅ‚ad 2",
    "section": "Ewolucja analizy danych: Od struktur tabelarycznych do strumieni",
    "text": "Ewolucja analizy danych: Od struktur tabelarycznych do strumieni\nRozwÃ³j technologii informatycznych stworzyÅ‚ nowe moÅ¼liwoÅ›ci przetwarzania ogromnych iloÅ›ci danych, zarÃ³wno ustrukturyzowanych, jak i nieustrukturyzowanych. W ciÄ…gu ostatnich kilku dekad obserwujemy wzrost dostÄ™pnych danych oraz technologii do ich przechowywania i analizy. DziÄ™ki temu dane staÅ‚y siÄ™ jednym z najcenniejszych zasobÃ³w wspÃ³Å‚czesnych organizacji."
  },
  {
    "objectID": "wyklad2.html#dane-ustrukturyzowane",
    "href": "wyklad2.html#dane-ustrukturyzowane",
    "title": "WykÅ‚ad 2",
    "section": "Dane ustrukturyzowane",
    "text": "Dane ustrukturyzowane\nDane ustrukturyzowane to dane, ktÃ³re sÄ… przechowywane w sposÃ³b zorganizowany i jednoznacznie okreÅ›lony. PrzykÅ‚adami takich danych sÄ… tabele w bazach SQL, w ktÃ³rych kaÅ¼da kolumna reprezentuje jednÄ… cechÄ™, a kaÅ¼dy wiersz to pojedynczy rekord. Tego typu dane sÄ… najczÄ™Å›ciej wykorzystywane w klasycznych algorytmach uczenia maszynowego, takich jak regresja logistyczna, XGBoost czy modele klasyfikacji.\nPrzykÅ‚ad: ZaÅ‚Ã³Å¼my, Å¼e mamy tabelÄ™, w ktÃ³rej kaÅ¼da linia przedstawia dane o kliencie: jego pÅ‚eÄ‡, wzrost, iloÅ›Ä‡ kredytÃ³w itd.\n\ndane_klientow = {\"sex\":[\"m\",\"f\",\"m\",\"m\",\"f\"],\n \"height\":[160, 172, 158, 174, 192],\n \"credits\":[0,0,1,3,1]\n }\n\ndf = pd.DataFrame(dane_klientow)\nprint(df)\n\n  sex  height  credits\n0   m     160        0\n1   f     172        0\n2   m     158        1\n3   m     174        3\n4   f     192        1\n\n\nNa tej podstawie moÅ¼emy przewidywaÄ‡ prawdopodobieÅ„stwo spÅ‚aty kredytu (regresja logistyczna). Takie przewidywanie rÃ³wnieÅ¼ oznaczane jest jako cecha (ang. target).\n\ndf['target'] = [0,1,1,0,0]\nprint(df)\n\n  sex  height  credits  target\n0   m     160        0       0\n1   f     172        0       1\n2   m     158        1       1\n3   m     174        3       0\n4   f     192        1       0"
  },
  {
    "objectID": "wyklad2.html#dane-nieustrukturyzowane",
    "href": "wyklad2.html#dane-nieustrukturyzowane",
    "title": "WykÅ‚ad 2",
    "section": "Dane nieustrukturyzowane",
    "text": "Dane nieustrukturyzowane\nDane nieustrukturyzowane to dane, ktÃ³re nie majÄ… okreÅ›lonej, tabelarycznej formy. NaleÅ¼Ä… do nich obrazy, dÅºwiÄ™ki, wideo i tekst. ChoÄ‡ te dane wydajÄ… siÄ™ chaotyczne, sÄ… one rÃ³wnieÅ¼ cennym ÅºrÃ³dÅ‚em informacji, ktÃ³re moÅ¼na przetwarzaÄ‡ za pomocÄ… odpowiednich algorytmÃ³w.\nPrzykÅ‚ad: Analiza obrazÃ³w (np. weryfikacja, czy zdjÄ™cie przedstawia psa czy kota) lub analizy tekstu (np. sentymentu w tweetach) sÄ… przykÅ‚adami pracy z danymi nieustrukturyzowanymi.\n\nJakie wyzwania niesie analiza danych w rÃ³Å¼nych formach?\n\nZwiÄ™kszajÄ…cy siÄ™ wolumen danych, a takÅ¼e ich rÃ³Å¼norodnoÅ›Ä‡, stawia przed nami kolejne wyzwania zwiÄ…zane z przetwarzaniem i analizowaniem tych danych.\n\nKluczowe pytanie brzmi: jak efektywnie przetwarzaÄ‡ ogromne iloÅ›ci danych w czasie rzeczywistym?"
  },
  {
    "objectID": "wyklad2.html#przetwarzanie-wsadowe-vs.-przetwarzanie-strumieniowe",
    "href": "wyklad2.html#przetwarzanie-wsadowe-vs.-przetwarzanie-strumieniowe",
    "title": "WykÅ‚ad 2",
    "section": "Przetwarzanie wsadowe vs.Â przetwarzanie strumieniowe",
    "text": "Przetwarzanie wsadowe vs.Â przetwarzanie strumieniowe\nW tradycyjnych systemach analizy danych, takich jak bazy danych SQL, przetwarzanie danych odbywa siÄ™ w trybie wsadowym (batch processing). Oznacza to, Å¼e dane sÄ… zbierane przez pewien czas, a nastÄ™pnie przetwarzane w partiach (np. raz dziennie, raz w tygodniu). Jest to podejÅ›cie, ktÃ³re Å›wietnie sprawdza siÄ™ w analizach historycznych i podejmowaniu decyzji na podstawie duÅ¼ych zbiorÃ³w danych.\n\nPrzykÅ‚ad batch processing:\nPrzetwarzanie wszystkich transakcji dokonanych przez klientÃ³w w ciÄ…gu dnia, aby na koÅ„cu dnia wyciÄ…gnÄ…Ä‡ raporty i wnioski dotyczÄ…ce aktywnoÅ›ci.\nNatomiast przetwarzanie strumieniowe (stream processing) pozwala na bieÅ¼Ä…ce analizowanie danych w momencie ich napÅ‚ywania. DziÄ™ki temu, dane mogÄ… byÄ‡ przetwarzane i analizowane w czasie rzeczywistym, co jest niezwykle waÅ¼ne w przypadku takich zastosowaÅ„ jak wykrywanie naduÅ¼yÄ‡ w czasie rzeczywistym, personalizowanie treÅ›ci czy monitorowanie urzÄ…dzeÅ„ IoT.\n\n\nPrzykÅ‚ad stream processing:\nSystem detekcji oszustw w kartach kredytowych, ktÃ³ry monitoruje transakcje na Å¼ywo, analizujÄ…c je pod kÄ…tem podejrzanych dziaÅ‚aÅ„ (np. przekroczenie typowego wzorca wydatkÃ³w).\nWspÃ³Å‚czesna analiza danych nie ogranicza siÄ™ do prostych zbiorÃ³w danych w formie tabelarycznej. Przechodzimy od danych ustrukturyzowanych do zaawansowanego przetwarzania strumieniowego, ktÃ³re pozwala na podejmowanie decyzji w czasie rzeczywistym. Zrozumienie rÃ³Å¼nicy miÄ™dzy przetwarzaniem wsadowym a strumieniowym to klucz do pracy z nowoczesnymi technologiami i narzÄ™dziami, ktÃ³re napÄ™dzajÄ… innowacje w wielu dziedzinach."
  },
  {
    "objectID": "wyklad2.html#ÅºrÃ³dÅ‚a-danych",
    "href": "wyklad2.html#ÅºrÃ³dÅ‚a-danych",
    "title": "WykÅ‚ad 2",
    "section": "Å¹rÃ³dÅ‚a danych",
    "text": "Å¹rÃ³dÅ‚a danych\nDo trzech najwiÄ™kszych â€œgeneratorÃ³wâ€ danych naleÅ¼Ä…:\n\ndane spoÅ‚eczne w formie tekstÃ³w (tweety, wpisy w portalach spoÅ‚ecznoÅ›ciowych, komentarze), zdjÄ™Ä‡ czy plikÃ³w wideo. Przydatne do problemÃ³w biznesowych realizujÄ…cych ocenÄ™ zachowaÅ„ i nastrojÃ³w konsumentÃ³w w analizach marketingowych.\nIoT: dane pochodzÄ…ce z czujnikÃ³w, czy teÅ¼ logi dziaÅ‚ania urzÄ…dzeÅ„ i uÅ¼ytkownikÃ³w (np. na stronie www).\ndane transakcyjne: czyli ogÃ³lnie to co w kaÅ¼dej chwili generowane jest jako transakcje pojawiajÄ…ce siÄ™ zarÃ³wno w trybie online jak i w trybie offline.\n\n\nRzeczywisty proces generowania danych\nDane generowane sÄ… w postaci nieograniczonej - pojawiajÄ… siÄ™ na skutek ciÄ…gÅ‚ych dziaÅ‚aÅ„ systemÃ³w. W swoim telefonie wygenerowaÅ‚eÅ› dziÅ› (a nawet na tych zajÄ™ciach!) wiele danych. Czy na nastÄ™pnych zajÄ™ciach lub tez jutro nie bÄ™dziesz ich generowaÅ‚?\nDane zawsze generowane sÄ… jako jakaÅ› forma strumienia danych.\nSystemy obsÅ‚ugujÄ…ce strumienie danych: - hurtownie danych - systemy monitorujÄ…ce dziaÅ‚ania urzÄ…dzeÅ„ (IoT) - systemy transakcyjne - systemy analityczne stron www - reklamy on-line - media spoÅ‚ecznoÅ›ciowe - systemy logowania - â€¦.\n\nfirma to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ danych. Zobacz\n\nW przetwarzaniu wsadowym ÅºrÃ³dÅ‚em (ale i wynikiem przetwarzania) danych jest plik. Jest on zapisywany raz i moÅ¼na siÄ™ do niego odwoÅ‚aÄ‡ (moÅ¼e na nim dziaÅ‚aÄ‡ wiele procesÃ³w - zadaÅ„). Nazwa pliku to element identyfikujÄ…cy zbiÃ³r rekordÃ³w.\nW przypadku strumienia zdarzenie jest generowane tylko raz przez tzw. producenta (zwanego teÅ¼ nadawcÄ… lub dostawcÄ…). PowstaÅ‚e zdarzenie przetwarzane moÅ¼e byÄ‡ przez wielu tzw. konsumentÃ³w (odbiorcÃ³w). Zdarzenia strumieniowe grupowane sÄ… w tzw. tematy (ang. topics)."
  },
  {
    "objectID": "wyklad2.html#architektura-systemÃ³w-real-time",
    "href": "wyklad2.html#architektura-systemÃ³w-real-time",
    "title": "WykÅ‚ad 2",
    "section": "Architektura systemÃ³w real-time",
    "text": "Architektura systemÃ³w real-time\nWykorzystanie systemÃ³w real-time (czas rzeczywisty) w analizie danych wymaga odpowiedniej architektury, ktÃ³ra bÄ™dzie mogÅ‚a szybko przetwarzaÄ‡ ogromne iloÅ›ci danych oraz reagowaÄ‡ na nie w czasie rzeczywistym. Architektura systemu real-time jest kluczowa, poniewaÅ¼ umoÅ¼liwia szybsze podejmowanie decyzji, monitorowanie procesÃ³w w czasie rzeczywistym i reagowanie na zdarzenia bez opÃ³Åºnienia.\nOmÃ³wimy gÅ‚Ã³wne elementy architektury systemÃ³w real-time, popularne wzorce architektoniczne oraz technologie, ktÃ³re sÄ… wykorzystywane do budowy takich systemÃ³w.\n\nPodstawowe elementy systemu real-time\nSystemy real-time muszÄ… speÅ‚niaÄ‡ szereg wymagaÅ„ zwiÄ…zanych z czasem przetwarzania danych. Istnieje kilka kluczowych komponentÃ³w w architekturze systemu, ktÃ³re zapewniajÄ… jego prawidÅ‚owe funkcjonowanie.\n\nProducent danych (Data Producer)\nDane w systemie real-time pochodzÄ… z rÃ³Å¼nych ÅºrÃ³deÅ‚, takich jak:\n\nCzujniki IoT: np. monitorowanie maszyn w fabryce, urzÄ…dzenia medyczne.\nTransakcje w czasie rzeczywistym: np. zakupy online, dane z gieÅ‚dy.\nDane uÅ¼ytkownikÃ³w: np. logi uÅ¼ytkownikÃ³w w aplikacjach mobilnych, dane z mediÃ³w spoÅ‚ecznoÅ›ciowych.\n\n\n\nPrzesyÅ‚anie danych (Data Transport)\nDane muszÄ… byÄ‡ szybko przesyÅ‚ane do systemÃ³w, ktÃ³re mogÄ… je analizowaÄ‡. W tym celu wykorzystywane sÄ… technologie strumieniowe, takie jak:\n\nApache Kafka: popularny system do przesyÅ‚ania danych w czasie rzeczywistym, zapewniajÄ…cy wysokÄ… wydajnoÅ›Ä‡ i niezawodnoÅ›Ä‡.\nApache Pulsar: alternatywa dla Kafki, dedykowana do przetwarzania danych w czasie rzeczywistym z duÅ¼Ä… iloÅ›ciÄ… subskrybentÃ³w.\n\n\n\nPrzetwarzanie danych (Data Processing)\nDane w systemach real-time sÄ… czÄ™sto przetwarzane w strumieniu. Dwa gÅ‚Ã³wne modele przetwarzania to:\n\nBatch processing: Przetwarzanie danych w partiach, ktÃ³re moÅ¼e mieÄ‡ opÃ³Åºnienie, ale przetwarza dane w sposÃ³b efektywny. MoÅ¼e byÄ‡ wykorzystywane w kombinacji z systemami real-time do agregacji danych.\nStream processing: Przetwarzanie danych w czasie rzeczywistym, bez opÃ³ÅºnieÅ„, w ktÃ³rym dane sÄ… natychmiastowo analizowane i przetwarzane.\n\n\n\nSkÅ‚adowanie danych (Data Storage)\nPrzechowywanie danych w systemie real-time zaleÅ¼y od wymagaÅ„ aplikacji. Dwa gÅ‚Ã³wne rodzaje przechowywania to:\n\nData Lake: skÅ‚adowanie ogromnych iloÅ›ci nieprzetworzonych danych w postaci surowych plikÃ³w. Bazy danych NoSQL: takie jak Cassandra, ktÃ³re umoÅ¼liwiajÄ… szybki dostÄ™p do danych w czasie rzeczywistym.\nData Warehouse: skÅ‚adowanie przetworzonych danych w celu ich analizy.\n\n\n\nAnaliza i wizualizacja danych (Data Analytics and Visualization)\nPo przetworzeniu danych w czasie rzeczywistym naleÅ¼y wykonaÄ‡ ich analizÄ™ i prezentacjÄ™ w sposÃ³b zrozumiaÅ‚y dla uÅ¼ytkownika:\n\nDashboardy: narzÄ™dzia takie jak Grafana lub Kibana, ktÃ³re sÅ‚uÅ¼Ä… do wizualizacji wynikÃ³w w czasie rzeczywistym.\nMachine Learning: zastosowanie algorytmÃ³w uczenia maszynowego w czasie rzeczywistym do klasyfikacji, wykrywania anomalii czy predykcji (np. wykrywanie oszustw).\n\n\n\n\nPopularne architektury systemÃ³w real-time\n\nLambda Architecture\nLambda Architecture to popularna koncepcja przetwarzania danych, ktÃ³ra Å‚Ä…czy przetwarzanie wsadowe z przetwarzaniem strumieniowym. To klasyczna architektura uÅ¼ywana w systemach przetwarzania Big Data, ktÃ³ra zakÅ‚ada dwie warstwy:\n\nBatch Layer: przetwarzanie (duÅ¼ych iloÅ›ci) danych wsadowych, ktÃ³re sÄ… pÃ³Åºniej wykorzystywane do analizy. Realizuje procesy przetwarzania w trybie offline\nSpeed Layer (Real-Time Layer): przetwarzanie danych w czasie rzeczywistym, czyli napÅ‚ywajÄ…ce dane strumieniowe, np. z sensorÃ³w, social media, transakcji, w celu uzyskania natychmiastowych wynikÃ³w.\nServing Layer: warstwa, ktÃ³ra Å‚Ä…czy wyniki obu poprzednich warstw i dostarcza je do uÅ¼ytkownika np. za pomocÄ… API.\n\n \n\n\nZalety i Wady Lambda Architecture:\n\nâœ… MoÅ¼liwoÅ›Ä‡ Å‚Ä…czenia przetwarzania wsadowego i strumieniowego,\nâœ… wsparcie dla duÅ¼ych zbiorÃ³w danych,\nâœ… elastycznoÅ›Ä‡ w przetwarzaniu zÅ‚oÅ¼onych zapytaÅ„.\nâŒ Wymaga utrzymywania dwÃ³ch oddzielnych systemÃ³w do przetwarzania danych (batch i stream), co prowadzi do zÅ‚oÅ¼onoÅ›ci implementacji i utrzymania.\n\n\n\nKappa Architecture\nKappa Architecture jest uproszczonÄ… wersjÄ… Lambda Architecture. Zamiast uÅ¼ywaÄ‡ dwÃ³ch osobnych warstw (batch i speed), Kappa wykorzystuje tylko jednÄ… warstwÄ™ przetwarzania strumieniowego, co upraszcza caÅ‚y system.\nJest to bardziej elastyczne podejÅ›cie do budowy systemÃ³w real-time, zwÅ‚aszcza w przypadku, gdy dane sÄ… przetwarzane tylko w jednym trybie (streaming).\n \n\n\nZalety i Wady Kappa Architecture:\n\nâœ… Prostota: Jako Å¼e przetwarzanie danych odbywa siÄ™ tylko w jednym strumieniu, caÅ‚y system jest prostszy i bardziej spÃ³jny.\nâœ… SkalowalnoÅ›Ä‡: DziÄ™ki eliminacji warstwy batch, system jest bardziej elastyczny i skalowalny w kontekÅ›cie analizy danych w czasie rzeczywistym.\nâœ… Idealne dla ML: Kappa Architecture Å›wietnie sprawdza siÄ™ w zastosowaniach zwiÄ…zanych z Machine Learning, poniewaÅ¼ przetwarzanie danych odbywa siÄ™ na bieÅ¼Ä…co, co pozwala na szybsze uczenie i wdraÅ¼anie modeli ML w czasie rzeczywistym.\nâŒ MoÅ¼e byÄ‡ mniej wydajna przy bardzo duÅ¼ych zbiorach danych, w przypadku, gdy wymagane jest skomplikowane przetwarzanie wsadowe.\n\n\n\nMicroservices Architecture\nArchitektura mikroserwisÃ³w jest powszechnie wykorzystywana w systemach real-time, poniewaÅ¼ umoÅ¼liwia:\n\nPodziaÅ‚ aplikacji na mniejsze, autonomiczne jednostki.\nElastycznoÅ›Ä‡ i skalowalnoÅ›Ä‡ systemu.\nMoÅ¼liwoÅ›Ä‡ przetwarzania rÃ³Å¼nych rodzajÃ³w danych przez rÃ³Å¼ne mikroserwisy.\nWykorzystanie komunikacji asynchronicznej, np. przez kolejki wiadomoÅ›ci.\n\n\n\nPrzykÅ‚ad\nUber to przykÅ‚ad firmy, ktÃ³ra skutecznie wykorzystuje narzÄ™dzia do przetwarzania strumieniowego, by monitorowaÄ‡ ruch drogowy w czasie rzeczywistym. DziÄ™ki systemowi Apache Kafka, Uber gromadzi dane o ruchu drogowym, lokalizacji pojazdÃ³w oraz czasach oczekiwania na przejazd, ktÃ³re sÄ… nastÄ™pnie analizowane na Å¼ywo.\nDane wejÅ›ciowe: Informacje o czasie i miejscu podrÃ³Å¼y, dane GPS z pojazdÃ³w, natÄ™Å¼enie ruchu.\nProces przetwarzania: Uber wykorzystuje Apache Kafka do przesyÅ‚ania tych danych w czasie rzeczywistym do systemÃ³w takich jak Apache Flink lub Spark Streaming, ktÃ³re analizujÄ… je na bieÅ¼Ä…co.\nAnaliza: System przewiduje czas oczekiwania na przejazd, monitoruje warunki drogowe oraz optymalizuje trasÄ™ w czasie rzeczywistym.\nWynik: UÅ¼ytkownicy Ubera otrzymujÄ… prognozy czasu przejazdu, a Uber dynamicznie dostosowuje zasoby (np. przydzielanie kierowcÃ³w), co umoÅ¼liwia optymalizacjÄ™ transportu."
  },
  {
    "objectID": "ksiazki.html",
    "href": "ksiazki.html",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "G. Maas, F. Garillot Stream Processing with Apache Spark Zobacz opis lub Kup e-book\nF. Hueske, V. Kalavri Stream Processing with Apache Flink Zobacz opis lub Kup e-book\n\n\n\nA. Bellemare MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™ Zobacz opis lub Kup\n\n\n\n\n\n\nW. McKinney Python w analizie danych. Przetwarzanie danych za pomocÄ… pakietÃ³w Pandas i NumPy oraz Å›rodowiska IPython. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. McIlwraith, H. Marmanis, D. Babenko Inteligentna sieÄ‡. Algorytmy przyszÅ‚oÅ›ci. Wydanie II (ebook) Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJoel Grus Data science od podstaw. Analiza danych w Pythonie. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nJohn W. Foreman Mistrz analizy danych. Od danych do wiedzy. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nA. Geron Uczenie maszynowe z uÅ¼yciem Scikit-Learn i TensorFlow. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nAlberto Boschetti, Luca Massaron Python. Podstawy nauki o danych. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nSebastian Raschka Python. Uczenie maszynowe. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nR. Schutt, C. Oâ€™Neil Badanie danych. Raport z pierwszej lini dziaÅ‚aÅ„. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nT. Segaran Nowe usÅ‚ugi 2.0. Przewodnik po analizie zbiorÃ³w danych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nF. Chollet Deep Learning. Praca z jÄ™zykiem Python i bibliotekÄ… Keras. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Patterson, A. Gibson Deep Learning. Praktyczne wprowadzenie (ebook) Zobacz opis lub Kup e-book\nV. Zocca, G. Spacagna, D. Slater, P. Roelants. Deep Learning. Uczenie gÅ‚Ä™bokie z jÄ™zykiem Python. Sztuczna inteligencja i sieci neuronowe Zobacz opis lub Kup ebook\nD. Osinga Deep Learning. Receptury Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Weidman Uczenie gÅ‚Ä™bokie od zera. Podstawy implementacji w Pythonie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. Foster Deep learning i modelowanie generatywne. Jak nauczyÄ‡ komputer malowania, pisania, komponowania i grania Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Howard, S. Gugger Deep learning dla programistÃ³w. Budowanie aplikacji AI za pomocÄ… fastai i PyTorch Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nJ. S. Damji, B. Wenig, T. Das, D. Lee Spark. BÅ‚yskawiczna analiza danych Zobacz opis lub Kup\nSpark. Zaawansowana analiza danych (ebook) Zobacz opis lub Kup e-book\nB. Chambers, M. Zaharia Spark: The Definitive Guide. Big Data Processing Made Simple (ebook) Zobacz opis lub Kup e-book\nJ. Quddus Machine Learning with Apache Spark Quick Start Guide (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nG. Coldwind ZrozumieÄ‡ programowanie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nA. Allain C++. Przewodnik dla poczÄ…tkujÄ…cych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Dasgupta, C. Papadimitriou, U. Vazirani Algorytmy PWN.\n\n\n\n\n\nJ. Krochmalski Docker. Projektowanie i wdraÅ¼anie aplikacji Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nR. McKendrick, S. Gallagher Docker. Programowanie aplikacji dla zaawansowanych. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nP. Bell, B. Beer GitHub. Przyjazny przewodnik (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nC. Althoff, Programista Samouk. Profesjonalny przewodnik do samodzielnej nauki kodowania. Zobacz opis lub Kup teraz, Kup e-book\nA. Sweigart, Automatyzacja nudnych zadaÅ„ z pythonem. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nK. Reitz, T. Schlusser Przewodnik po Pythonie. Dobre praktyki i praktyczne narzÄ™dzia. Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nB.Tate, L. Carslon, C. Hiibs, Ruby on Rails. Wprowadzenie. Wydanie II Zobacz opis lub Kup e-book\nB. Frain, Responsive Web Design. Projektowanie elastycznych witryn w HTML5 i CSS3, Zobacz opis lub Kup e-book\nK. Beck, TDD. Sztuda tworzenia, Zobacz opis lub Kup teraz, Kup e-book\nB. Dayley, Node.js, MongoDB, AngularJS. Kompendium wiedzy, Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage."
  },
  {
    "objectID": "ksiazki.html#ksiÄ…Å¼ki",
    "href": "ksiazki.html#ksiÄ…Å¼ki",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "G. Maas, F. Garillot Stream Processing with Apache Spark Zobacz opis lub Kup e-book\nF. Hueske, V. Kalavri Stream Processing with Apache Flink Zobacz opis lub Kup e-book\n\n\n\nA. Bellemare MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™ Zobacz opis lub Kup\n\n\n\n\n\n\nW. McKinney Python w analizie danych. Przetwarzanie danych za pomocÄ… pakietÃ³w Pandas i NumPy oraz Å›rodowiska IPython. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. McIlwraith, H. Marmanis, D. Babenko Inteligentna sieÄ‡. Algorytmy przyszÅ‚oÅ›ci. Wydanie II (ebook) Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJoel Grus Data science od podstaw. Analiza danych w Pythonie. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nJohn W. Foreman Mistrz analizy danych. Od danych do wiedzy. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nA. Geron Uczenie maszynowe z uÅ¼yciem Scikit-Learn i TensorFlow. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nAlberto Boschetti, Luca Massaron Python. Podstawy nauki o danych. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nSebastian Raschka Python. Uczenie maszynowe. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nR. Schutt, C. Oâ€™Neil Badanie danych. Raport z pierwszej lini dziaÅ‚aÅ„. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nT. Segaran Nowe usÅ‚ugi 2.0. Przewodnik po analizie zbiorÃ³w danych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nF. Chollet Deep Learning. Praca z jÄ™zykiem Python i bibliotekÄ… Keras. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Patterson, A. Gibson Deep Learning. Praktyczne wprowadzenie (ebook) Zobacz opis lub Kup e-book\nV. Zocca, G. Spacagna, D. Slater, P. Roelants. Deep Learning. Uczenie gÅ‚Ä™bokie z jÄ™zykiem Python. Sztuczna inteligencja i sieci neuronowe Zobacz opis lub Kup ebook\nD. Osinga Deep Learning. Receptury Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Weidman Uczenie gÅ‚Ä™bokie od zera. Podstawy implementacji w Pythonie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. Foster Deep learning i modelowanie generatywne. Jak nauczyÄ‡ komputer malowania, pisania, komponowania i grania Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Howard, S. Gugger Deep learning dla programistÃ³w. Budowanie aplikacji AI za pomocÄ… fastai i PyTorch Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nJ. S. Damji, B. Wenig, T. Das, D. Lee Spark. BÅ‚yskawiczna analiza danych Zobacz opis lub Kup\nSpark. Zaawansowana analiza danych (ebook) Zobacz opis lub Kup e-book\nB. Chambers, M. Zaharia Spark: The Definitive Guide. Big Data Processing Made Simple (ebook) Zobacz opis lub Kup e-book\nJ. Quddus Machine Learning with Apache Spark Quick Start Guide (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nG. Coldwind ZrozumieÄ‡ programowanie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nA. Allain C++. Przewodnik dla poczÄ…tkujÄ…cych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Dasgupta, C. Papadimitriou, U. Vazirani Algorytmy PWN.\n\n\n\n\n\nJ. Krochmalski Docker. Projektowanie i wdraÅ¼anie aplikacji Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nR. McKendrick, S. Gallagher Docker. Programowanie aplikacji dla zaawansowanych. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nP. Bell, B. Beer GitHub. Przyjazny przewodnik (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nC. Althoff, Programista Samouk. Profesjonalny przewodnik do samodzielnej nauki kodowania. Zobacz opis lub Kup teraz, Kup e-book\nA. Sweigart, Automatyzacja nudnych zadaÅ„ z pythonem. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nK. Reitz, T. Schlusser Przewodnik po Pythonie. Dobre praktyki i praktyczne narzÄ™dzia. Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nB.Tate, L. Carslon, C. Hiibs, Ruby on Rails. Wprowadzenie. Wydanie II Zobacz opis lub Kup e-book\nB. Frain, Responsive Web Design. Projektowanie elastycznych witryn w HTML5 i CSS3, Zobacz opis lub Kup e-book\nK. Beck, TDD. Sztuda tworzenia, Zobacz opis lub Kup teraz, Kup e-book\nB. Dayley, Node.js, MongoDB, AngularJS. Kompendium wiedzy, Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage."
  },
  {
    "objectID": "ksiazki.html#strony-www",
    "href": "ksiazki.html#strony-www",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "Strony WWW",
    "text": "Strony WWW\n\nSoftware\n\nGithub\nGit-instrukcja\nwww.python.org\nPyPI python libraries\nAnaconda\nDocker\n\n\n\nPakiety python dla analiz danych\n\nNumPy\nSciPy\nPandas\nScikit-learn\nJupyter\nMatplotlib\nBeautiful Soup\nTheano\nKeras\nTensorFlow\nVirtual ENV\n\n\n\nEdytory tekstu\n\nNotepad++\nSublime Text\nVisual Studio Code\n\n\n\nMarkdown\n\nMD\n\n\n\nJupyter notebook\n\nGaleria ciekawych notatnikÃ³w\nIntro\nKernels\nBringing the best out of jupyter for data science\nJupyter extensions\nI donâ€™t like notebooks\nJupyter lab\nSpeed up jupyter notebook\n\n\n\nPrzetwarzanie danych\n\ndata cookbook\n\n\n\nZbiory danych\n\nInternet Archive\nReddit\nKDnuggets\nKaggle\nList of datasets for machine learning research\nUCI Machine Learning Repo\nPublic API\nGoogle Datatset Search\n\n\n\nPython\n\nChris Albon Technical Notes on Using Data Science & AI\n40+ Python Statistics For Data Science Resources\nPractical Business Python\n\n\n\nkursy ML\n\nKurs Machine Learning - Andrew Ng, Stanford\nKurs Machine Learning - Andrew Ng, Stanford\nPython programming for data science"
  },
  {
    "objectID": "sylabus.html",
    "href": "sylabus.html",
    "title": "Sylabus",
    "section": "",
    "text": "Nazwa przedmiotu: Analiza danych w czasie rzeczywistym\nJednostka: SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nKod przedmiotu: 222890-D, 222890-S\nPunkty ECTS: 3\nJÄ™zyk prowadzenia: polski\nPoziom przedmiotu: Å›rednio-zaawansowany\nProwadzÄ…cy: Sebastian ZajÄ…c, sebastian.zajac@sgh.waw.pl\nWebsite: https://sebkaz-teaching.github.io/RTA_2025/"
  },
  {
    "objectID": "sylabus.html#cel-przedmiotu",
    "href": "sylabus.html#cel-przedmiotu",
    "title": "Sylabus",
    "section": "Cel Przedmiotu",
    "text": "Cel Przedmiotu\nWspÃ³Å‚czesny biznes opiera siÄ™ na podejmowaniu decyzji opartych na danych. Coraz wiÄ™ksza iloÅ›Ä‡ informacji, rosnÄ…ce wymagania rynku oraz potrzeba natychmiastowej reakcji sprawiajÄ…, Å¼e analiza danych w czasie rzeczywistym staje siÄ™ kluczowym elementem nowoczesnych procesÃ³w biznesowych.\nNa zajÄ™ciach studenci zapoznajÄ… siÄ™ z metodami i technologiami umoÅ¼liwiajÄ…cymi przetwarzanie danych w czasie rzeczywistym. SzczegÃ³lnÄ… uwagÄ™ poÅ›wiÄ™cimy zastosowaniu uczenia maszynowego (machine learning), sztucznej inteligencji (artificial intelligence) oraz gÅ‚Ä™bokich sieci neuronowych (deep learning) w analizie danych. Zrozumienie tych metod pozwala nie tylko lepiej interpretowaÄ‡ zjawiska biznesowe, ale takÅ¼e podejmowaÄ‡ szybkie i trafne decyzje.\nW ramach kursu omÃ³wimy zarÃ³wno dane ustrukturyzowane, jak i nieustrukturyzowane (obrazy, dÅºwiÄ™k, strumieniowanie wideo). Studenci poznajÄ… architektury przetwarzania danych, takie jak lambda i kappa, wykorzystywane w systemach data lake, a takÅ¼e wyzwania zwiÄ…zane z modelowaniem danych w czasie rzeczywistym na duÅ¼Ä… skalÄ™.\nKurs obejmuje czÄ™Å›Ä‡ teoretycznÄ… oraz praktyczne laboratoria, podczas ktÃ³rych studenci bÄ™dÄ… pracowaÄ‡ z rzeczywistymi danymi w Å›rodowiskach takich jak: JupyterLab, PyTorch, Apache Spark, Apache Kafka. DziÄ™ki temu studenci nie tylko zdobÄ™dÄ… wiedzÄ™ na temat metod analitycznych, ale takÅ¼e nauczÄ… siÄ™ korzystaÄ‡ z najnowszych technologii informatycznych stosowanych w analizie danych w czasie rzeczywistym."
  },
  {
    "objectID": "sylabus.html#program-przedmiotu",
    "href": "sylabus.html#program-przedmiotu",
    "title": "Sylabus",
    "section": "Program przedmiotu",
    "text": "Program przedmiotu\n\nModelowanie, uczenie i predykcja w trybie wsadowym (offline learning) i przyrostowym (online learning). Problemy przyrostowego uczenia maszynowego.\nModele przetwarzania danych w Big Data. Od plikoÌw pÅ‚askich do Data Lake. Mity i fakty przetwarzania danych w czasie rzeczywistym. (WykÅ‚ad)\nSystemy NRT (near real-time systems), pozyskiwanie danych, streaming, analityka.\nAlgorytmy estymacji parametroÌw modelu w trybie przyrostowym. Stochastic Gradient Descent.\nArchitektura Lambda i Kappa. Zaprojektowanie architektury IT dla przetwarzania danych w czasie rzeczywistym.\nPrzygotowanie mikroserwisu z modelem ML do zastosowania produkcyjnego.\nStrukturyzowane i niestrukturyzowane dane. Relacyjne bazy danych i bazy NoSQL\nAgregacje i raportowanie w bazach NoSQL (na przykÅ‚adzie bazy Cassandra).\nPodstawy obiektowego programowania w Pythonie w analizie regresji liniowej, logistycznej oraz sieci neuronowych z wykorzystaniem biblioteki sklearn, TensorFLow i Keras\nArchitektura IT przetwarzania Big Data. Przygotowanie wirtualnego sÌrodowiska dla Sparka. Pierwszy program w PySpark. Wykorzystanie przygotowanego sÌrodowiska do analizy danych z serwisu Twitter.\nAnaliza 1 Detekcja wyÅ‚udzenÌ w zgÅ‚oszeniach szkoÌd samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego sÌrodowiska. Cz 1.\nAnaliza 1 Detekcja wyÅ‚udzenÌ w zgÅ‚oszeniach szkoÌd samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego sÌrodowiska. Cz 2.\nPrzygotowanie sÌrodowiska Microsoft Azure. Detekcja anomalii i wartosÌci odstajaÌ¨cych w logowanych zdarzeniach sieci Ethernet cz 1.\nAnaliza 2 Detekcja anomalii i wartosÌci odstajaÌ¨cych w logowanych zdarzeniach sieci Ethernet cz 2. Inne narzeÌ¨dzia IT do szybkiej analizy logoÌw.\nNarzeÌ¨dzia SAS do strumieniowego przetwarzania danych"
  },
  {
    "objectID": "sylabus.html#efekty-ksztaÅ‚cenia",
    "href": "sylabus.html#efekty-ksztaÅ‚cenia",
    "title": "Sylabus",
    "section": "Efekty ksztaÅ‚cenia",
    "text": "Efekty ksztaÅ‚cenia\n\nWiedza:\n\n\nZna historieÌ¨ i filozofieÌ¨ modeli przetwarzania danych\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W02, (OGL)O2_W04, (OGL)O2_W07\nMetody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ z kolokwium\n\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W04, (OGL)O2_W04, (OGL) O2_W07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nZna mozÌ‡liwosÌci i obszary zastosowania procesowania danych w czasie rzeczywistym\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W02, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W08\nMetody weryfikacji: egzamin pisemny (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ egzaminacyjnych\n\nZna teoretyczne aspekty struktury lambda i kappa\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W03, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W04, (OGL) O2_W06, (OGL)O2_W08\nMetody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ z kolokwium\n\nUmie wybracÌ struktureÌ¨ IT dla danego problemu biznesowego\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nRozumie potrzeby biznesowe podejmowania decyzji w bardzo kroÌtkim czasie\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmiejÄ™tnoÅ›ci:\n\n\nRozroÌzÌ‡nia typy danych strukturyzowanych jak i niestrukturyzowanych\n\nPowiaÌ¨zania: K2A_U02, K2A_U07, K2A_U10, O2_U02\nMetody weryfikacji: test\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie przygotowacÌ, przetwarzacÌ oraz zachowywacÌ dane generowane w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U03, K2A_U05, K2A_U09, O2_U02, O2_U04\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nRozumie ograniczenia wynikajaÌ¨ce z czasu przetwarzania przez urzaÌ¨dzenia oraz systemy informatyczne\n\nPowiaÌ¨zania: K2A_U01, K2A_U07, K2A_U11, O2_U02\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie zastosowacÌ i skonstruowacÌ system do przetwarzania w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U05, K2A_U10, O2_U05, O2_U06, O2_U07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie przygotowacÌ raportowanie dla systemu przetwarzania w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U02, K2A_U08, K2A_U10, O2_U06, O2_U07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nKompetencje:\n\n\nFormuÅ‚uje problem analityczny wraz z jego informatycznym rozwiaÌ¨zaniem\n\nPowiaÌ¨zania: K2A_K01, K2A_K03, O2_K02, O2_K06, O2_K07\nMetody weryfikacji: projekt, prezentacja\nMetody dokumentacji: prace pisemne studenta (w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUtrwala umiejeÌ¨tnosÌcÌ samodzielnego uzupeÅ‚niania wiedzy teoretycznej jak i praktycznej w zakresie programowania, modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym.\n\nPowiaÌ¨zania: K2A_K02, K2A_K04, (OGL)O2_K01, (OGL) O2_K02, (OGL)O2_K05, (OGL)O2_K06\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)"
  },
  {
    "objectID": "sylabus.html#realizacja-przedmiotu",
    "href": "sylabus.html#realizacja-przedmiotu",
    "title": "Sylabus",
    "section": "Realizacja przedmiotu",
    "text": "Realizacja przedmiotu\n\negzamin testowy 20%\nZadania 40%\nProjekt 40%"
  },
  {
    "objectID": "sylabus.html#literatura",
    "href": "sylabus.html#literatura",
    "title": "Sylabus",
    "section": "Literatura",
    "text": "Literatura\n1ï¸âƒ£ ZajÄ…c S. (red.), Modelowanie dla biznesu, Analityka w czasie rzeczywistym - narzÄ™dzia informatyczne i biznesowe, SGH, Warszawa 2022.\n2ï¸âƒ£ FrÄ…tczak E. (red.), Modelowanie dla biznesu: Regresja logistyczna, Regresja Poissona, Survival Data Mining, CRM, Credit Scoring, SGH, Warszawa 2019.\n3ï¸âƒ£ Bellemare A., MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™, Oâ€™Reilly 2021.\n4ï¸âƒ£ Shapira G., Palino T., Sivaram R., Petty K., Kafka: The Definitive Guide. Real-time data and stream processing at scale, Oâ€™Reilly 2022.\n5ï¸âƒ£ Lakshmanan V., Robinson S., Munn M., Wzorce projektowe uczenia maszynowego. RozwiÄ…zania typowych problemÃ³w dotyczÄ…cych przygotowania danych, konstruowania modeli i MLOps, Oâ€™Reilly 2021.\n6ï¸âƒ£ Gift N., Deza A., Practical MLOps: Operationalizing Machine Learning Models, Oâ€™Reilly 2022.\n7ï¸âƒ£ Tiark Rompf, Streaming Systems: The What, Where, When, and How of Large-Scale Data Processing, Oâ€™Reilly 2018.\n8ï¸âƒ£ SebastiÃ¡n RamÃ­rez, FastAPI: Modern Web APIs with Python, Manning (w przygotowaniu, aktualnie dostÄ™pna online).\n9ï¸âƒ£ Trevor Hastie, Robert Tibshirani, Jerome Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer 2017.\nğŸ”Ÿ Anirudh Koul, Siddha Ganju, Meher Kasam, Practical Deep Learning for Cloud, Mobile & Edge, Oâ€™Reilly 2019."
  },
  {
    "objectID": "wyklad1.html",
    "href": "wyklad1.html",
    "title": "WykÅ‚ad 1",
    "section": "",
    "text": "â³ Czas trwania: 1,5h ğŸ¯ Cel wykÅ‚adu"
  },
  {
    "objectID": "wyklad1.html#zapoznanie-studentÃ³w-z-podstawami-real-time-analytics-rÃ³Å¼nicami-miÄ™dzy-trybami-przetwarzania-danych-batch-streaming-real-time-oraz-kluczowymi-zastosowaniami-i-wyzwaniami.",
    "href": "wyklad1.html#zapoznanie-studentÃ³w-z-podstawami-real-time-analytics-rÃ³Å¼nicami-miÄ™dzy-trybami-przetwarzania-danych-batch-streaming-real-time-oraz-kluczowymi-zastosowaniami-i-wyzwaniami.",
    "title": "WykÅ‚ad 1",
    "section": "Zapoznanie studentÃ³w z podstawami real-time analytics, rÃ³Å¼nicami miÄ™dzy trybami przetwarzania danych (batch, streaming, real-time) oraz kluczowymi zastosowaniami i wyzwaniami.",
    "text": "Zapoznanie studentÃ³w z podstawami real-time analytics, rÃ³Å¼nicami miÄ™dzy trybami przetwarzania danych (batch, streaming, real-time) oraz kluczowymi zastosowaniami i wyzwaniami."
  },
  {
    "objectID": "wyklad1.html#czym-jest-analiza-danych-w-czasie-rzeczywistym",
    "href": "wyklad1.html#czym-jest-analiza-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 1",
    "section": "Czym jest analiza danych w czasie rzeczywistym?",
    "text": "Czym jest analiza danych w czasie rzeczywistym?\n\nDefinicja i kluczowe koncepcje\nAnaliza danych w czasie rzeczywistym (ang. Real-Time Data Analytics) to proces przetwarzania i analizy danych natychmiast po ich wygenerowaniu, bez koniecznoÅ›ci przechowywania i oczekiwania na pÃ³Åºniejsze przetworzenie. Celem jest uzyskanie natychmiastowych wnioskÃ³w i reakcji na zmieniajÄ…ce siÄ™ warunki w systemach biznesowych, technologicznych i naukowych.\n\n\nKluczowe cechy analizy danych w czasie rzeczywistym:\n\nNiska latencja (ang. low-latency) â€“ dane sÄ… analizowane w ciÄ…gu milisekund lub sekund od ich wygenerowania.\nStreaming vs.Â Batch Processing â€“ analiza danych moÅ¼e odbywaÄ‡ siÄ™ w sposÃ³b ciÄ…gÅ‚y (streaming) lub w z gÃ³ry okreÅ›lonych interwaÅ‚ach (batch).\nIntegracja z IoT, AI i ML â€“ real-time analytics czÄ™sto wspÃ³Å‚pracuje z Internetem Rzeczy (IoT) oraz algorytmami sztucznej inteligencji.\nPodejmowanie decyzji w czasie rzeczywistym â€“ np. natychmiastowa detekcja oszustw w transakcjach bankowych."
  },
  {
    "objectID": "wyklad1.html#zastosowanie-analizy-danych-w-czasie-rzeczywistym-w-biznesie",
    "href": "wyklad1.html#zastosowanie-analizy-danych-w-czasie-rzeczywistym-w-biznesie",
    "title": "WykÅ‚ad 1",
    "section": "Zastosowanie analizy danych w czasie rzeczywistym w biznesie",
    "text": "Zastosowanie analizy danych w czasie rzeczywistym w biznesie\n\nFinanse i bankowoÅ›Ä‡\n\nWykrywanie oszustw â€“ analiza transakcji w czasie rzeczywistym pozwala na wykrycie anomalii wskazujÄ…cych na oszustwa.\nAutomatyczny trading â€“ systemy HFT (High-Frequency Trading) analizujÄ… miliony danych w uÅ‚amkach sekundy.\nDynamiczne oceny kredytowe â€“ natychmiastowa analiza ryzyka kredytowego klienta.\n\n\n\nE-commerce i marketing cyfrowy\n\nPersonalizacja ofert w czasie rzeczywistym â€“ dynamiczne rekomendacje produktÃ³w na podstawie aktualnego zachowania uÅ¼ytkownika.\nDynamiczne ceny â€“ np. Uber, Amazon i hotele stosujÄ… dynamiczne ustalanie cen na podstawie popytu.\nMonitorowanie mediÃ³w spoÅ‚ecznoÅ›ciowych â€“ analiza nastrojÃ³w klientÃ³w i natychmiastowa reakcja na negatywne komentarze.\n\n\n\nTelekomunikacja i IoT\n\nMonitorowanie infrastruktury sieciowej â€“ analiza logÃ³w w czasie rzeczywistym pozwala na wykrywanie awarii przed ich wystÄ…pieniem.\nSmart Cities â€“ analiza ruchu drogowego i natychmiastowa optymalizacja sygnalizacji Å›wietlnej.\nAnalityka IoT â€“ urzÄ…dzenia IoT generujÄ… strumienie danych, ktÃ³re moÅ¼na analizowaÄ‡ w czasie rzeczywistym (np. inteligentne liczniki energii).\n\n\n\nOchrona zdrowia\n\nMonitorowanie pacjentÃ³w â€“ analiza sygnaÅ‚Ã³w z urzÄ…dzeÅ„ medycznych w celu natychmiastowego wykrycia zagroÅ¼enia Å¼ycia.\nAnalityka epidemiologiczna â€“ Å›ledzenie rozprzestrzeniania siÄ™ chorÃ³b na podstawie danych w czasie rzeczywistym.\n\nAnaliza danych w czasie rzeczywistym to kluczowy element nowoczesnych systemÃ³w informatycznych, ktÃ³ry umoÅ¼liwia firmom podejmowanie decyzji szybciej i bardziej precyzyjnie. Jest wykorzystywana w wielu branÅ¼ach â€“ od finansÃ³w, przez e-commerce, aÅ¼ po ochronÄ™ zdrowia i IoT."
  },
  {
    "objectID": "wyklad1.html#rÃ³Å¼nice-miÄ™dzy-batch-processing-near-real-time-analytics-real-time-analytics",
    "href": "wyklad1.html#rÃ³Å¼nice-miÄ™dzy-batch-processing-near-real-time-analytics-real-time-analytics",
    "title": "WykÅ‚ad 1",
    "section": "RÃ³Å¼nice miÄ™dzy Batch Processing, Near Real-Time Analytics, Real-Time Analytics",
    "text": "RÃ³Å¼nice miÄ™dzy Batch Processing, Near Real-Time Analytics, Real-Time Analytics\nIstniejÄ… trzy gÅ‚Ã³wne podejÅ›cia do przetwarzania informacji:\n\nBatch Processing (Przetwarzanie wsadowe)\nNear Real-Time Analytics (Analiza niemal w czasie rzeczywistym)\nReal-Time Analytics (Analiza w czasie rzeczywistym)\n\nKaÅ¼de z nich rÃ³Å¼ni siÄ™ szybkoÅ›ciÄ… przetwarzania, wymaganiami technologicznymi oraz zastosowaniami biznesowymi.\n\nBatch Processing â€“ Przetwarzanie wsadowe\nğŸ“Œ Definicja:\nBatch Processing polega na zbieraniu duÅ¼ych iloÅ›ci danych i ich przetwarzaniu w okreÅ›lonych odstÄ™pach czasu (np. co godzinÄ™, codziennie, co tydzieÅ„).\nğŸ“Œ Cechy:\n\nâœ… Wysoka wydajnoÅ›Ä‡ dla duÅ¼ych zbiorÃ³w danych\nâœ… Przetwarzanie danych po ich zgromadzeniu\nâœ… Nie wymaga natychmiastowej analizy\nâœ… Zwykle taÅ„sze niÅ¼ przetwarzanie w czasie rzeczywistym\nâŒ OpÃ³Åºnienia â€“ wyniki sÄ… dostÄ™pne dopiero po zakoÅ„czeniu przetwarzania\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nGenerowanie raportÃ³w finansowych na koniec dnia/miesiÄ…ca\nAnaliza trendÃ³w sprzedaÅ¼y na podstawie historycznych danych\nTworzenie modeli uczenia maszynowego offline\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nHadoop MapReduce\nApache Spark (w trybie batch)\nGoogle BigQuery\n\nimport pandas as pd  \ndf = pd.read_csv(\"transactions.csv\")  \n\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\ndf['month'] = df['transaction_date'].dt.to_period('M')  # Ekstrakcja miesiÄ…ca\n\n# Agregacja danych - miesiÄ™czne sumy transakcji\nmonthly_sales = df.groupby(['month'])['amount'].sum()\n\n# Zapis wynikÃ³w do pliku (np. raportu)\nmonthly_sales.to_csv(\"monthly_report.csv\")  \n\nprint(\"Raport zapisany!\")\nGdybyÅ› chciaÅ‚ utworzyÄ‡ dane do przykÅ‚adu\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\ndata = {\n    'transaction_id': [f'TX{str(i).zfill(4)}' for i in range(1, 1001)],\n    'amount': np.random.uniform(10, 10000, 1000), \n    'transaction_date': pd.date_range(start=\"2025-01-01\", periods=1000, freq='h'), \n    'merchant': np.random.choice(['Merchant_A', 'Merchant_B', 'Merchant_C', 'Merchant_D'], 1000),\n    'card_type': np.random.choice(['Visa', 'MasterCard', 'AmEx'], 1000)\n}\n\ndf = pd.DataFrame(data)\ncsv_file = 'transactions.csv'\ndf.to_csv(csv_file, index=False)\n\n\nNear Real-Time Analytics â€“ Analiza niemal w czasie rzeczywistym\nğŸ“Œ Definicja:\nNear Real-Time Analytics to analiza danych, ktÃ³ra odbywa siÄ™ z minimalnym opÃ³Åºnieniem (zazwyczaj od kilku sekund do kilku minut). Jest stosowana tam, gdzie peÅ‚na analiza w czasie rzeczywistym nie jest konieczna, ale zbyt duÅ¼e opÃ³Åºnienia mogÄ… wpÅ‚ynÄ…Ä‡ na biznes.\nğŸ“Œ Cechy:\n\nâœ… Przetwarzanie danych w krÃ³tkich odstÄ™pach czasu (kilka sekund â€“ minut)\nâœ… UmoÅ¼liwia szybkie podejmowanie decyzji, ale nie wymaga reakcji w milisekundach\nâœ… Optymalny balans miÄ™dzy kosztami a szybkoÅ›ciÄ…\nâŒ Nie nadaje siÄ™ do systemÃ³w wymagajÄ…cych natychmiastowej reakcji\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nMonitorowanie transakcji bankowych i wykrywanie oszustw (np. analiza w ciÄ…gu 30 sekund)\nDynamiczne dostosowywanie reklam online na podstawie zachowaÅ„ uÅ¼ytkownikÃ³w\nAnaliza logÃ³w serwerÃ³w i sieci w celu wykrycia anomalii\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nApache Kafka + Spark Streaming\nElasticsearch + Kibana (np. analiza logÃ³w IT)\nAmazon Kinesis\n\nPrzykÅ‚ad producenta danych realizujÄ…cego tranzakcje wysyÅ‚ane do systemu Apache Kafka.\nfrom kafka import KafkaProducer\nimport json\nimport random\nimport time\nfrom datetime import datetime\n\n# Ustawienia dla producenta\nbootstrap_servers = 'localhost:9092'\ntopic = 'transactions' \n\n# Funkcja generujÄ…ca przykÅ‚adowe dane transakcji\ndef generate_transaction():\n    transaction = {\n        'transaction_id': f'TX{random.randint(1000, 9999)}',\n        'amount': round(random.uniform(10, 10000), 2),  # Kwota miÄ™dzy 10 a 10 000\n        'transaction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'merchant': random.choice(['Merchant_A', 'Merchant_B', 'Merchant_C', 'Merchant_D']),\n        'card_type': random.choice(['Visa', 'MasterCard', 'AmEx']),\n    }\n    return transaction\n\nproducer = KafkaProducer(\n    bootstrap_servers=bootstrap_servers,\n    value_serializer=lambda v: json.dumps(v).encode('utf-8') \n)\n\n\nfor _ in range(1000):  \n    transaction = generate_transaction()\n    producer.send(topic, value=transaction) \n    print(f\"Sent: {transaction}\")\n    time.sleep(1) \n\n# ZakoÅ„czenie dziaÅ‚ania producenta\nproducer.flush()\nproducer.close()\nPrzykÅ‚ad consumenta - programu sparawdzajÄ…cego zbyt duÅ¼e transakcje\nfrom kafka import KafkaConsumer\nimport json  \n\n# Konsumer do pobierania danych z Kafka\nconsumer = KafkaConsumer(\n    'transactions',\n    bootstrap_servers='localhost:9092',\n    auto_offset_reset='earliest',\n    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n)\n\n# Pobieranie transakcji w niemal real-time i analiza\nfor message in consumer:\n    transaction = message.value\n    if transaction[\"amount\"] &gt; 8000:\n        print(f\"ğŸš¨ Wykryto duÅ¼Ä… transakcjÄ™: {transaction}\")\nPrzykÅ‚adowy zestaw danych\n{\n    \"transaction_id\": \"TX1234\",\n    \"amount\": 523.47,\n    \"transaction_date\": \"2025-02-11 08:10:45\",\n    \"merchant\": \"Merchant_A\",\n    \"card_type\": \"Visa\"\n}\n\n\nReal-Time Analytics â€“ Analiza w czasie rzeczywistym\nğŸ“Œ Definicja:\nReal-Time Analytics to natychmiastowa analiza danych i podejmowanie decyzji w uÅ‚amku sekundy (milisekundy do jednej sekundy). Wykorzystywana w systemach wymagajÄ…cych reakcji w czasie rzeczywistym, np. w transakcjach gieÅ‚dowych, systemach IoT czy cyberbezpieczeÅ„stwie.\nğŸ“Œ Cechy:\n\nâœ… Bardzo niskie opÃ³Åºnienie (milliseconds-seconds)\nâœ… UmoÅ¼liwia natychmiastowÄ… reakcjÄ™ systemu\nâœ… Wymaga wysokiej mocy obliczeniowej i skalowalnej architektury\nâŒ DroÅ¼sze i bardziej zÅ‚oÅ¼one technologicznie niÅ¼ batch processing\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nHigh-Frequency Trading (HFT) â€“ analiza i podejmowanie decyzji w transakcjach gieÅ‚dowych w milisekundach\nAutonomiczne samochody â€“ analiza strumieni danych z kamer i sensorÃ³w w czasie rzeczywistym\nCyberbezpieczeÅ„stwo â€“ detekcja atakÃ³w w sieciach komputerowych w uÅ‚amku sekundy\nAnalityka IoT â€“ np. natychmiastowa detekcja anomalii w danych z czujnikÃ³w przemysÅ‚owych\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nApache Flink\nApache Storm\nGoogle Dataflow\n\nğŸ” PorÃ³wnanie:\n\n\n\n\n\n\n\n\n\nCecha\nBatch Processing\nNear Real-Time Analytics\nReal-Time Analytics\n\n\n\n\nOpÃ³Åºnienie\nMinuty â€“ godziny â€“ dni\nSekundy â€“ minuty\nMilisekundy â€“ sekundy\n\n\nTyp przetwarzania\nWsadowe (offline)\nStrumieniowe (ale nie w peÅ‚ni natychmiastowe)\nStrumieniowe (prawdziwy real-time)\n\n\nKoszt infrastruktury\nğŸ“‰ Niski\nğŸ“ˆ Åšredni\nğŸ“ˆğŸ“ˆ Wysoki\n\n\nZÅ‚oÅ¼onoÅ›Ä‡ implementacji\nğŸ“‰ Prosta\nğŸ“ˆ Åšrednia\nğŸ“ˆğŸ“ˆ Trudna\n\n\nPrzykÅ‚ady zastosowaÅ„\nRaporty, ML offline, analizy historyczne\nMonitorowanie transakcji, dynamiczne reklamy\nHFT, IoT, detekcja oszustw w czasie rzeczywistym\n\n\n\nğŸ“Œ Kiedy stosowaÄ‡ Batch Processing?\n\nâœ… Gdy nie wymagasz natychmiastowej analizy\nâœ… Gdy masz duÅ¼e iloÅ›ci danych, ale przetwarzane sÄ… one okresowo\nâœ… Gdy chcesz obniÅ¼yÄ‡ koszty\n\nğŸ“Œ Kiedy stosowaÄ‡ Near Real-Time Analytics?\n\nâœ… Gdy wymagasz analizy w krÃ³tkim czasie (sekundy â€“ minuty)\nâœ… Gdy potrzebujesz bardziej aktualnych danych, ale nie w peÅ‚nym real-time\nâœ… Gdy szukasz kompromisu miÄ™dzy wydajnoÅ›ciÄ… a kosztami\n\nğŸ“Œ Kiedy stosowaÄ‡ Real-Time Analytics?\n\nâœ… Gdy kaÅ¼da milisekunda ma znaczenie (np. gieÅ‚da, autonomiczne pojazdy)\nâœ… Gdy chcesz wykrywaÄ‡ oszustwa, anomalie lub incydenty natychmiast\nâœ… Gdy system musi natychmiast reagowaÄ‡ na zdarzenia\n\nReal-time analytics nie zawsze jest konieczne â€“ w wielu przypadkach near real-time jest wystarczajÄ…ce i bardziej opÅ‚acalne. Kluczowe jest zrozumienie wymagaÅ„ biznesowych przed wyborem odpowiedniego rozwiÄ…zania."
  },
  {
    "objectID": "wyklad1.html#dlaczego-real-time-analytics-jest-waÅ¼ne",
    "href": "wyklad1.html#dlaczego-real-time-analytics-jest-waÅ¼ne",
    "title": "WykÅ‚ad 1",
    "section": "Dlaczego Real-Time Analytics jest waÅ¼ne?",
    "text": "Dlaczego Real-Time Analytics jest waÅ¼ne?\nReal-time analytics (analiza danych w czasie rzeczywistym) staje siÄ™ coraz bardziej istotna w wielu branÅ¼ach, poniewaÅ¼ umoÅ¼liwia organizacjom podejmowanie natychmiastowych decyzji na podstawie aktualnych danych. Oto kilka kluczowych powodÃ³w, dla ktÃ³rych real-time analytics jest waÅ¼ne:\n\nSzybkie podejmowanie decyzji\nReal-time analytics pozwala firmom reagowaÄ‡ na zmiany i wydarzenia w czasie rzeczywistym. DziÄ™ki temu moÅ¼na podejmowaÄ‡ decyzje szybciej, co jest kluczowe w dynamicznych Å›rodowiskach, takich jak:\n\nMarketing: Reklamy mogÄ… byÄ‡ dostosowane do zachowaÅ„ uÅ¼ytkownikÃ³w w czasie rzeczywistym (np. personalizacja treÅ›ci reklamowych).\nFinanse: Wykrywanie oszustw w czasie rzeczywistym, gdzie kaÅ¼da minuta moÅ¼e oznaczaÄ‡ rÃ³Å¼nicÄ™ w prewencji strat finansowych.\n\n\n\nMonitorowanie w czasie rzeczywistym\nFirmy mogÄ… monitorowaÄ‡ kluczowe wskaÅºniki operacyjne na bieÅ¼Ä…co. PrzykÅ‚ady:\n\nIoT (Internet of Things): Monitorowanie stanu maszyn i urzÄ…dzeÅ„ w fabrykach, aby natychmiast wykrywaÄ‡ awarie i zapobiegaÄ‡ przestojom.\nHealthtech: Åšledzenie parametrÃ³w Å¼yciowych pacjentÃ³w i wykrywanie anomalii, co moÅ¼e ratowaÄ‡ Å¼ycie.\n\n\n\nZwiÄ™kszenie efektywnoÅ›ci operacyjnej\nReal-time analytics umoÅ¼liwia natychmiastowe wykrywanie i eliminowanie problemÃ³w operacyjnych, zanim stanÄ… siÄ™ powaÅ¼niejsze. PrzykÅ‚ady:\n\nLogistyka: Åšledzenie przesyÅ‚ek i monitorowanie statusu transportu w czasie rzeczywistym, co poprawia efektywnoÅ›Ä‡ i zmniejsza opÃ³Åºnienia.\nRetail: Monitorowanie poziomu zapasÃ³w na bieÅ¼Ä…co i dostosowywanie zamÃ³wieÅ„ do aktualnych potrzeb.\n\n\n\nKonkurencyjnoÅ›Ä‡\nOrganizacje, ktÃ³re wykorzystujÄ… analitykÄ™ w czasie rzeczywistym, majÄ… przewagÄ™ nad konkurencjÄ…, poniewaÅ¼ mogÄ… szybciej reagowaÄ‡ na zmiany na rynku, nowe potrzeby klientÃ³w i sytuacje kryzysowe. DziÄ™ki natychmiastowym informacjom:\n\nMoÅ¼na podejmowaÄ‡ decyzje z wyprzedzeniem przed konkurentami.\nUtrzymywaÄ‡ lepsze relacje z klientami, reagujÄ…c na ich potrzeby w czasie rzeczywistym (np. dostosowywanie oferty).\n\n\n\nLepsze doÅ›wiadczenia uÅ¼ytkownikÃ³w (Customer Experience)\nAnaliza danych w czasie rzeczywistym pozwala na dostosowywanie interakcji z uÅ¼ytkownikami w trakcie ich trwania. PrzykÅ‚ady:\n\nE-commerce: Analiza koszyka zakupowego uÅ¼ytkownika w czasie rzeczywistym, aby np. zaoferowaÄ‡ rabat lub przypomnieÄ‡ o porzuconych produktach.\nStreaming: Optymalizacja jakoÅ›ci usÅ‚ugi wideo/streamingowej w zaleÅ¼noÅ›ci od dostÄ™pnej przepustowoÅ›ci Å‚Ä…cza.\n\n\n\nWykrywanie i reagowanie na anomalie\nW dzisiejszym Å›wiecie peÅ‚nym danych, wykrywanie anomalii w czasie rzeczywistym jest kluczowe dla bezpieczeÅ„stwa. PrzykÅ‚ady:\n\nCyberbezpieczeÅ„stwo: Real-time analytics umoÅ¼liwia wykrywanie podejrzanych dziaÅ‚aÅ„ w sieci i zapobieganie atakom w czasie rzeczywistym (np. ataki DDoS, nieautoryzowane logowanie).\nWykrywanie oszustw: Natychmiastowa identyfikacja podejrzanych transakcji w systemach bankowych i kartach kredytowych.\n\n\n\nOptymalizacja kosztÃ³w\nDziÄ™ki analizie w czasie rzeczywistym moÅ¼na optymalizowaÄ‡ zasoby i zmniejszaÄ‡ koszty. Na przykÅ‚ad:\n\nZarzÄ…dzanie energiÄ…: Analiza zuÅ¼ycia energii w czasie rzeczywistym, umoÅ¼liwiajÄ…ca optymalizacjÄ™ wydatkÃ³w na energiÄ™ w firmach.\nOptymalizacja Å‚aÅ„cucha dostaw: DziÄ™ki bieÅ¼Ä…cemu Å›ledzeniu zapasÃ³w i dostaw moÅ¼na lepiej zarzÄ…dzaÄ‡ kosztami magazynowania i transportu.\n\n\n\nZdolnoÅ›Ä‡ do przewidywania i zapobiegania\nAnaliza w czasie rzeczywistym wspiera procesy predykcyjne, ktÃ³re mogÄ… przewidywaÄ‡ przyszÅ‚e zachowania lub problemy, a takÅ¼e je eliminowaÄ‡ zanim siÄ™ pojawiÄ…. Na przykÅ‚ad:\n\nUtrzymanie predykcyjne w produkcji: Wykorzystanie analizy w czasie rzeczywistym w poÅ‚Ä…czeniu z modelami predykcyjnymi pozwala przewidywaÄ‡ awarie maszyn.\nPrognozy popytu: W czasie rzeczywistym moÅ¼na dostosowywaÄ‡ produkcjÄ™ lub zapasy na podstawie bieÅ¼Ä…cych trendÃ³w.\n\nReal-time analytics to nie tylko analiza danych â€“ to kluczowy element strategii firm w Å›wiecie, ktÃ³ry wymaga szybkich reakcji, elastycznoÅ›ci i dostosowywania siÄ™ do zmieniajÄ…cego siÄ™ otoczenia. Firmy, ktÃ³re wdraÅ¼ajÄ… te technologie, mogÄ… znaczÄ…co poprawiÄ‡ swoje wyniki finansowe, obsÅ‚ugÄ™ klienta, wydajnoÅ›Ä‡ operacyjnÄ…, a takÅ¼e przewagÄ™ konkurencyjnÄ…."
  },
  {
    "objectID": "wyklad1.html#wyzwania-i-problemy-analizy-danych-w-czasie-rzeczywistym",
    "href": "wyklad1.html#wyzwania-i-problemy-analizy-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 1",
    "section": "Wyzwania i problemy analizy danych w czasie rzeczywistym",
    "text": "Wyzwania i problemy analizy danych w czasie rzeczywistym\nAnaliza danych w czasie rzeczywistym wiÄ…Å¼e siÄ™ z wieloma wyzwaniami i trudnoÅ›ciami, ktÃ³re trzeba rozwiÄ…zaÄ‡, aby systemy real-time dziaÅ‚aÅ‚y efektywnie i niezawodnie. Pomimo ogromnego potencjaÅ‚u, jaki daje moÅ¼liwoÅ›Ä‡ natychmiastowego przetwarzania danych, realizacja tych procesÃ³w w praktyce wiÄ…Å¼e siÄ™ z licznymi problemami technologicznymi, organizacyjnymi i dotyczÄ…cymi zarzÄ…dzania danymi.\nPoniÅ¼ej przedstawiamy najwaÅ¼niejsze wyzwania oraz moÅ¼liwe rozwiÄ…zania, ktÃ³re naleÅ¼y uwzglÄ™dniÄ‡ podczas implementacji systemÃ³w analizy danych w czasie rzeczywistym.\n\nSkalowalnoÅ›Ä‡ systemÃ³w\n\nWyzwanie:\nSkalowanie systemu analitycznego w czasie rzeczywistym jest jednym z najtrudniejszych zadaÅ„. W miarÄ™ jak iloÅ›Ä‡ generowanych danych roÅ›nie, systemy muszÄ… byÄ‡ w stanie obsÅ‚ugiwaÄ‡ wiÄ™ksze obciÄ…Å¼enie bez opÃ³Åºnienia w przetwarzaniu.\nZwiÄ™kszona iloÅ›Ä‡ danych: W systemach real-time, jak np. monitorowanie danych IoT czy transakcje w systemach finansowych, iloÅ›Ä‡ generowanych danych moÅ¼e byÄ‡ olbrzymia. Potrzebna jest elastycznoÅ›Ä‡: System musi automatycznie dostosowywaÄ‡ zasoby w zaleÅ¼noÅ›ci od obciÄ…Å¼enia.\n\n\nRozwiÄ…zanie:\nWykorzystanie skalowalnych systemÃ³w chmurowych, ktÃ³re pozwalajÄ… na dynamiczne zwiÄ™kszanie zasobÃ³w obliczeniowych (np. AWS, Azure, Google Cloud). Kubernetes do zarzÄ…dzania kontenerami i automatycznego skalowania mikroserwisÃ³w. Technologie strumieniowe (Apache Kafka, Apache Flink) umoÅ¼liwiajÄ…ce przetwarzanie danych w sposÃ³b wydajny i rozproszony.\n\n\n\nOpÃ³Åºnienia (Latency)\n\nWyzwanie:\nW systemach analizy danych w czasie rzeczywistym, kaÅ¼de opÃ³Åºnienie w przetwarzaniu danych moÅ¼e mieÄ‡ powaÅ¼ne konsekwencje. Dotyczy to zwÅ‚aszcza obszarÃ³w takich jak:\nWykrywanie oszustw: W przypadku systemÃ³w pÅ‚atnoÅ›ci online, opÃ³Åºnienie w analizie transakcji moÅ¼e oznaczaÄ‡ przegapienie nieautoryzowanej transakcji. Monitorowanie zdrowia pacjentÃ³w: OpÃ³Åºnienia mogÄ… wpÅ‚ynÄ…Ä‡ na skutecznoÅ›Ä‡ reakcji w sytuacjach kryzysowych.\n\n\nRozwiÄ…zanie:\nUÅ¼ywanie algorytmÃ³w optymalizujÄ…cych czas przetwarzania, np. stream processing z wykorzystaniem systemÃ³w takich jak Apache Kafka lub Apache Flink. Edge computing: Przesuwanie przetwarzania danych bliÅ¼ej ÅºrÃ³dÅ‚a (np. urzÄ…dzenia IoT), aby zmniejszyÄ‡ opÃ³Åºnienia w transmisji danych do chmury.\n\n\n\nJakoÅ›Ä‡ danych i zarzÄ…dzanie danymi\n\nWyzwanie:\nW systemach real-time musimy nie tylko analizowaÄ‡ dane w czasie rzeczywistym, ale takÅ¼e zapewniÄ‡ ich wysokÄ… jakoÅ›Ä‡. W przeciwnym razie analizy mogÄ… prowadziÄ‡ do bÅ‚Ä™dnych wnioskÃ³w lub opÃ³ÅºnieÅ„ w reagowaniu na nieprawidÅ‚owe dane.\nZanieczyszczone dane: W systemach real-time dane czÄ™sto sÄ… niepeÅ‚ne, brudne, bÅ‚Ä™dne lub nieuporzÄ…dkowane. Zmiana charakterystyki danych: Dane mogÄ… zmieniaÄ‡ siÄ™ w czasie, co moÅ¼e utrudniaÄ‡ ich przetwarzanie i analizÄ™. #### RozwiÄ…zanie:\nData cleansing i data validation na wstÄ™pnym etapie procesu. Automatyczne systemy monitorowania jakoÅ›ci danych w celu wykrywania bÅ‚Ä™dÃ³w w czasie rzeczywistym. ZarzÄ…dzanie danymi w strumieniu: NarzÄ™dzia takie jak Apache Kafka pozwalajÄ… na filtrowanie i oczyszczanie danych w locie.\n\n\n\nZÅ‚oÅ¼onoÅ›Ä‡ integracji systemÃ³w\n\nWyzwanie:\nSystemy analizy danych w czasie rzeczywistym czÄ™sto muszÄ… wspÃ³Å‚pracowaÄ‡ z istniejÄ…cymi systemami IT i ÅºrÃ³dÅ‚ami danych (np. bazami danych, czujnikami IoT, aplikacjami). Integracja tych systemÃ³w, zwÅ‚aszcza w rozproszonej architekturze, moÅ¼e byÄ‡ skomplikowana.\n\n\nRozwiÄ…zanie:\nUÅ¼ywanie API do Å‚atwiejszej integracji z zewnÄ™trznymi systemami. Mikroserwisy i konteneryzacja z pomocÄ… narzÄ™dzi takich jak Docker i Kubernetes. Przetwarzanie w chmurze, ktÃ³re umoÅ¼liwia Å‚atwÄ… integracjÄ™ rÃ³Å¼nych ÅºrÃ³deÅ‚ danych oraz zapewnia elastycznoÅ›Ä‡ w dostosowywaniu systemÃ³w do rosnÄ…cych potrzeb.\n\n\n\nBezpieczeÅ„stwo i prywatnoÅ›Ä‡\n\nWyzwanie:\nPrzetwarzanie danych w czasie rzeczywistym wiÄ…Å¼e siÄ™ z ogromnÄ… iloÅ›ciÄ… wraÅ¼liwych informacji, szczegÃ³lnie w branÅ¼ach takich jak finanse, zdrowie czy e-commerce. Zapewnienie, Å¼e dane sÄ… odpowiednio chronione przed nieautoryzowanym dostÄ™pem, jest kluczowe.\nOchrona danych w czasie transmisji: MuszÄ… byÄ‡ szyfrowane zarÃ³wno podczas przesyÅ‚ania, jak i przechowywania. Zabezpieczenia przed atakami: Przetwarzanie danych w czasie rzeczywistym moÅ¼e byÄ‡ celem atakÃ³w, takich jak DDoS czy SQL injection.\n\n\nRozwiÄ…zanie:\nSzyfrowanie danych zarÃ³wno w spoczynku, jak i podczas przesyÅ‚ania (np. TLS). Autentykacja i autoryzacja z wykorzystaniem nowoczesnych technologii bezpieczeÅ„stwa. ZgodnoÅ›Ä‡ z regulacjami prawnymi, np. RODO w Unii Europejskiej czy GDPR w przypadku danych osobowych.\n\n\n\nZarzÄ…dzanie bÅ‚Ä™dami i awariami\n\nWyzwanie:\nBÅ‚Ä™dy i awarie w systemach real-time mogÄ… prowadziÄ‡ do powaÅ¼nych konsekwencji, w tym utraty danych, opÃ³ÅºnieÅ„ w analizach czy nawet usuniÄ™cia usÅ‚ug. W systemach rozproszonych trudno jest osiÄ…gnÄ…Ä‡ peÅ‚nÄ… niezawodnoÅ›Ä‡.\n\n\nRozwiÄ…zanie:\nRedundancja: Tworzenie kopii zapasowych systemÃ³w i danych. Systemy monitorowania i alertowania (np. Prometheus, Grafana), ktÃ³re pozwalajÄ… na szybkie wykrycie i naprawienie problemÃ³w. ZarzÄ…dzanie stanem: DziÄ™ki uÅ¼yciu narzÄ™dzi jak Apache Kafka, moÅ¼na ponownie przetwarzaÄ‡ dane, jeÅ›li wystÄ…piÅ‚ bÅ‚Ä…d w transmisji.\n\n\n\nKoszty zwiÄ…zane z infrastrukturÄ…\n\nWyzwanie:\nPrzetwarzanie danych w czasie rzeczywistym wymaga odpowiedniej infrastruktury, ktÃ³ra zapewni odpowiedniÄ… moc obliczeniowÄ… i pamiÄ™Ä‡. To moÅ¼e wiÄ…zaÄ‡ siÄ™ z duÅ¼ymi kosztami, szczegÃ³lnie gdy dane muszÄ… byÄ‡ przechowywane i przetwarzane w czasie rzeczywistym na duÅ¼Ä… skalÄ™.\n\n\nRozwiÄ…zanie:\nChmura obliczeniowa: MoÅ¼liwoÅ›Ä‡ elastycznego skalowania zasobÃ³w w chmurze. Serverless computing: Technologie takie jak AWS Lambda pozwalajÄ… na uruchamianie procesÃ³w bez potrzeby utrzymywania staÅ‚ej infrastruktury.\nChociaÅ¼ analiza danych w czasie rzeczywistym oferuje ogromne korzyÅ›ci, wiÄ…Å¼e siÄ™ takÅ¼e z wieloma wyzwaniami. WÅ‚aÅ›ciwa architektura, narzÄ™dzia i technologie, takie jak Apache Kafka, Flink, Spark czy Kubernetes, mogÄ… pomÃ³c w przezwyciÄ™Å¼eniu wielu z tych trudnoÅ›ci. Warto rÃ³wnieÅ¼ pamiÄ™taÄ‡ o koniecznoÅ›ci zapewnienia wysokiej jakoÅ›ci danych, ich bezpieczeÅ„stwa, a takÅ¼e elastycznoÅ›ci i skalowalnoÅ›ci systemÃ³w, ktÃ³re bÄ™dÄ… w stanie sprostaÄ‡ rosnÄ…cym wymaganiom."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-D\nSemestr: 2024/2025 Uczelnia: SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nPodstawowe informacje o kursie znajdziesz w sylabusie.\nPolecane materiaÅ‚y znajdziesz na liÅ›cie ksiÄ…Å¼ek.\nMateriaÅ‚y z wykÅ‚adu i laboratoriÃ³w nie sÄ… wspierane przez Google. ObecnoÅ›Ä‡ na wykÅ‚adach i Ä‡wiczeniach nie zmniejszy Twoich 5 dolarÃ³w."
  },
  {
    "objectID": "index.html#analiza-danych-w-czasie-rzeczywistym",
    "href": "index.html#analiza-danych-w-czasie-rzeczywistym",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-D\nSemestr: 2024/2025 Uczelnia: SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nPodstawowe informacje o kursie znajdziesz w sylabusie.\nPolecane materiaÅ‚y znajdziesz na liÅ›cie ksiÄ…Å¼ek.\nMateriaÅ‚y z wykÅ‚adu i laboratoriÃ³w nie sÄ… wspierane przez Google. ObecnoÅ›Ä‡ na wykÅ‚adach i Ä‡wiczeniach nie zmniejszy Twoich 5 dolarÃ³w."
  },
  {
    "objectID": "index.html#kalendarz",
    "href": "index.html#kalendarz",
    "title": "Informacje ogÃ³lne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykÅ‚ad\nWykÅ‚ad jest realizowany w trybie stacjonarnym. Jest on NIEOBOWIÄ„ZKOWY i odbywa siÄ™ w Auli VI bud G\n\n18-02-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 1\n25-02-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 2\n04-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 3\n11-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 4\n18-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 5\n\nWykÅ‚ad 5 koÅ„czy siÄ™ TESTEM: 20 pytaÅ„ - 30 minut. Test przeprowadzany jest za poÅ›rednictwem MS Teams.\n\n\nLaboratoria\n\nLab1\n24-03-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n25-03-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab2\n31-03-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n01-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab3\n07-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n08-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab4\n14-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n15-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab5\n28-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n29-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab6\n05-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n06-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab7\n12-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n13-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab8\n19-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n20-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab9\n26-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n27-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab10\n02-06-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n03-06-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\n\nZaliczenie i Egzamin\nWykÅ‚ady zakoÅ„czÄ… siÄ™ testem (podczas ostatnich zajÄ™Ä‡).\nAby zaliczyÄ‡ test, naleÅ¼y zdobyÄ‡ wiÄ™cej niÅ¼ 13 punktÃ³w â€“ jest to warunek konieczny do uczestnictwa w Ä‡wiczeniach.\nLaboratoria\nPodczas laboratoriÃ³w bÄ™dÄ… zadawane prace domowe, ktÃ³re naleÅ¼y przesyÅ‚aÄ‡ za poÅ›rednictwem MS Teams. KaÅ¼dy brak pracy domowej obniÅ¼a koÅ„cowÄ… ocenÄ™ o 0,5 stopnia.\n\nProjekt\nProjekty naleÅ¼y realizowaÄ‡ w grupach maksymalnie 5-osobowych.\nWymagania projektu\n\nProjekt powinien rozwiÄ…zywaÄ‡ realny problem biznesowy, ktÃ³ry moÅ¼na opracowaÄ‡ przy uÅ¼yciu danych przetwarzanych w trybie online. (Nie wyklucza to uÅ¼ycia przetwarzania wsadowego, np. do generowania modelu).\nDane powinny byÄ‡ przesyÅ‚ane do Apache Kafka, skÄ…d bÄ™dÄ… poddawane dalszemu przetwarzaniu i analizie.\nMoÅ¼na uÅ¼ywaÄ‡ dowolnego jÄ™zyka programowania w kaÅ¼dym komponencie projektu.\nMoÅ¼na wykorzystaÄ‡ narzÄ™dzia BI.\nÅ¹rÃ³dÅ‚em danych moÅ¼e byÄ‡ dowolne API, sztucznie generowane dane, IoT itp."
  },
  {
    "objectID": "index.html#technologie",
    "href": "index.html#technologie",
    "title": "Informacje ogÃ³lne",
    "section": "Technologie",
    "text": "Technologie\nUczestniczÄ…c w zajÄ™ciach musisz opanowaÄ‡ i przynajmniej w podstawowym zakresie posÅ‚ugiwaÄ‡ siÄ™ nastÄ™pujÄ…cymi technologiami informatycznymi:\n\nGIT\nPython, Jupyter notebook, Jupyter lab, Colab\nDocker\nApache Spark, Apache Kafka\nDatabricks Community edition Web page."
  },
  {
    "objectID": "old_lectures/wyklad2.html",
    "href": "old_lectures/wyklad2.html",
    "title": "Analiza strumieni danych",
    "section": "",
    "text": "Oczekiwania vs RzeczywistoÅ›Ä‡\n\nKiedy podjÄ…Ä‡ decyzjÄ™ biznesowÄ… ?\n\n\n\n\nBatch = DuÅ¼e, historyczne zbiory\nStream = StrumieÅ„ danych, on line, przesyÅ‚ane w trybie ciÄ…gÅ‚ym\n\n\n\n\n\nBatch = minuty, godziny, dni (patrz Hurtownie danych)\nStream = Real-time/near-real-time\n\n\n\n\n\nBatch = moÅ¼liwe i stosowane bardzo czesto\nStream = ,,niemoÅ¼liweâ€™â€™\n\n\n\n\n\nExtract, Transform, Load is a basic pattern for data processing, commonly known in data warehousing. Itâ€™s all about extracting data from a source, transforming the data (business rules) and at the end writing/loading everything to a target (Hadoop, Relational Database, Data Warehouse etc.)\n\n\n\nSystemy Big data mogÄ… byÄ‡ czÄ™Å›ciÄ… (ÅºrÃ³dÅ‚em) dla hurtowni danych (np. Data Lake, Enterprise Data Hub)\nAle Hurtownie danych nie sÄ… systemami Big Data!\n\nHurtownie danych\n\n\nprzetrzymywanie danych wysoko strukturyzowanych\nskupione na analizach i procesie raportowania\n100% accuracy\n\n\nBig Data\n\n\ndane o dowolnej strukturze\nsÅ‚uÅ¼y do rÃ³Å¼norodnych celÃ³w opartych na danych (analityka, data science â€¦)\nponiÅ¼ej 100% accuracy\n\n\n\n\n\nGdy mÃ³wimy o skali (nie o jÄ™zyku Scala), najczÄ™Å›ciej przychodzi nam na myÅ›l przeglÄ…darka Google. Przeszukuje ona ogromne zbiory danychz duÅ¼Ä… prÄ™dkoÅ›ciÄ…. Sama nazwa Goolge wskasuje na skalÄ™ (colowo przyjÄ™to bÅ‚Ä™dnÄ… nazwÄ™ w zapisie googol co oznacza 1 i 100 zer).\n\nSprawdÅº czy do koÅ„ca zajÄ™Ä‡ uda Ci siÄ™ zapisaÄ‡ liczbÄ™ googol na kartce.\n\nPowinno byÄ‡ dla Ciebie jasne, Å¼e Å¼adne tradycyjne systemy, np relacyjne systemy baz danych, ani programowanie imperatywne nie sÄ… w stanie obÅ‚uÅ¼yÄ‡ przeszukiwania takiej iloÅ›ci danych. Problemy te doprowadziÅ‚y do budowy rozproszonych systemÃ³w plikÃ³w Google File System, MapReduce (paradygmat programowania rÃ³wnolegÅ‚ego), czy Bigtable (skalowalna pamiÄ™Ä‡ masowa ustrukturyzowanych danych znajdujÄ…cych siÄ™ na GFS).\n\n\nZnajdÅº prosty algorytm map reduce w dowolnym jÄ™zyku programowania i uruchom go.\n\n\nJak poprawiÄ‡ ?"
  },
  {
    "objectID": "old_lectures/wyklad2.html#batch-vs-stream-processing",
    "href": "old_lectures/wyklad2.html#batch-vs-stream-processing",
    "title": "Analiza strumieni danych",
    "section": "",
    "text": "Oczekiwania vs RzeczywistoÅ›Ä‡\n\nKiedy podjÄ…Ä‡ decyzjÄ™ biznesowÄ… ?\n\n\n\n\nBatch = DuÅ¼e, historyczne zbiory\nStream = StrumieÅ„ danych, on line, przesyÅ‚ane w trybie ciÄ…gÅ‚ym\n\n\n\n\n\nBatch = minuty, godziny, dni (patrz Hurtownie danych)\nStream = Real-time/near-real-time\n\n\n\n\n\nBatch = moÅ¼liwe i stosowane bardzo czesto\nStream = ,,niemoÅ¼liweâ€™â€™\n\n\n\n\n\nExtract, Transform, Load is a basic pattern for data processing, commonly known in data warehousing. Itâ€™s all about extracting data from a source, transforming the data (business rules) and at the end writing/loading everything to a target (Hadoop, Relational Database, Data Warehouse etc.)\n\n\n\nSystemy Big data mogÄ… byÄ‡ czÄ™Å›ciÄ… (ÅºrÃ³dÅ‚em) dla hurtowni danych (np. Data Lake, Enterprise Data Hub)\nAle Hurtownie danych nie sÄ… systemami Big Data!\n\nHurtownie danych\n\n\nprzetrzymywanie danych wysoko strukturyzowanych\nskupione na analizach i procesie raportowania\n100% accuracy\n\n\nBig Data\n\n\ndane o dowolnej strukturze\nsÅ‚uÅ¼y do rÃ³Å¼norodnych celÃ³w opartych na danych (analityka, data science â€¦)\nponiÅ¼ej 100% accuracy\n\n\n\n\n\nGdy mÃ³wimy o skali (nie o jÄ™zyku Scala), najczÄ™Å›ciej przychodzi nam na myÅ›l przeglÄ…darka Google. Przeszukuje ona ogromne zbiory danychz duÅ¼Ä… prÄ™dkoÅ›ciÄ…. Sama nazwa Goolge wskasuje na skalÄ™ (colowo przyjÄ™to bÅ‚Ä™dnÄ… nazwÄ™ w zapisie googol co oznacza 1 i 100 zer).\n\nSprawdÅº czy do koÅ„ca zajÄ™Ä‡ uda Ci siÄ™ zapisaÄ‡ liczbÄ™ googol na kartce.\n\nPowinno byÄ‡ dla Ciebie jasne, Å¼e Å¼adne tradycyjne systemy, np relacyjne systemy baz danych, ani programowanie imperatywne nie sÄ… w stanie obÅ‚uÅ¼yÄ‡ przeszukiwania takiej iloÅ›ci danych. Problemy te doprowadziÅ‚y do budowy rozproszonych systemÃ³w plikÃ³w Google File System, MapReduce (paradygmat programowania rÃ³wnolegÅ‚ego), czy Bigtable (skalowalna pamiÄ™Ä‡ masowa ustrukturyzowanych danych znajdujÄ…cych siÄ™ na GFS).\n\n\nZnajdÅº prosty algorytm map reduce w dowolnym jÄ™zyku programowania i uruchom go.\n\n\nJak poprawiÄ‡ ?"
  },
  {
    "objectID": "old_lectures/wyklad2.html#strumienie-danych",
    "href": "old_lectures/wyklad2.html#strumienie-danych",
    "title": "Analiza strumieni danych",
    "section": "Strumienie danych",
    "text": "Strumienie danych\nStrumieniowanie moÅ¼esz kojarzyÄ‡ z serwisÃ³w przesyÅ‚ajÄ…cych video w trybie online. Gdy oglÄ…dasz swÃ³j ulubiony serial (tak jak teraz na zajÄ™ciach) serwis odpowiadajÄ…cy za strumieniowanie w nieprzerwany sposÃ³b przesyÅ‚a do ciebie kolejne â€œporcjeâ€ video. Identycznie koncepcja ta realizowana jest w przypadku danych strumieniowych. Format przesyÅ‚anych porcji nie musi byÄ‡ plikiem video, wszystko zaleÅ¼y od celu realizowanego biznesowo. Np. ciÄ…gÅ‚y pomiar z rÃ³Å¼nego rodzaju czujnikÃ³w w farbykach, elektrowniach itp. Warto odnotowaÄ‡, Å¼e masz do czynienia z ciÄ…gÅ‚ym strumieniem danych, ktÃ³re przetwarzaÄ‡ musisz w czasie rzeczywistym. Nie moÅ¼esz czekaÄ‡ do zatrzymania linii produkcyjnych w celu wykonania analizy, wszystkie pojawiajÄ…ce siÄ™ problemy chcesz rejestrowaÄ‡ natychmiast i jak najszybciej na nie reagowaÄ‡.\n\nAnaliza strumieni danych to ciÄ…gÅ‚e przetwarzanie i analiza duÅ¼ych zbiorÃ³w danych w ruchu.\n\nPorÃ³wnuj to do wsakazanych powyÅ¼ej elementÃ³w Big Data. Przetwarzanie Batchowe jest przeciwieÅ„stwem do przetwarzania strumieniowego. Najpierw zbierasz duÅ¼e iloÅ›ci danych a potem realizujesz analizy. MoÅ¼esz oczywiÅ›cie zawsze pobraÄ‡ video w caÅ‚oÅ›ci zanim je obejrzysz, ale czy miaÅ‚oby to sens? IstniejÄ… przypadki gdy takie podejÅ›cie nie stanowi problemu, ale juÅ¼ tu widzisz, Å¼e przetwarzanie strumieniowe moÅ¼e przynieÅ›Ä‡ dla biznesu dodatkowe wartoÅ›ci dodane, ktÃ³rych trudno oczekiwaÄ‡ przy wsadowym przetwarzaniu.\nciekawe informacje\n\nAnaliza danych w czasie rzeczywistym a przetwarzanie strumienia zdarzeÅ„\nÅatwo jest poÅ‚Ä…czyÄ‡ analizÄ™ w czasie rzeczywistym i analizÄ™ strumieniowÄ… (lub przetwarzanie strumienia zdarzeÅ„). Ale chociaÅ¼ technologie analizy strumieniowej mogÄ… umoÅ¼liwiaÄ‡ analizÄ™ w czasie rzeczywistym, to nie to samo!\nAnaliza strumieniowa polega na przetwarzaniu danych w ruchu. Analityka w czasie rzeczywistym to dowolna metoda przetwarzania danych, ktÃ³ra skutkuje okresem opÃ³Åºnienia okreÅ›lanym jako â€w czasie rzeczywistymâ€.\nZazwyczaj systemy analizy czasu rzeczywistego sÄ… definiowane jako twarde i miÄ™kkie systemy czasu rzeczywistego. Niedotrzymanie terminu w twardych systemach czasu rzeczywistego, takich jak samolot, jest katastrofalne, a w miÄ™kkich systemach czasu rzeczywistego, takich jak stacja pogodowa, niedotrzymanie terminÃ³w moÅ¼e prowadziÄ‡ do bezuÅ¼ytecznych danych.\nPonadto, podczas gdy analiza strumieniowa implikuje istnienie architektury strumieniowej, analiza w czasie rzeczywistym nie implikuje Å¼adnej konkretnej architektury.\nWszystko, co implikuje analityka w czasie rzeczywistym, polega na tym, Å¼e tworzenie i przetwarzanie danych odbywa siÄ™ w dowolnym czasie, ktÃ³ry firma definiuje jako â€w czasie rzeczywistymâ€.\n\n\nÅ¹rÃ³dÅ‚a danych przesyÅ‚anych strumieniowo obejmujÄ…:\n\nczujniki sprzÄ™tu,\nstrumienie klikniÄ™Ä‡,\nÅ›ledzenie lokalizacji\ninterackcja z uÅ¼ytkownikiem: co robiÄ… uÅ¼ytkownicy Twojej witryny?\nkanaÅ‚y mediÃ³w spoÅ‚ecznoÅ›ciowych,\nnotowania gieÅ‚dowe,\naktywnoÅ›Ä‡ w aplikacjach\ninne.\n\nFirmy wykorzystujÄ… analitykÄ™ strumieniowÄ… do odkrywania i interpretowania wzorcÃ³w, tworzenia wizualizacji, przekazywania spostrzeÅ¼eÅ„ i alertÃ³w oraz uruchamiania procesÃ³w w czasie rzeczywistym lub zbliÅ¼onym do rzeczywistego."
  },
  {
    "objectID": "old_lectures/wyklad2.html#uzasadnienie-biznesowe",
    "href": "old_lectures/wyklad2.html#uzasadnienie-biznesowe",
    "title": "Analiza strumieni danych",
    "section": "Uzasadnienie biznesowe",
    "text": "Uzasadnienie biznesowe\nAnalityka sÅ‚uÅ¼y do znajdowania znaczÄ…cych wzorcÃ³w w danych i odkrywania nowej wiedzy. Dotyczy to zarÃ³wno transmisji strumieniowych, jak i tradycyjnych analiz.\nAle w dzisiejszym Å›wiecie natura â€znajdowania sensownych wzorcÃ³w w danychâ€ ulegÅ‚a zmianie, poniewaÅ¼ zmieniÅ‚ siÄ™ charakter danych. SzybkoÅ›Ä‡, objÄ™toÅ›Ä‡ i rodzaje danych eksplodowaÅ‚y.\nTwitter produkuje ponad 500 milionÃ³w tweetÃ³w dziennie. IDC przewiduje, Å¼e do 2025 roku urzÄ…dzenia Internetu rzeczy (IoT) bÄ™dÄ… w stanie wygenerowaÄ‡ 79,4 zettabajtÃ³w (ZB) danych. I te trendy nie wykazujÄ… oznak spowolnienia.\nBiorÄ…c pod uwagÄ™ nowy charakter danych, gÅ‚Ã³wnÄ… zaletÄ… analizy strumieniowej jest to, Å¼e pomaga ona firmom znajdowaÄ‡ znaczÄ…ce wzorce w danych i odkrywaÄ‡ nowÄ… wiedzÄ™ ,,w czasie rzeczywistymâ€ lub zbliÅ¼onym do rzeczywistego.\n\nktÃ³ry pojazd firmowej floty ma prawie pusty bak i gdzie wysÅ‚aÄ‡ prowadzÄ…cego pojazd do tankowania.\nKtÃ³ry pojazd floty zuÅ¼ywa najwiÄ™cej paliwa i dlaczego?\nKtÃ³re urzÄ…dzenia w zakÅ‚adzie czy fabryce mogÄ… ulec awarii w ciÄ…gu najbliÅ¼szych dni?\nJakie czÄ™Å›ci zamienne trzeba bÄ™dzie wymieniÄ‡ i w ktÃ³rych maszynach w najbliÅ¼szym czasie ?\nIlu klientÃ³w aktualnie robi zakupy w sklepie i czy moÅ¼na im coÅ› zaproponowaÄ‡ ?\nCzy klient dzwoni w celu zerwania umowy ?\ni wiele wiele innych.\n\n\nPrzykÅ‚adowe biznesowe zastosowania\n\nDane z sensorÃ³w IoT i detekcja anomalii\nStock Trading (problemy regresyjne) - czas reagowania na zmiany i czas zakupy i sprzedaÅ¼y akcji.\nClickstream for websites (problem klasyfikacji) - Å›ledzenie i analiza goÅ›ci na stronie serwisu internetowego - personalizacja strony i treÅ›ci.\n\n8 najlepszych przykÅ‚adÃ³w analizy w czasie rzeczywistym\nBiznesowe zastosowania"
  },
  {
    "objectID": "old_lectures/wyklad2.html#definicje",
    "href": "old_lectures/wyklad2.html#definicje",
    "title": "Analiza strumieni danych",
    "section": "Definicje",
    "text": "Definicje\nZapoznaj siÄ™ z tematem danych strumieniowych\n\nDefinicja 1 - Zdarzenie czyli wszystko co moÅ¼emy zaobserwowaÄ‡ w pewnej chwili czasu. Generowane sÄ… jako bezpoÅ›redni skutek dziaÅ‚ania.\nDefinicja 2 - W przypadku danych zdarzenie rozumiemy jako niezmienialny rekord w strumieniu danych zakodowany jako JSON, XML, CSV lub binarnie.\nDefinicja 3 - CiÄ…gÅ‚y strumieÅ„ zdarzeÅ„ to nieskoÅ„czony zbiÃ³r pojedynczych zdarzeÅ„ uporzÄ…dkowanych w czasie np. logi z urzÄ…dzenia.\nDefinicja 4 - StrumieÅ„ danych to dane tworzone przyrostowo w czasie, generowane ze statycznych danych (baza danych, czytanie lini z pliku) bÄ…dÅº w sposÃ³b dynamiczny (logi, sensory, funkcje).\n\n\nPrzedsiÄ™biorstwo to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„.\n\nAnalityka strumieniowa (ang. stream analytics) nazywana jest rÃ³wnieÅ¼ przetwarzaniem strumieniowym zdarzeÅ„ (ang. event stream processing) - przetwarzanie duÅ¼ej iloÅ›ci danych juÅ¼ na etapie ich generowania.\nNiezaleÅ¼nie od zastosowanej technologi wszystkie dane powstajÄ… jako ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„ (dziaÅ‚ania uÅ¼ytkownikÃ³w na stronie www, logi systemowe, pomiary z sensorÃ³w)."
  },
  {
    "objectID": "old_lectures/wyklad2.html#czas-w-analizie-danych-w-czasie-rzeczywistym",
    "href": "old_lectures/wyklad2.html#czas-w-analizie-danych-w-czasie-rzeczywistym",
    "title": "Analiza strumieni danych",
    "section": "Czas w analizie danych w czasie rzeczywistym",
    "text": "Czas w analizie danych w czasie rzeczywistym\nW przypadku przetwarzania wsadowego przetwarzamy dane historyczne i czas uruchomienia procesu przetwarzania nie ma nic wspÃ³lnego z czasem wystÄ™powania analizowanych zdarzeÅ„.\nDla danych strumieniowych mamy dwie koncepcje czasu:\n\nczas zdarzenia (event time) - czas w ktÃ³rym zdarzenie siÄ™ wydarzyÅ‚o.\nczas przetwarzania (processing time) - czas w ktÃ³rym system przetwarza zdarzenie.\n\nW przypadku idealnej sytuacji:\n\nW rzeczywistoÅ›ci przetwarzanie danych zawsze odbywa siÄ™ z pewnym opÃ³Åºnieniem, co reprezentowane jest przez punkty pojawiajÄ…ce siÄ™ poniÅ¼ej funkcji dla sytuacji idealnej (poniÅ¼ej diagonalnej).\n\nW aplikacjach przetwarzania strumieniowego istotne okazujÄ… siÄ™ rÃ³Å¼nice miedzy czasem powstania zdarzenia i jego procesowania. Do najczÄ™stszych przyczyn opÃ³Åºnienia wyszczegÃ³lnia siÄ™ przesyÅ‚anie danych przez sieÄ‡ czy brak komunikacji miÄ™dzy urzÄ…dzeniem a sieciÄ…. Prostym przykÅ‚adem jest tu przejazd samochodem przez tunel i Å›ledzenie poÅ‚oÅ¼enia przez aplikacjÄ™ GPS.\nMoÅ¼esz oczywiÅ›cie zliczaÄ‡ iloÅ›Ä‡ takich pominiÄ™tych zdarzeÅ„ i uruchomiÄ‡ alarm w sytuacji gdy takich odrzutÃ³w bÄ™dzie za duÅ¼o. Drugim (chyba czÄ™Å›ciej) wykorzystywanym sposobem jest zastosowanie korekty z wykorzystaniem tzw. watermarkingu.\nProces przetwarzania zdarzeÅ„ w czasie rzeczywistym moÅ¼na przedstawiÄ‡ w postaci funkcji schodkowej, reprezentowanej na rysunku: \nJak moÅ¼na zauwaÅ¼yÄ‡ nie wszystkie zdarzenia wnoszÄ… wkÅ‚ad do analizy i przetwarzania. RealizacjÄ™ procesu przetwarzania wraz z uwzglÄ™dnieniem dodatkowego czasu na pojawienie siÄ™ zdarzeÅ„ (watermark) moÅ¼na przedstawiÄ‡ jako proces obejmujÄ…cy wszystkie zdarzenia powyÅ¼ej przerywanej linii. Dodatkowy czas pozwoliÅ‚ na przetworzenie dodatkowych zdarzeÅ„, natomiast nadal mogÄ… zdarzyÄ‡ siÄ™ punkty, ktÃ³re nie bÄ™dÄ… brane pod uwagÄ™.  \nPrzedstawione na wykresach sytuacje jawnie wskazujÄ… dlaczego pojÄ™cie czasu jest istotnym czynnikiem i wymaga Å›cisÅ‚ego okreÅ›lenia juÅ¼ na poziomie definiowania potrzeb biznesowych. Przypisywanie znacznikÃ³w czasu do danych (zdarzeÅ„) to trudne zadanie."
  },
  {
    "objectID": "old_lectures/wyklad2.html#okna-czasowe",
    "href": "old_lectures/wyklad2.html#okna-czasowe",
    "title": "Analiza strumieni danych",
    "section": "okna czasowe",
    "text": "okna czasowe\nOkno rozÅ‚Ä…czne (ang. tumbling window) czyli okno o staÅ‚ej dÅ‚ugoÅ›ci. Jego cechÄ… charakterystycznÄ… jest to, iÅ¼ kaÅ¼de zdarzenie naleÅ¼y tylko do jednego okna.  \nOkno przesuwne (ang. sliding window) obejmuje wszystkie zdarzenia nastÄ™pujÄ…ce w okreÅ›lonej dÅ‚ugoÅ›ci miÄ™dzy sobÄ….  \nOkno skokowe (ang. hopping window) tak jak okno rozÅ‚Ä…czne ma staÅ‚Ä… dÅ‚ugoÅ›Ä‡, ale pozwala siÄ™ w nim na zachodzenie jednych okien na inne. Stosowane zazwyczaj do wygÅ‚adzenia danych."
  },
  {
    "objectID": "old_lectures/wyklad2.html#aplikacje-dla-strumieniowania-danych",
    "href": "old_lectures/wyklad2.html#aplikacje-dla-strumieniowania-danych",
    "title": "Analiza strumieni danych",
    "section": "Aplikacje dla strumieniowania danych",
    "text": "Aplikacje dla strumieniowania danych\nAplikacja przetwarzajÄ…ca strumieÅ„ zdarzeÅ„ powinna umoÅ¼liwiaÄ‡ przetworzenie i zapisanie zdarzenia oraz dostÄ™p (w tym samym czasie) do innych danych tak by mÃ³c dane zdarzenie przetworzyÄ‡ (wykonaÄ‡ na nim dowolne przeliczenie) i zapisaÄ‡ jako stan lokalny. Stan ten moÅ¼e byÄ‡ zapisywany w wielu miejscach np. zmienne w programie, pliki lokalne, wew i zew bazy danych. JednÄ… z najbardziej znanych aplikacji tego typu jest Apache Kafka, ktÃ³rÄ… moÅ¼na Å‚Ä…czyÄ‡ np. z Apache Spark bÄ…dÅº Apache Flink.\nPorÃ³wnanie z aplikacjÄ… w trybie batch\n\nWiedza:\n\nZna mozÌ‡liwosÌci i obszary zastosowania procesowania danych w czasie rzeczywistym\nRozumie potrzeby biznesowe podejmowania decyzji w bardzo kroÌtkim czasie\n\n\n\nUmiejÄ™tnoÅ›ci:\n\nRozumie ograniczenia wynikajaÌ¨ce z czasu przetwarzania przez urzaÌ¨dzenia oraz systemy informatyczne\n\n\n\nKompetencje:\n\nUtrwala umiejeÌ¨tnosÌcÌ samodzielnego uzupeÅ‚niania wiedzy teoretycznej jak i praktycznej w zakresie programowania, modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym.\nFormuÅ‚uje problem analityczny wraz z jego informatycznym rozwiaÌ¨zaniem"
  },
  {
    "objectID": "old_lectures/wyklad4.html",
    "href": "old_lectures/wyklad4.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "Architektura przesyÅ‚ania strumieniowego to okreÅ›lony zestaw technologii, ktÃ³re wspÃ³Å‚pracujÄ… ze sobÄ… w celu obsÅ‚ugi przetwarzania strumieniowego, co jest praktykÄ… podejmowania dziaÅ‚aÅ„ na serii danych w momencie ich tworzenia. W wielu nowoczesnych wdroÅ¼eniach Apache Kafka dziaÅ‚a jako magazyn danych przesyÅ‚anych strumieniowo, a nastÄ™pnie wiele procesorÃ³w strumieniowych moÅ¼e dziaÅ‚aÄ‡ na danych przechowywanych w Kafce w celu wygenerowania wielu danych wyjÅ›ciowych. NiektÃ³re architektury przesyÅ‚ania strumieniowego obejmujÄ… przepÅ‚ywy pracy zarÃ³wno do przetwarzania strumieniowego, jak i przetwarzania wsadowego, ktÃ³re obejmujÄ… inne technologie do obsÅ‚ugi przetwarzania wsadowego na duÅ¼Ä… skalÄ™ lub wykorzystujÄ… KafkÄ™ jako magazyn centralny, jak okreÅ›lono w architekturze Kappa.\nDoskonaÅ‚a architektura przetwarzania danych w czasie rzeczywistym musi byÄ‡ odporna na bÅ‚Ä™dy i skalowalna; musi obsÅ‚ugiwaÄ‡ aktualizacje wsadowe i przyrostowe oraz byÄ‡ rozszerzalna.\nNa poczÄ…tku badamy dwie podstawowe architektury przetwarzania danych, Lambda i Kappa, ktÃ³re stanowiÄ… podstawÄ™ rÃ³Å¼nych aplikacji korporacyjnych.\n\n\nArchitektura Lambda obejmuje warstwÄ™ wsadowÄ… (batch layer), warstwÄ™ strumieniowa (stream layer) i warstwÄ™ serwowania.\nWarstwa wsadowa dziaÅ‚a na peÅ‚nych danych, dziÄ™ki czemu system moÅ¼e generowaÄ‡ najdokÅ‚adniejsze wyniki. Jednak wyniki sÄ… okupione duÅ¼ymi opÃ³Åºnieniami wynikajÄ…cymi z dÅ‚ugiego czasu obliczeÅ„. Warstwa wsadowa przechowuje surowe dane w miarÄ™ ich nadejÅ›cia i oblicza widoki wsadowe do wykorzystania. Naturalnie procesy wsadowe bÄ™dÄ… wystÄ™powaÄ‡ w pewnych odstÄ™pach czasu i bÄ™dÄ… dÅ‚ugotrwaÅ‚e. Zakres danych wynosi od godzin do kilku lat.\nWarstwa strumieniowa:\n\ngeneruje wyniki z maÅ‚ymi opÃ³Åºnieniami i w czasie zbliÅ¼onym do rzeczywistego.\noblicza widoki w czasie rzeczywistym w celu uzupeÅ‚nienia widokÃ³w wsadowych.\nodbiera napÅ‚ywajÄ…ce dane i aktualizuje wyniki warstwy wsadowej. Koszt obliczeÅ„ jest znacznie obniÅ¼ony dziÄ™ki algorytmom przyrostowym zaimplementowanym w warstwie szybkoÅ›ci.\n\nWidoki wsadowe mogÄ… byÄ‡ przetwarzane przy uÅ¼yciu bardziej zÅ‚oÅ¼onych lub kosztownych reguÅ‚ i mogÄ… mieÄ‡ lepszÄ… jakoÅ›Ä‡ danych i mniej przekrzywieÅ„, podczas gdy widoki w czasie rzeczywistym zapewniajÄ… bieÅ¼Ä…cy dostÄ™p do najnowszych moÅ¼liwych danych.\nWreszcie warstwa serwujÄ…ca umoÅ¼liwia rÃ³Å¼ne zapytania o wyniki przesÅ‚ane z warstw wsadowych i szybkich. Dane wyjÅ›ciowe z warstwy wsadowej w postaci widokÃ³w wsadowych i warstwy szybkoÅ›ci w postaci opinii w czasie zbliÅ¼onym do rzeczywistego sÄ… przekazywane do warstwy obsÅ‚ugujÄ…cej, ktÃ³ra wykorzystuje te dane do obsÅ‚ugi oczekujÄ…cych zapytaÅ„ na zasadzie ad-hoc.\n  Implementacja:  \nDobre bo:\n\nDobra rÃ³wnowaga miÄ™dzy szybkoÅ›ciÄ…, niezawodnoÅ›ciÄ… i skalowalnoÅ›ciÄ….\nDostÄ™p do wynikÃ³w zarÃ³wno w czasie rzeczywistym, jak i offline, bardzo dobrze pokrywa wiele scenariuszy analizy danych.\nDostÄ™p do peÅ‚nego zestawu danych w oknie wsadowym moÅ¼e przynieÅ›Ä‡ okreÅ›lone optymalizacje, ktÃ³re sprawiÄ…, Å¼e Lambda bÄ™dzie wydajniejsza i jeszcze prostsza do wdroÅ¼enia.\n\nKiepskie gdy:\n\nWewnÄ™trzna logika przetwarzania jest taka sama (warstwy wsadowe i warstwy czasu rzeczywistego) - wiele zduplikowanych moduÅ‚Ã³w i kodowania.\nZbiÃ³r danych modelowany za pomocÄ… architektury Lambda jest trudny do migracji i reorganizacji.\n\n\n\n\nArchitektura Kappa to architektura oprogramowania uÅ¼ywana do przetwarzania danych przesyÅ‚anych strumieniowo. GÅ‚Ã³wnym zaÅ‚oÅ¼eniem Architektury Kappa jest moÅ¼liwoÅ›Ä‡ wykonywania przetwarzania w czasie rzeczywistym i przetwarzania wsadowego, zwÅ‚aszcza w celach analitycznych, za pomocÄ… jednego stosu technologicznego. Opiera siÄ™ na architekturze przesyÅ‚ania strumieniowego, w ktÃ³rej przychodzÄ…ce serie danych sÄ… najpierw przechowywane w silniku przesyÅ‚ania wiadomoÅ›ci, takim jak Apache Kafka. StamtÄ…d silnik przetwarzania strumienia odczyta dane, przeksztaÅ‚ci je w format nadajÄ…cy siÄ™ do analizy, a nastÄ™pnie zapisze je w analitycznej bazie danych, aby uÅ¼ytkownicy koÅ„cowi mogli wyszukiwaÄ‡.\nArchitektura Kappa obsÅ‚uguje analizy (prawie) w czasie rzeczywistym, gdy dane sÄ… odczytywane i przeksztaÅ‚cane natychmiast po umieszczeniu ich w silniku przesyÅ‚ania komunikatÃ³w. DziÄ™ki temu najnowsze dane sÄ… szybko dostÄ™pne dla zapytaÅ„ uÅ¼ytkownikÃ³w koÅ„cowych. ObsÅ‚uguje rÃ³wnieÅ¼ analizÄ™ historycznÄ…, odczytujÄ…c zapisane dane przesyÅ‚ane strumieniowo z mechanizmu przesyÅ‚ania wiadomoÅ›ci pÃ³Åºniej w sposÃ³b wsadowy, aby utworzyÄ‡ dodatkowe moÅ¼liwe do analizy dane wyjÅ›ciowe dla wiÄ™kszej liczby typÃ³w analiz.\nArchitektura Kappa jest prostszÄ… alternatywÄ… dla architektury Lambda, poniewaÅ¼ wykorzystuje ten sam stos technologii do obsÅ‚ugi strumienia w czasie rzeczywistym i historycznego przetwarzania wsadowego. Obie architektury obejmujÄ… przechowywanie danych historycznych w celu umoÅ¼liwienia analiz na duÅ¼Ä… skalÄ™. Obie architektury sÄ… rÃ³wnieÅ¼ pomocne w rozwiÄ…zywaniu problemÃ³w zwiÄ…zanych z â€tolerancjÄ… bÅ‚Ä™dÃ³w ludzkichâ€, w ktÃ³rych problemy z kodem przetwarzania (bÅ‚Ä™dy lub znane ograniczenia) moÅ¼na przezwyciÄ™Å¼yÄ‡, aktualizujÄ…c kod i ponownie uruchamiajÄ…c go na danych historycznych. GÅ‚Ã³wna rÃ³Å¼nica w stosunku do architektury Kappa polega na tym, Å¼e wszystkie dane sÄ… traktowane jako strumieÅ„, wiÄ™c silnik przetwarzania strumienia dziaÅ‚a jako jedyny silnik transformacji danych.\n \nImplementation Example:  \n\n\n\n\nAplikacje mogÄ… odczytywaÄ‡ i zapisywaÄ‡ bezpoÅ›rednio do Kafki zgodnie z rozwojem. W przypadku istniejÄ…cych ÅºrÃ³deÅ‚ zdarzeÅ„ detektory sÄ… teraz przyzwyczajone do przesyÅ‚ania strumieniowego raportÃ³w z dziennikÃ³w bazy danych, co eliminuje koniecznoÅ›Ä‡ przetwarzania wsadowego podczas ruchu przychodzÄ…cego, co skutkuje mniejszÄ… liczbÄ… zasobÃ³w.\nZapytania muszÄ… uwzglÄ™dniaÄ‡ tylko jednÄ… lokalizacjÄ™ serwowania, zamiast sprawdzaÄ‡ widoki partii i szybkoÅ›ci.\n\n\n\n\n\nnieÅ‚atwe do wdroÅ¼enia, zwÅ‚aszcza w przypadku odtwarzania danych.\n\n\n\n\nObie architektury obsÅ‚ugujÄ… analizy w czasie rzeczywistym i historyczne w jednym Å›rodowisku. Jednak istotnÄ… zaletÄ… architektury Kappa w porÃ³wnaniu z architekturÄ… Lambda jest to, Å¼e umoÅ¼liwia ona zbudowanie systemu przesyÅ‚ania strumieniowego i przetwarzania wsadowego na jednej technologii. Oznacza to, Å¼e moÅ¼esz zbudowaÄ‡ aplikacjÄ™ przetwarzajÄ…cÄ… strumienie do obsÅ‚ugi danych w czasie rzeczywistym, a jeÅ›li musisz zmodyfikowaÄ‡ dane wyjÅ›ciowe, zaktualizuj swÃ³j kod, a nastÄ™pnie ponownie uruchom go na danych w mechanizmie przesyÅ‚ania komunikatÃ³w w sposÃ³b wsadowy. Jak sugeruje architektura Lambda, nie ma osobnej technologii do obsÅ‚ugi przetwarzania wsadowego.\nPrzy wystarczajÄ…co szybkim silniku przetwarzania strumieniowego moÅ¼esz nie potrzebowaÄ‡ innej technologii zoptymalizowanej pod kÄ…tem przetwarzania wsadowego. Odczytujesz rÃ³wnolegle przechowywane dane przesyÅ‚ane strumieniowo (zakÅ‚adajÄ…c, Å¼e dane w Kafce sÄ… odpowiednio podzielone na osobne kanaÅ‚y lub â€partycjeâ€) i przeksztaÅ‚casz dane tak, jakby pochodziÅ‚y ze ÅºrÃ³dÅ‚a strumieniowego. W przypadku niektÃ³rych Å›rodowisk moÅ¼liwe do przeanalizowania dane wyjÅ›ciowe moÅ¼na utworzyÄ‡ na Å¼Ä…danie. Gdy nowe zapytanie zostanie przesÅ‚ane przez uÅ¼ytkownika koÅ„cowego, dane mogÄ… zostaÄ‡ przeksztaÅ‚cone ad hoc, aby uzyskaÄ‡ optymalnÄ… odpowiedÅº na to zapytanie. Ponownie wymaga to szybkiego silnika przetwarzania strumieniowego, aby zapewniÄ‡ maÅ‚e opÃ³Åºnienia.\nChociaÅ¼ architektura Lambda nie okreÅ›la technologii, ktÃ³rych naleÅ¼y uÅ¼yÄ‡, komponent przetwarzania wsadowego jest czÄ™sto wykonywany na platformie big data z wykorzystaniem Apache Hadoop. Rozproszony system plikÃ³w Hadoop (HDFS) umoÅ¼liwia ekonomiczne przechowywanie â€surowych danychâ€, ktÃ³re moÅ¼na przeksztaÅ‚ciÄ‡ za pomocÄ… narzÄ™dzi Hadoop w format umoÅ¼liwiajÄ…cy analizÄ™. Podczas gdy Hadoop jest uÅ¼ywany w komponencie systemu do przetwarzania wsadowego, oddzielny silnik przeznaczony do przetwarzania strumieniowego jest uÅ¼ywany w komponencie analitycznym w czasie rzeczywistym. Jednak jednÄ… z zalet architektury Lambda jest to, Å¼e znacznie wiÄ™ksze zestawy danych (w zakresie petabajtÃ³w) moÅ¼na przechowywaÄ‡ i przetwarzaÄ‡ wydajniej w Hadoop w celu analizy historycznej na duÅ¼Ä… skalÄ™."
  },
  {
    "objectID": "old_lectures/wyklad4.html#architektury-strumieniowania-danych",
    "href": "old_lectures/wyklad4.html#architektury-strumieniowania-danych",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "Architektura przesyÅ‚ania strumieniowego to okreÅ›lony zestaw technologii, ktÃ³re wspÃ³Å‚pracujÄ… ze sobÄ… w celu obsÅ‚ugi przetwarzania strumieniowego, co jest praktykÄ… podejmowania dziaÅ‚aÅ„ na serii danych w momencie ich tworzenia. W wielu nowoczesnych wdroÅ¼eniach Apache Kafka dziaÅ‚a jako magazyn danych przesyÅ‚anych strumieniowo, a nastÄ™pnie wiele procesorÃ³w strumieniowych moÅ¼e dziaÅ‚aÄ‡ na danych przechowywanych w Kafce w celu wygenerowania wielu danych wyjÅ›ciowych. NiektÃ³re architektury przesyÅ‚ania strumieniowego obejmujÄ… przepÅ‚ywy pracy zarÃ³wno do przetwarzania strumieniowego, jak i przetwarzania wsadowego, ktÃ³re obejmujÄ… inne technologie do obsÅ‚ugi przetwarzania wsadowego na duÅ¼Ä… skalÄ™ lub wykorzystujÄ… KafkÄ™ jako magazyn centralny, jak okreÅ›lono w architekturze Kappa.\nDoskonaÅ‚a architektura przetwarzania danych w czasie rzeczywistym musi byÄ‡ odporna na bÅ‚Ä™dy i skalowalna; musi obsÅ‚ugiwaÄ‡ aktualizacje wsadowe i przyrostowe oraz byÄ‡ rozszerzalna.\nNa poczÄ…tku badamy dwie podstawowe architektury przetwarzania danych, Lambda i Kappa, ktÃ³re stanowiÄ… podstawÄ™ rÃ³Å¼nych aplikacji korporacyjnych.\n\n\nArchitektura Lambda obejmuje warstwÄ™ wsadowÄ… (batch layer), warstwÄ™ strumieniowa (stream layer) i warstwÄ™ serwowania.\nWarstwa wsadowa dziaÅ‚a na peÅ‚nych danych, dziÄ™ki czemu system moÅ¼e generowaÄ‡ najdokÅ‚adniejsze wyniki. Jednak wyniki sÄ… okupione duÅ¼ymi opÃ³Åºnieniami wynikajÄ…cymi z dÅ‚ugiego czasu obliczeÅ„. Warstwa wsadowa przechowuje surowe dane w miarÄ™ ich nadejÅ›cia i oblicza widoki wsadowe do wykorzystania. Naturalnie procesy wsadowe bÄ™dÄ… wystÄ™powaÄ‡ w pewnych odstÄ™pach czasu i bÄ™dÄ… dÅ‚ugotrwaÅ‚e. Zakres danych wynosi od godzin do kilku lat.\nWarstwa strumieniowa:\n\ngeneruje wyniki z maÅ‚ymi opÃ³Åºnieniami i w czasie zbliÅ¼onym do rzeczywistego.\noblicza widoki w czasie rzeczywistym w celu uzupeÅ‚nienia widokÃ³w wsadowych.\nodbiera napÅ‚ywajÄ…ce dane i aktualizuje wyniki warstwy wsadowej. Koszt obliczeÅ„ jest znacznie obniÅ¼ony dziÄ™ki algorytmom przyrostowym zaimplementowanym w warstwie szybkoÅ›ci.\n\nWidoki wsadowe mogÄ… byÄ‡ przetwarzane przy uÅ¼yciu bardziej zÅ‚oÅ¼onych lub kosztownych reguÅ‚ i mogÄ… mieÄ‡ lepszÄ… jakoÅ›Ä‡ danych i mniej przekrzywieÅ„, podczas gdy widoki w czasie rzeczywistym zapewniajÄ… bieÅ¼Ä…cy dostÄ™p do najnowszych moÅ¼liwych danych.\nWreszcie warstwa serwujÄ…ca umoÅ¼liwia rÃ³Å¼ne zapytania o wyniki przesÅ‚ane z warstw wsadowych i szybkich. Dane wyjÅ›ciowe z warstwy wsadowej w postaci widokÃ³w wsadowych i warstwy szybkoÅ›ci w postaci opinii w czasie zbliÅ¼onym do rzeczywistego sÄ… przekazywane do warstwy obsÅ‚ugujÄ…cej, ktÃ³ra wykorzystuje te dane do obsÅ‚ugi oczekujÄ…cych zapytaÅ„ na zasadzie ad-hoc.\n  Implementacja:  \nDobre bo:\n\nDobra rÃ³wnowaga miÄ™dzy szybkoÅ›ciÄ…, niezawodnoÅ›ciÄ… i skalowalnoÅ›ciÄ….\nDostÄ™p do wynikÃ³w zarÃ³wno w czasie rzeczywistym, jak i offline, bardzo dobrze pokrywa wiele scenariuszy analizy danych.\nDostÄ™p do peÅ‚nego zestawu danych w oknie wsadowym moÅ¼e przynieÅ›Ä‡ okreÅ›lone optymalizacje, ktÃ³re sprawiÄ…, Å¼e Lambda bÄ™dzie wydajniejsza i jeszcze prostsza do wdroÅ¼enia.\n\nKiepskie gdy:\n\nWewnÄ™trzna logika przetwarzania jest taka sama (warstwy wsadowe i warstwy czasu rzeczywistego) - wiele zduplikowanych moduÅ‚Ã³w i kodowania.\nZbiÃ³r danych modelowany za pomocÄ… architektury Lambda jest trudny do migracji i reorganizacji.\n\n\n\n\nArchitektura Kappa to architektura oprogramowania uÅ¼ywana do przetwarzania danych przesyÅ‚anych strumieniowo. GÅ‚Ã³wnym zaÅ‚oÅ¼eniem Architektury Kappa jest moÅ¼liwoÅ›Ä‡ wykonywania przetwarzania w czasie rzeczywistym i przetwarzania wsadowego, zwÅ‚aszcza w celach analitycznych, za pomocÄ… jednego stosu technologicznego. Opiera siÄ™ na architekturze przesyÅ‚ania strumieniowego, w ktÃ³rej przychodzÄ…ce serie danych sÄ… najpierw przechowywane w silniku przesyÅ‚ania wiadomoÅ›ci, takim jak Apache Kafka. StamtÄ…d silnik przetwarzania strumienia odczyta dane, przeksztaÅ‚ci je w format nadajÄ…cy siÄ™ do analizy, a nastÄ™pnie zapisze je w analitycznej bazie danych, aby uÅ¼ytkownicy koÅ„cowi mogli wyszukiwaÄ‡.\nArchitektura Kappa obsÅ‚uguje analizy (prawie) w czasie rzeczywistym, gdy dane sÄ… odczytywane i przeksztaÅ‚cane natychmiast po umieszczeniu ich w silniku przesyÅ‚ania komunikatÃ³w. DziÄ™ki temu najnowsze dane sÄ… szybko dostÄ™pne dla zapytaÅ„ uÅ¼ytkownikÃ³w koÅ„cowych. ObsÅ‚uguje rÃ³wnieÅ¼ analizÄ™ historycznÄ…, odczytujÄ…c zapisane dane przesyÅ‚ane strumieniowo z mechanizmu przesyÅ‚ania wiadomoÅ›ci pÃ³Åºniej w sposÃ³b wsadowy, aby utworzyÄ‡ dodatkowe moÅ¼liwe do analizy dane wyjÅ›ciowe dla wiÄ™kszej liczby typÃ³w analiz.\nArchitektura Kappa jest prostszÄ… alternatywÄ… dla architektury Lambda, poniewaÅ¼ wykorzystuje ten sam stos technologii do obsÅ‚ugi strumienia w czasie rzeczywistym i historycznego przetwarzania wsadowego. Obie architektury obejmujÄ… przechowywanie danych historycznych w celu umoÅ¼liwienia analiz na duÅ¼Ä… skalÄ™. Obie architektury sÄ… rÃ³wnieÅ¼ pomocne w rozwiÄ…zywaniu problemÃ³w zwiÄ…zanych z â€tolerancjÄ… bÅ‚Ä™dÃ³w ludzkichâ€, w ktÃ³rych problemy z kodem przetwarzania (bÅ‚Ä™dy lub znane ograniczenia) moÅ¼na przezwyciÄ™Å¼yÄ‡, aktualizujÄ…c kod i ponownie uruchamiajÄ…c go na danych historycznych. GÅ‚Ã³wna rÃ³Å¼nica w stosunku do architektury Kappa polega na tym, Å¼e wszystkie dane sÄ… traktowane jako strumieÅ„, wiÄ™c silnik przetwarzania strumienia dziaÅ‚a jako jedyny silnik transformacji danych.\n \nImplementation Example:  \n\n\n\n\nAplikacje mogÄ… odczytywaÄ‡ i zapisywaÄ‡ bezpoÅ›rednio do Kafki zgodnie z rozwojem. W przypadku istniejÄ…cych ÅºrÃ³deÅ‚ zdarzeÅ„ detektory sÄ… teraz przyzwyczajone do przesyÅ‚ania strumieniowego raportÃ³w z dziennikÃ³w bazy danych, co eliminuje koniecznoÅ›Ä‡ przetwarzania wsadowego podczas ruchu przychodzÄ…cego, co skutkuje mniejszÄ… liczbÄ… zasobÃ³w.\nZapytania muszÄ… uwzglÄ™dniaÄ‡ tylko jednÄ… lokalizacjÄ™ serwowania, zamiast sprawdzaÄ‡ widoki partii i szybkoÅ›ci.\n\n\n\n\n\nnieÅ‚atwe do wdroÅ¼enia, zwÅ‚aszcza w przypadku odtwarzania danych.\n\n\n\n\nObie architektury obsÅ‚ugujÄ… analizy w czasie rzeczywistym i historyczne w jednym Å›rodowisku. Jednak istotnÄ… zaletÄ… architektury Kappa w porÃ³wnaniu z architekturÄ… Lambda jest to, Å¼e umoÅ¼liwia ona zbudowanie systemu przesyÅ‚ania strumieniowego i przetwarzania wsadowego na jednej technologii. Oznacza to, Å¼e moÅ¼esz zbudowaÄ‡ aplikacjÄ™ przetwarzajÄ…cÄ… strumienie do obsÅ‚ugi danych w czasie rzeczywistym, a jeÅ›li musisz zmodyfikowaÄ‡ dane wyjÅ›ciowe, zaktualizuj swÃ³j kod, a nastÄ™pnie ponownie uruchom go na danych w mechanizmie przesyÅ‚ania komunikatÃ³w w sposÃ³b wsadowy. Jak sugeruje architektura Lambda, nie ma osobnej technologii do obsÅ‚ugi przetwarzania wsadowego.\nPrzy wystarczajÄ…co szybkim silniku przetwarzania strumieniowego moÅ¼esz nie potrzebowaÄ‡ innej technologii zoptymalizowanej pod kÄ…tem przetwarzania wsadowego. Odczytujesz rÃ³wnolegle przechowywane dane przesyÅ‚ane strumieniowo (zakÅ‚adajÄ…c, Å¼e dane w Kafce sÄ… odpowiednio podzielone na osobne kanaÅ‚y lub â€partycjeâ€) i przeksztaÅ‚casz dane tak, jakby pochodziÅ‚y ze ÅºrÃ³dÅ‚a strumieniowego. W przypadku niektÃ³rych Å›rodowisk moÅ¼liwe do przeanalizowania dane wyjÅ›ciowe moÅ¼na utworzyÄ‡ na Å¼Ä…danie. Gdy nowe zapytanie zostanie przesÅ‚ane przez uÅ¼ytkownika koÅ„cowego, dane mogÄ… zostaÄ‡ przeksztaÅ‚cone ad hoc, aby uzyskaÄ‡ optymalnÄ… odpowiedÅº na to zapytanie. Ponownie wymaga to szybkiego silnika przetwarzania strumieniowego, aby zapewniÄ‡ maÅ‚e opÃ³Åºnienia.\nChociaÅ¼ architektura Lambda nie okreÅ›la technologii, ktÃ³rych naleÅ¼y uÅ¼yÄ‡, komponent przetwarzania wsadowego jest czÄ™sto wykonywany na platformie big data z wykorzystaniem Apache Hadoop. Rozproszony system plikÃ³w Hadoop (HDFS) umoÅ¼liwia ekonomiczne przechowywanie â€surowych danychâ€, ktÃ³re moÅ¼na przeksztaÅ‚ciÄ‡ za pomocÄ… narzÄ™dzi Hadoop w format umoÅ¼liwiajÄ…cy analizÄ™. Podczas gdy Hadoop jest uÅ¼ywany w komponencie systemu do przetwarzania wsadowego, oddzielny silnik przeznaczony do przetwarzania strumieniowego jest uÅ¼ywany w komponencie analitycznym w czasie rzeczywistym. Jednak jednÄ… z zalet architektury Lambda jest to, Å¼e znacznie wiÄ™ksze zestawy danych (w zakresie petabajtÃ³w) moÅ¼na przechowywaÄ‡ i przetwarzaÄ‡ wydajniej w Hadoop w celu analizy historycznej na duÅ¼Ä… skalÄ™."
  },
  {
    "objectID": "old_lectures/wyklad4.html#publikujsubskrybuj",
    "href": "old_lectures/wyklad4.html#publikujsubskrybuj",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "Publikuj/Subskrybuj",
    "text": "Publikuj/Subskrybuj\nSystem przesyÅ‚ania wiadomoÅ›ci â€Publikuj/Subskrybujâ€ ma kluczowe znaczenie dla aplikacji opartych na danych. Komunikaty Pub/Sub to wzorzec charakteryzujÄ…cy siÄ™ tym, Å¼e nadawca (publikujÄ…cy) fragmentu danych (wiadomoÅ›ci) nie kieruje go wprost do odbiorcy. pub/sub to systemy, ktÃ³re czÄ™sto posiadajÄ… brokera czyli centralny punkt, w ktÃ³rym znajdujÄ… siÄ™ wiadomoÅ›ci."
  },
  {
    "objectID": "old_lectures/wyklad4.html#apache-kafka",
    "href": "old_lectures/wyklad4.html#apache-kafka",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "Apache Kafka",
    "text": "Apache Kafka\nNa witrynie Kafki znajdziesz definicjÄ™:\n\nRozproszona platforma streamingowa\n\nCo to jest â€platforma rozproszonego przesyÅ‚ania strumieniowegoâ€?\nNajpierw chcÄ™ przypomnieÄ‡, czym jest â€strumieÅ„â€. Strumienie to po prostu nieograniczone dane, dane, ktÃ³re nigdy siÄ™ nie koÅ„czÄ…. CiÄ…gle ich przybywa i moÅ¼esz przetwarzaÄ‡ je w czasie rzeczywistym.\nA â€rozproszoneâ€? Rozproszony oznacza, Å¼e â€‹â€‹Kafka dziaÅ‚a w klastrze, a kaÅ¼dy wÄ™zeÅ‚ w grupie nazywa siÄ™ Brokerem. Ci brokerzy to po prostu serwery wykonujÄ…ce kopiÄ™ Apache Kafka.\nTak wiÄ™c Kafka to zestaw wspÃ³Å‚pracujÄ…cych ze sobÄ… maszyn, aby mÃ³c obsÅ‚ugiwaÄ‡ i przetwarzaÄ‡ nieograniczone dane w czasie rzeczywistym.\nJego rozproszona architektura jest jednym z powodÃ³w, dla ktÃ³rych Kafka staÅ‚ siÄ™ tak sÅ‚awny. Brokerzy sprawiajÄ…, Å¼e jest odporny, niezawodny, skalowalny i odporny na bÅ‚Ä™dy. Ale dlaczego panuje bÅ‚Ä™dne przekonanie, Å¼e Kafka to kolejny â€kolejkowy system przesyÅ‚ania wiadomoÅ›ciâ€?\nAby odpowiedzieÄ‡ na tÄ™ odpowiedÅº, musimy najpierw wyjaÅ›niÄ‡, jak dziaÅ‚a kolejkowe przesyÅ‚anie wiadomoÅ›ci.\n\nKolejkowy system przesyÅ‚ania wiadomoÅ›ci\nPrzesyÅ‚anie wiadomoÅ›ci, to po prostu czynnoÅ›Ä‡ wysyÅ‚ania wiadomoÅ›ci z jednego miejsca do drugiego. Ma trzech gÅ‚Ã³wnych â€œaktorÃ³wâ€:\n\nProducent: KtÃ³ry tworzy i wysyÅ‚a komunikaty do jednej lub wiÄ™cej kolejek;\nKolejka: struktura danych bufora, ktÃ³ra odbiera (od producentÃ³w) i dostarcza komunikaty (do konsumentÃ³w) w sposÃ³b FIFO (First-In-First-Out). Po otrzymaniu powiadomienia jest ono na zawsze usuwane z kolejki; nie ma szans na odzyskanie go;\nKonsument: subskrybuje jednÄ… lub wiÄ™cej kolejek i otrzymuje ich wiadomoÅ›ci po opublikowaniu.\n\nI to jest to; tak dziaÅ‚a przesyÅ‚anie wiadomoÅ›ci. Jak widaÄ‡, nie ma tu nic o strumieniach, czasie rzeczywistym czy klastrach.\n\n\nArchitektura Kafki\nDuÅ¼o informacji znajdziesz pod tym linkiem.\nTeraz, gdy wiemy, jak dziaÅ‚a przesyÅ‚anie wiadomoÅ›ci, zanurzmy siÄ™ w Å›wiat Kafki. W Kafce mamy teÅ¼ â€ProducentÃ³wâ€ i â€KonsumentÃ³wâ€; dziaÅ‚ajÄ… w bardzo podobny sposÃ³b, jak w kolejkowych systemach, produkujÄ…c i konsumujÄ…c komunikaty.\n \nJak widaÄ‡, jest to bardzo podobne do tego, o czym rozmawialiÅ›my o przesyÅ‚aniu wiadomoÅ›ci, ale tutaj nie mamy pojÄ™cia â€kolejkiâ€. Zamiast tego mamy â€Tematyâ€ (Topic).\nâ€Tematâ€ to szczegÃ³lny typ strumienia danych; jest bardzo podobny do kolejki, odbiera i dostarcza wiadomoÅ›ci, ale jest kilka pojÄ™Ä‡, ktÃ³re musimy zrozumieÄ‡ w odniesieniu do tematÃ³w:\n\nTemat jest podzielony na partycje; kaÅ¼dy temat moÅ¼e mieÄ‡ jednÄ… lub wiÄ™cej partycji i musimy okreÅ›liÄ‡ tÄ™ liczbÄ™ podczas tworzenia topicu. MoÅ¼esz sobie wyobraziÄ‡ topic jako folder w systemie operacyjnym, a kaÅ¼dy folder wewnÄ…trz niego jako partycjÄ™.\nKaÅ¼da wiadomoÅ›Ä‡ zostanie zapisana na dysku brokera i otrzyma offset (unikalny identyfikator). Offset jest unikalny na poziomie partycji; kaÅ¼da partycja ma swÃ³j wÅ‚asny zbiÃ³r offsetÃ³w. To jeszcze jeden powÃ³d, ktÃ³ry sprawia, Å¼e â€‹â€‹Kafka jest tak wyjÄ…tkowa, przechowuje wiadomoÅ›ci na dysku (jak baza danych, a w rzeczywistoÅ›ci Kafka teÅ¼ jest bazÄ… danych), aby w razie potrzeby odzyskaÄ‡ je pÃ³Åºniej. W odrÃ³Å¼nieniu od systemu przesyÅ‚ania wiadomoÅ›ci, gdzie wiadomoÅ›Ä‡ jest usuwana po zuÅ¼yciu;\nKosumenci uÅ¼ywajÄ… offsetu do czytania wiadomoÅ›ci, od najstarszej do najnowszej. W przypadku awarii konsumenta zacznie odczytywaÄ‡ koÅ„cowe wartoÅ›ci realizowane po nawiÄ…zaniu poÅ‚Ä…czenia.\n\n \n\n\nBrokerzy\nJak wspomniano wczeÅ›niej, Kafka dziaÅ‚a w sposÃ³b rozproszony. W razie potrzeby klaster Kafka moÅ¼e zawieraÄ‡ wielu brokerÃ³w.\n \nKaÅ¼dy broker w klastrze jest identyfikowany przez identyfikator i zawiera co najmniej jednÄ… partycjÄ™ tematycznÄ…. Aby skonfigurowaÄ‡ liczbÄ™ partycji w kaÅ¼dym brokerze, podczas tworzenia tematu musimy skonfigurowaÄ‡ coÅ›, co nazywa siÄ™ wspÃ³Å‚czynnikiem replikacji. Powiedzmy, Å¼e mamy trzech brokerÃ³w w naszym klastrze, temat z trzema partycjami i wspÃ³Å‚czynnikiem replikacji rÃ³wnym trzy; w takim przypadku kaÅ¼dy broker bÄ™dzie odpowiedzialny za jednÄ… sekcjÄ™ emisji.\nJak widaÄ‡ na powyÅ¼szym obrazku, \\(Topic_1\\) ma trzy partycje; kaÅ¼dy broker jest odpowiedzialny za sekcjÄ™ tematu, wiÄ™c wspÃ³Å‚czynnik replikacji \\(Topic_1\\) wynosi trzy. Liczba partycji musi byÄ‡ zgodna z liczbÄ… brokerÃ³w; w ten sposÃ³b kaÅ¼dy broker bÄ™dzie odpowiedzialny za jednÄ… sekcjÄ™ tematu.\n\n\nProducenci\nPodobnie jak w Å›wiecie kolejkowych systemÃ³w, â€Producenciâ€ w Kafce to ci, ktÃ³rzy tworzÄ… i wysyÅ‚ajÄ… wiadomoÅ›ci do tematÃ³w. Jak wspomniano wczeÅ›niej, wiadomoÅ›ci sÄ… wysyÅ‚ane w sposÃ³b okrÄ™Å¼ny. PrzykÅ‚ad: wiadomoÅ›Ä‡ 01 trafia do partycji 0 tematu 1, a wiadomoÅ›Ä‡ 02 do partycji 1 tego samego tematu. Oznacza to, Å¼e nie moÅ¼emy zagwarantowaÄ‡, Å¼e wiadomoÅ›ci stworzone przez tego samego producenta zawsze bÄ™dÄ… dostarczane w tym samym numerze. Podczas wysyÅ‚ania wiadomoÅ›ci musimy okreÅ›liÄ‡ klucz; Kafka wygeneruje skrÃ³t na podstawie tego klucza i bÄ™dzie wiedziaÅ‚, ktÃ³ra partycja ma dostarczyÄ‡ tÄ™ wiadomoÅ›Ä‡. Ten skrÃ³t uwzglÄ™dnia liczbÄ™ partycji tematu; dlatego tego numeru nie moÅ¼na zmieniÄ‡, gdy temat jest juÅ¼ utworzony.\n\n\nKonsumenci i grupy konsumentÃ³w\nKonsumenci to aplikacje zasubskrybowane do jednego lub wiÄ™cej tematÃ³w, ktÃ³re bÄ™dÄ… odczytywaÄ‡ wiadomoÅ›ci stamtÄ…d. MogÄ… czytaÄ‡ z jednej lub wiÄ™cej partycji. Gdy konsument odczytuje tylko z jednej partycji, moÅ¼emy zapewniÄ‡ kolejnoÅ›Ä‡ odczytu, ale gdy pojedynczy konsument odczytuje z dwÃ³ch lub wiÄ™cej partycji, bÄ™dzie czytaÄ‡ rÃ³wnolegle, wiÄ™c nie ma gwarancji kolejnoÅ›ci odczytu. Na przykÅ‚ad wiadomoÅ›Ä‡, ktÃ³ra przyszÅ‚a pÃ³Åºniej, moÅ¼e zostaÄ‡ odczytana przed innÄ…, ktÃ³ra przyszÅ‚a wczeÅ›niej. Dlatego musimy byÄ‡ ostroÅ¼ni przy wyborze liczby partycji i podczas tworzenia wiadomoÅ›ci.\nInnym waÅ¼nym pojÄ™ciem Kafki sÄ… â€Grupy konsumentÃ³wâ€. Jest to bardzo waÅ¼ne, gdy musimy skalowaÄ‡ odczytywanie wiadomoÅ›ci. Staje siÄ™ to bardzo kosztowne, gdy pojedynczy konsument musi czytaÄ‡ z wielu partycji, wiÄ™c musimy zrÃ³wnowaÅ¼yÄ‡ obciÄ…Å¼enie miÄ™dzy naszymi konsumentami, wtedy wchodzÄ… grupy konsumentÃ³w.\nDane z jednego tematu bÄ™dÄ… rÃ³wnowaÅ¼one obciÄ…Å¼eniem miÄ™dzy konsumentami, dziÄ™ki czemu moÅ¼emy zagwarantowaÄ‡, Å¼e nasi konsumenci bÄ™dÄ… w stanie obsÅ‚ugiwaÄ‡ i przetwarzaÄ‡ dane. IdeaÅ‚em jest posiadanie takiej samej liczby konsumentÃ³w w grupie, jakÄ… mamy jako partycje w temacie, w ten sposÃ³b kaÅ¼dy konsument czyta tylko z jednego. Podczas dodawania konsumentÃ³w do grupy naleÅ¼y uwaÅ¼aÄ‡, jeÅ›li liczba konsumentÃ³w jest wiÄ™ksza niÅ¼ liczba partycji, niektÃ³rzy konsumenci nie bÄ™dÄ… czytaÄ‡ z Å¼adnego tematu i pozostanÄ… bezczynni."
  },
  {
    "objectID": "old_lectures/wyklad2S.html",
    "href": "old_lectures/wyklad2S.html",
    "title": "WykÅ‚ad 2",
    "section": "",
    "text": "Oczekiwania vs RzeczywistoÅ›Ä‡\n\nKiedy podjÄ…Ä‡ decyzjÄ™ biznesowÄ… ?\n\n\n\n\nBatch = DuÅ¼e, historyczne zbiory\nStream = StrumieÅ„ danych, on line, przesyÅ‚ane w trybie ciÄ…gÅ‚ym\n\n\n\n\n\nBatch = minuty, godziny, dni (patrz Hurtownie danych)\nStream = Real-time/near-real-time\n\n\n\n\n\nBatch = moÅ¼liwe i stosowane bardzo czesto\nStream = ,,niemoÅ¼liweâ€™â€™\n\n\n\n\n\nExtract, Transform, Load is a basic pattern for data processing, commonly known in data warehousing. Itâ€™s all about extracting data from a source, transforming the data (business rules) and at the end writing/loading everything to a target (Hadoop, Relational Database, Data Warehouse etc.)\n\n\n\nGdy mÃ³wimy o skali (nie o jÄ™zyku Scala), najczÄ™Å›ciej przychodzi nam na myÅ›l przeglÄ…darka Google. Przeszukuje ona ogromne zbiory danychz duÅ¼Ä… prÄ™dkoÅ›ciÄ…. Sama nazwa Goolge wskasuje na skalÄ™ (colowo przyjÄ™to bÅ‚Ä™dnÄ… nazwÄ™ w zapisie googol co oznacza 1 i 100 zer).\n\nSprawdÅº czy do koÅ„ca zajÄ™Ä‡ uda Ci siÄ™ zapisaÄ‡ liczbÄ™ googol na kartce.\n\nPowinno byÄ‡ dla Ciebie jasne, Å¼e Å¼adne tradycyjne systemy, np relacyjne systemy baz danych, ani programowanie imperatywne nie sÄ… w stanie obÅ‚uÅ¼yÄ‡ przeszukiwania takiej iloÅ›ci danych. Problemy te doprowadziÅ‚y do budowy rozproszonych systemÃ³w plikÃ³w Google File System, MapReduce (paradygmat programowania rÃ³wnolegÅ‚ego), czy Bigtable (skalowalna pamiÄ™Ä‡ masowa ustrukturyzowanych danych znajdujÄ…cych siÄ™ na GFS).\n\n\nZnajdÅº prosty algorytm map reduce w dowolnym jÄ™zyku programowania i uruchom go.\n\n\nJak poprawiÄ‡ ?"
  },
  {
    "objectID": "old_lectures/wyklad2S.html#batch-vs-stream-processing",
    "href": "old_lectures/wyklad2S.html#batch-vs-stream-processing",
    "title": "WykÅ‚ad 2",
    "section": "",
    "text": "Oczekiwania vs RzeczywistoÅ›Ä‡\n\nKiedy podjÄ…Ä‡ decyzjÄ™ biznesowÄ… ?\n\n\n\n\nBatch = DuÅ¼e, historyczne zbiory\nStream = StrumieÅ„ danych, on line, przesyÅ‚ane w trybie ciÄ…gÅ‚ym\n\n\n\n\n\nBatch = minuty, godziny, dni (patrz Hurtownie danych)\nStream = Real-time/near-real-time\n\n\n\n\n\nBatch = moÅ¼liwe i stosowane bardzo czesto\nStream = ,,niemoÅ¼liweâ€™â€™\n\n\n\n\n\nExtract, Transform, Load is a basic pattern for data processing, commonly known in data warehousing. Itâ€™s all about extracting data from a source, transforming the data (business rules) and at the end writing/loading everything to a target (Hadoop, Relational Database, Data Warehouse etc.)\n\n\n\nGdy mÃ³wimy o skali (nie o jÄ™zyku Scala), najczÄ™Å›ciej przychodzi nam na myÅ›l przeglÄ…darka Google. Przeszukuje ona ogromne zbiory danychz duÅ¼Ä… prÄ™dkoÅ›ciÄ…. Sama nazwa Goolge wskasuje na skalÄ™ (colowo przyjÄ™to bÅ‚Ä™dnÄ… nazwÄ™ w zapisie googol co oznacza 1 i 100 zer).\n\nSprawdÅº czy do koÅ„ca zajÄ™Ä‡ uda Ci siÄ™ zapisaÄ‡ liczbÄ™ googol na kartce.\n\nPowinno byÄ‡ dla Ciebie jasne, Å¼e Å¼adne tradycyjne systemy, np relacyjne systemy baz danych, ani programowanie imperatywne nie sÄ… w stanie obÅ‚uÅ¼yÄ‡ przeszukiwania takiej iloÅ›ci danych. Problemy te doprowadziÅ‚y do budowy rozproszonych systemÃ³w plikÃ³w Google File System, MapReduce (paradygmat programowania rÃ³wnolegÅ‚ego), czy Bigtable (skalowalna pamiÄ™Ä‡ masowa ustrukturyzowanych danych znajdujÄ…cych siÄ™ na GFS).\n\n\nZnajdÅº prosty algorytm map reduce w dowolnym jÄ™zyku programowania i uruchom go.\n\n\nJak poprawiÄ‡ ?"
  },
  {
    "objectID": "old_lectures/wyklad2S.html#strumienie-danych",
    "href": "old_lectures/wyklad2S.html#strumienie-danych",
    "title": "WykÅ‚ad 2",
    "section": "Strumienie danych",
    "text": "Strumienie danych\nStrumieniowanie moÅ¼esz kojarzyÄ‡ z serwisÃ³w przesyÅ‚ajÄ…cych video w trybie online. Gdy oglÄ…dasz swÃ³j ulubiony serial (tak jak teraz na zajÄ™ciach) serwis odpowiadajÄ…cy za strumieniowanie w nieprzerwany sposÃ³b przesyÅ‚a do ciebie kolejne â€œporcjeâ€ video. Identycznie koncepcja ta realizowana jest w przypadku danych strumieniowych. Format przesyÅ‚anych porcji nie musi byÄ‡ plikiem video, wszystko zaleÅ¼y od celu realizowanego biznesowo. Np. ciÄ…gÅ‚y pomiar z rÃ³Å¼nego rodzaju czujnikÃ³w w farbykach, elektrowniach itp. Warto odnotowaÄ‡, Å¼e masz do czynienia z ciÄ…gÅ‚ym strumieniem danych, ktÃ³re przetwarzaÄ‡ musisz w czasie rzeczywistym. Nie moÅ¼esz czekaÄ‡ do zatrzymania linii produkcyjnych w celu wykonania analizy, wszystkie pojawiajÄ…ce siÄ™ problemy chcesz rejestrowaÄ‡ natychmiast i jak najszybciej na nie reagowaÄ‡.\n\nAnaliza strumieni danych to ciÄ…gÅ‚e przetwarzanie i analiza duÅ¼ych zbiorÃ³w danych w ruchu.\n\nPorÃ³wnuj to do wsakazanych powyÅ¼ej elementÃ³w Big Data. Przetwarzanie Batchowe jest przeciwieÅ„stwem do przetwarzania strumieniowego. Najpierw zbierasz duÅ¼e iloÅ›ci danych a potem realizujesz analizy. MoÅ¼esz oczywiÅ›cie zawsze pobraÄ‡ video w caÅ‚oÅ›ci zanim je obejrzysz, ale czy miaÅ‚oby to sens? IstniejÄ… przypadki gdy takie podejÅ›cie nie stanowi problemu, ale juÅ¼ tu widzisz, Å¼e przetwarzanie strumieniowe moÅ¼e przynieÅ›Ä‡ dla biznesu dodatkowe wartoÅ›ci dodane, ktÃ³rych trudno oczekiwaÄ‡ przy wsadowym przetwarzaniu.\nciekawe informacje\n\nÅ¹rÃ³dÅ‚a danych przesyÅ‚anych strumieniowo obejmujÄ…:\n\nczujniki sprzÄ™tu,\nstrumienie klikniÄ™Ä‡,\nÅ›ledzenie lokalizacji\ninterackcja z uÅ¼ytkownikiem: co robiÄ… uÅ¼ytkownicy Twojej witryny?\nkanaÅ‚y mediÃ³w spoÅ‚ecznoÅ›ciowych,\nnotowania gieÅ‚dowe,\naktywnoÅ›Ä‡ w aplikacjach\ninne.\n\nFirmy wykorzystujÄ… analitykÄ™ strumieniowÄ… do odkrywania i interpretowania wzorcÃ³w, tworzenia wizualizacji, przekazywania spostrzeÅ¼eÅ„ i alertÃ³w oraz uruchamiania procesÃ³w w czasie rzeczywistym lub zbliÅ¼onym do rzeczywistego.\n\n\nPrzykÅ‚adowe biznesowe zastosowania\n\nDane z sensorÃ³w IoT i detekcja anomalii\nStock Trading (problemy regresyjne) - czas reagowania na zmiany i czas zakupy i sprzedaÅ¼y akcji.\nClickstream for websites (problem klasyfikacji) - Å›ledzenie i analiza goÅ›ci na stronie serwisu internetowego - personalizacja strony i treÅ›ci.\n\n8 najlepszych przykÅ‚adÃ³w analizy w czasie rzeczywistym\nBiznesowe zastosowania\n\nPrzedsiÄ™biorstwo to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„.\n\nAnalityka strumieniowa (ang. stream analytics) nazywana jest rÃ³wnieÅ¼ przetwarzaniem strumieniowym zdarzeÅ„ (ang. event stream processing) - przetwarzanie duÅ¼ej iloÅ›ci danych juÅ¼ na etapie ich generowania.\nNiezaleÅ¼nie od zastosowanej technologi wszystkie dane powstajÄ… jako ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„ (dziaÅ‚ania uÅ¼ytkownikÃ³w na stronie www, logi systemowe, pomiary z sensorÃ³w)."
  },
  {
    "objectID": "old_lectures/wyklad2S.html#czas-w-analizie-danych-w-czasie-rzeczywistym",
    "href": "old_lectures/wyklad2S.html#czas-w-analizie-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 2",
    "section": "Czas w analizie danych w czasie rzeczywistym",
    "text": "Czas w analizie danych w czasie rzeczywistym\nW przypadku przetwarzania wsadowego przetwarzamy dane historyczne i czas uruchomienia procesu przetwarzania nie ma nic wspÃ³lnego z czasem wystÄ™powania analizowanych zdarzeÅ„.\nDla danych strumieniowych mamy dwie koncepcje czasu:\n\nczas zdarzenia (event time) - czas w ktÃ³rym zdarzenie siÄ™ wydarzyÅ‚o.\nczas przetwarzania (processing time) - czas w ktÃ³rym system przetwarza zdarzenie.\n\nW przypadku idealnej sytuacji:\n\nW rzeczywistoÅ›ci przetwarzanie danych zawsze odbywa siÄ™ z pewnym opÃ³Åºnieniem, co reprezentowane jest przez punkty pojawiajÄ…ce siÄ™ poniÅ¼ej funkcji dla sytuacji idealnej (poniÅ¼ej diagonalnej).\n\nW aplikacjach przetwarzania strumieniowego istotne okazujÄ… siÄ™ rÃ³Å¼nice miedzy czasem powstania zdarzenia i jego procesowania. Do najczÄ™stszych przyczyn opÃ³Åºnienia wyszczegÃ³lnia siÄ™ przesyÅ‚anie danych przez sieÄ‡ czy brak komunikacji miÄ™dzy urzÄ…dzeniem a sieciÄ…. Prostym przykÅ‚adem jest tu przejazd samochodem przez tunel i Å›ledzenie poÅ‚oÅ¼enia przez aplikacjÄ™ GPS.\nMoÅ¼esz oczywiÅ›cie zliczaÄ‡ iloÅ›Ä‡ takich pominiÄ™tych zdarzeÅ„ i uruchomiÄ‡ alarm w sytuacji gdy takich odrzutÃ³w bÄ™dzie za duÅ¼o. Drugim (chyba czÄ™Å›ciej) wykorzystywanym sposobem jest zastosowanie korekty z wykorzystaniem tzw. watermarkingu.\nProces przetwarzania zdarzeÅ„ w czasie rzeczywistym moÅ¼na przedstawiÄ‡ w postaci funkcji schodkowej, reprezentowanej na rysunku: \nJak moÅ¼na zauwaÅ¼yÄ‡ nie wszystkie zdarzenia wnoszÄ… wkÅ‚ad do analizy i przetwarzania. RealizacjÄ™ procesu przetwarzania wraz z uwzglÄ™dnieniem dodatkowego czasu na pojawienie siÄ™ zdarzeÅ„ (watermark) moÅ¼na przedstawiÄ‡ jako proces obejmujÄ…cy wszystkie zdarzenia powyÅ¼ej przerywanej linii. Dodatkowy czas pozwoliÅ‚ na przetworzenie dodatkowych zdarzeÅ„, natomiast nadal mogÄ… zdarzyÄ‡ siÄ™ punkty, ktÃ³re nie bÄ™dÄ… brane pod uwagÄ™.  \nPrzedstawione na wykresach sytuacje jawnie wskazujÄ… dlaczego pojÄ™cie czasu jest istotnym czynnikiem i wymaga Å›cisÅ‚ego okreÅ›lenia juÅ¼ na poziomie definiowania potrzeb biznesowych. Przypisywanie znacznikÃ³w czasu do danych (zdarzeÅ„) to trudne zadanie."
  },
  {
    "objectID": "old_lectures/wyklad2S.html#okna-czasowe",
    "href": "old_lectures/wyklad2S.html#okna-czasowe",
    "title": "WykÅ‚ad 2",
    "section": "okna czasowe",
    "text": "okna czasowe\nOkno rozÅ‚Ä…czne (ang. tumbling window) czyli okno o staÅ‚ej dÅ‚ugoÅ›ci. Jego cechÄ… charakterystycznÄ… jest to, iÅ¼ kaÅ¼de zdarzenie naleÅ¼y tylko do jednego okna.  \nOkno przesuwne (ang. sliding window) obejmuje wszystkie zdarzenia nastÄ™pujÄ…ce w okreÅ›lonej dÅ‚ugoÅ›ci miÄ™dzy sobÄ….  \nOkno skokowe (ang. hopping window) tak jak okno rozÅ‚Ä…czne ma staÅ‚Ä… dÅ‚ugoÅ›Ä‡, ale pozwala siÄ™ w nim na zachodzenie jednych okien na inne. Stosowane zazwyczaj do wygÅ‚adzenia danych.  \nKomunikacja sieciowa, relacyjne bazy danych, rozwiÄ…zania chmurowe i big data znaczÄ…co zmieniÅ‚y sposÃ³b budowania systemÃ³w informatycznych i wykonywnia na niach pracy.\nPorÃ³wnaj to jak â€œnarzÄ™dziaâ€ do realizacji przekazu (gazeta, radio, telewizja, internet, komunikatory, media spoÅ‚ecznoÅ›ciowe) zmieniÅ‚y interakcje miÄ™dzyludzkie i struktury spoÅ‚eczne.\n\nKaÅ¼de nowe informatyczne medium zmieniÅ‚o stosunek ludzi do informatyki.\n\nKoncepcja mikrousÅ‚ugi (mikroserwisu) jest bardzo popularnym sposobem budowania systemÃ³w informatycznych jak i koncepcjÄ… przy tworzeniu oprogramowania czy realizacji firmy w duchu Data-Driven. Koncepcja ta pozwala zachowaÄ‡ wydajnoÅ›Ä‡ (rÃ³b jednÄ… rzecz ale dobrze), elastycznoÅ›Ä‡ i jasnÄ… postaÄ‡ caÅ‚ej struktury.\nChociaÅ¼ istniejÄ… inne sposoby architektury projektÃ³w oprogramowania, â€mikroserwisyâ€ sÄ… czÄ™sto uÅ¼ywane nie bez powodu. Idea mikroserwisÃ³w tkwi w nazwie: oprogramowanie jest reprezentowane jako wiele maÅ‚ych usÅ‚ug, ktÃ³re dziaÅ‚ajÄ… indywidualnie. PatrzÄ…c na ogÃ³lnÄ… architekturÄ™, kaÅ¼da mikrousÅ‚uga znajduje siÄ™ w maÅ‚ej czarnej skrzynce z jasno zdefiniowanymi wejÅ›ciami i wyjÅ›ciami. MoÅ¼esz porÃ³wnaÄ‡ tego typu zachowanie do â€œczystej funkcjiâ€ w programowaniu funkcyjnym.\nW celu umoÅ¼liwienia komunikacji rÃ³Å¼nych mikroserwisÃ³w czÄ™sto wybieranym rozwiÄ…zaniem jest wykorzystanie Application Programming Interfaces API .\n\nKomunikacja przez API\nCentralnym elementem architektury mikrousÅ‚ug jest wykorzystanie interfejsÃ³w API. API to czÄ™Å›Ä‡, ktÃ³ra pozwala na poÅ‚Ä…czenie dwÃ³ch mikroserwisÃ³w. Interfejsy API sÄ… bardzo podobne do stron internetowych. Podobnie jak strona internetowa, serwer wysyÅ‚a do Ciebie kod reprezentujÄ…cy stronÄ™ internetowÄ…. Twoja przeglÄ…darka internetowa interpretuje ten kod i wyÅ›wietla stronÄ™ internetowÄ….\nWeÅºmy przypadek biznesowy z modelem ML jako usÅ‚ugÄ…. ZaÅ‚Ã³Å¼my, Å¼e pracujesz dla firmy sprzedajÄ…cej mieszkania w Bostonie. Chcesz zwiÄ™kszaÄ‡ sprzedaÅ¼ i oferowaÄ‡ naszym klientom lepszÄ… jakoÅ›Ä‡ usÅ‚ug dziÄ™ki nowej aplikacji mobilnej, z ktÃ³rej moÅ¼e korzystaÄ‡ nawet 1 000 000 osÃ³b jednoczeÅ›nie. MoÅ¼emy to osiÄ…gnÄ…Ä‡, udostÄ™pniajÄ…c prognozÄ™ wartoÅ›ci domu, gdy uÅ¼ytkownik prosi o wycenÄ™ przez Internet.\n\nCzym jest serwowanie modelu ML\n\nSzkolenie dobrego modelu ML to TYLKO pierwsza czÄ™Å›Ä‡ caÅ‚ego procesu: Musisz udostÄ™pniÄ‡ swÃ³j model uÅ¼ytkownikom koÅ„cowym. Robisz to, zapewniajÄ…c dostÄ™p do modelu na swoim serwerze.\nAby udostÄ™pniÄ‡ model potrzebujesz: modelu, interpretera, danych wsadowych.\nWaÅ¼ne metryki\n\n\nczas oczekiwania,\nkoszty,\nliczba zapytaÄ‡ w jednostce czasu\n\n\nUdostÄ™pnianie danych miÄ™dzy dwoma lub wiÄ™cej systemami zawsze byÅ‚o podstawowym wymogiem tworzenia oprogramowania â€“ DevOps vs.Â MLOps.\n\nGdy wywoÅ‚asz interfejs API, otrzyma on Twoje Å¼Ä…danie. Å»Ä…danie wyzwala kod do uruchomienia na serwerze i generuje odpowiedÅº odesÅ‚anÄ… do Ciebie. JeÅ›li coÅ› pÃ³jdzie nie tak, moÅ¼esz nie otrzymaÄ‡ Å¼adnej odpowiedzi lub otrzymaÄ‡ kod bÅ‚Ä™du jako kod stanu HTTP.\n\nKlient-Serwer: Klient (system A) przesyÅ‚a Å¼Ä…danie przez HTTP do adresu URL hostowanego przez system B, ktÃ³ry zwraca odpowiedÅº. Identycznie dziaÅ‚a np przeglÄ…darka internetowa. Å»Ä…danie jest kierowane do serwera WWW, ktÃ³ry zwraca tekstowÄ… stronÄ™ HTML.\n\n\nBezstanowe: Å»Ä…danie klienta powinno zawieraÄ‡ wszystkie informacje niezbÄ™dne do udzielenia peÅ‚nej odpowiedzi.\n\nInterfejsy API moÅ¼na wywoÅ‚ywaÄ‡ za pomocÄ… wielu rÃ³Å¼nych narzÄ™dzi. Czasami moÅ¼esz nawet uÅ¼yÄ‡ przeglÄ…darki internetowej. NarzÄ™dzia takie jak CURL wykonujÄ… zadanie w wierszu poleceÅ„. MoÅ¼esz uÅ¼ywaÄ‡ narzÄ™dzi, takich jak Postman, do wywoÅ‚ywania interfejsÃ³w API za pomocÄ… interfejsu uÅ¼ytkownika.\n\nCaÅ‚a komunikacja jest objÄ™ta ustalonymi zasadami i praktykami, ktÃ³re sÄ… nazywane protokoÅ‚em HTTP.\n\n\n\nZapytanie - Request\n\nAdres URL (np. http://mydomain:8000/getapi?&val1=43&val2=3) zawiera: - domenÄ™, - port, - dodatkowe Å›cieÅ¼ki, - zapytanie\nMetody HTTP: - GET, - POST\nNagÅ‚Ã³wki HTTP zawierajÄ…: - informacje o autoryzacji, - cookies metadata CaÅ‚a informacja zawarta jest w Content-Type: application/json, text â€¦ Accept: application/json, Authorization: Basic abase64string, Tokens\nCiaÅ‚o zapytania\n\nNajczÄ™Å›ciej wybieranym formatem dla wymiany informacji miÄ™dzy serwisami jest format JavaScript Object Notation (JSON). Przypomina on pythonowy obiekt sÅ‚ownika - â€œkluczâ€: â€œwartoÅ›Ä‡â€.\n{\n\"RAD\": 1,\n\"PTRATIO\": 15.3, \"INDUS\": 2.31, \"B\": 396.9,\n\"ZN\": 18,\n\"DIS\": 4.09, \"CRIM\": 0.00632, \"RM\": 6.575, \"AGE\": 65.2, \"CHAS\": 0, \"NOX\": 0.538, \"TAX\": 296, \"LSTAT\": 4.98\n}\n\n\nOdpowiedÅº - Response\n\nTreÅ›Ä‡ odpowiedzi przekazywana jest razem z nagÅ‚Ã³wkiem oraz statusem:\n\n200 OK\nContent-Encoding: gzip\nContent-Type: text/html; charset=utf-8\nDate: Mon, 18 Jul 2016 16:06:00 GMT Server: Apache\nPath=/;\n\nnp.: â€œContent-Typeâ€ =&gt; â€application/json; charset=utf-8â€, â€Serverâ€ =&gt; â€Genie/Julia/1.8.5â€\nTreÅ›Ä‡ (ciaÅ‚o) odpowiedzi:\n\n{\":input\":{\"RAD\":1,\"PTRATIO\":15.3,\"INDUS\":2.31,.....}}, {\":prediction\":[29.919737211857683]}\n\nHTTP status code: â€¢ 200 OK - prawidÅ‚owe wykonanie zapytania, â€¢ 40X Access Denied â€¢ 50X Internal server error\n\n\nWyszukaj informacje czym jest REST API.\n\n\nWiedza:\n\nZna mozÌ‡liwosÌci i obszary zastosowania procesowania danych w czasie rzeczywistym\nRozumie potrzeby biznesowe podejmowania decyzji w bardzo kroÌtkim czasie\n\n\n\nUmiejÄ™tnoÅ›ci:\n\nRozumie ograniczenia wynikajaÌ¨ce z czasu przetwarzania przez urzaÌ¨dzenia oraz systemy informatyczne\n\n\n\nKompetencje:\n\nUtrwala umiejeÌ¨tnosÌcÌ samodzielnego uzupeÅ‚niania wiedzy teoretycznej jak i praktycznej w zakresie programowania, modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym.\nFormuÅ‚uje problem analityczny wraz z jego informatycznym rozwiaÌ¨zaniem"
  },
  {
    "objectID": "plan_wyklady.html",
    "href": "plan_wyklady.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "ğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej? 2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce. 3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym. 4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w. 5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych. ğŸ›  Laboratoria (praktyka + implementacja w Pythonie)\nğŸ”¹ Lab 1: Struktury danych w Pythonie â€“ Pandas, SQL (PostgreSQL, SQLite). ğŸ”¹ Lab 2: Dane grafowe w analizie relacji â€“ NetworkX i algorytmy grafowe. ğŸ”¹ Lab 3: Analiza tekstÃ³w i NLP â€“ przetwarzanie danych tekstowych (spaCy, TF-IDF). ğŸ”¹ Lab 4: Strumieniowanie danych w Apache Kafka â€“ pierwsza aplikacja Python + Kafka. ğŸ”¹ Lab 5: Uczenie maszynowe na strumieniu â€“ klasyfikacja w czasie rzeczywistym (SGDClassifier). ğŸ”¹ Lab 6: Przygotowanie API w FastAPI â€“ serwowanie modelu ML. ğŸ”¹ Lab 7: Zastosowanie modelu ML w reguÅ‚ach decyzyjnych â€“ integracja API z logikÄ… biznesowÄ…. ğŸ”¹ Lab 8: Przetwarzanie obrazÃ³w w czasie rzeczywistym â€“ OpenCV + klasyfikacja wideo. ğŸ”¹ Lab 9: Wykrywanie oszustw w transakcjach finansowych â€“ online learning na Kafka. ğŸ”¹ Lab 10: Projekt koÅ„cowy â€“ budowa mikroserwisu do analizy danych w czasie rzeczywistym."
  },
  {
    "objectID": "plan_wyklady.html#plan-wykÅ‚adu",
    "href": "plan_wyklady.html#plan-wykÅ‚adu",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "ğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej? 2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce. 3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym. 4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w. 5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych. ğŸ›  Laboratoria (praktyka + implementacja w Pythonie)\nğŸ”¹ Lab 1: Struktury danych w Pythonie â€“ Pandas, SQL (PostgreSQL, SQLite). ğŸ”¹ Lab 2: Dane grafowe w analizie relacji â€“ NetworkX i algorytmy grafowe. ğŸ”¹ Lab 3: Analiza tekstÃ³w i NLP â€“ przetwarzanie danych tekstowych (spaCy, TF-IDF). ğŸ”¹ Lab 4: Strumieniowanie danych w Apache Kafka â€“ pierwsza aplikacja Python + Kafka. ğŸ”¹ Lab 5: Uczenie maszynowe na strumieniu â€“ klasyfikacja w czasie rzeczywistym (SGDClassifier). ğŸ”¹ Lab 6: Przygotowanie API w FastAPI â€“ serwowanie modelu ML. ğŸ”¹ Lab 7: Zastosowanie modelu ML w reguÅ‚ach decyzyjnych â€“ integracja API z logikÄ… biznesowÄ…. ğŸ”¹ Lab 8: Przetwarzanie obrazÃ³w w czasie rzeczywistym â€“ OpenCV + klasyfikacja wideo. ğŸ”¹ Lab 9: Wykrywanie oszustw w transakcjach finansowych â€“ online learning na Kafka. ğŸ”¹ Lab 10: Projekt koÅ„cowy â€“ budowa mikroserwisu do analizy danych w czasie rzeczywistym."
  }
]