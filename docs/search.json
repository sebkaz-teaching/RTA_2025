[
  {
    "objectID": "plan.html",
    "href": "plan.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "Lecture 1: Introduction to Real-Time Data Analysis\nLecture 2: Data Ingestion and Processing for Real-Time Analysis\nLecture 3: Real-Time Data Analysis Techniques\nLecture 4: Real-Time Data Visualization and Communication\nLecture 5: Case Studies and Implementation\nThroughout the lectures, Iâ€™ll incorporate interactive elements, such as:\nThis comprehensive lecture plan will provide students with a solid foundation in real-time data analysis, covering the technical aspects of data ingestion, processing, and visualization, as well as practical applications and best practices."
  },
  {
    "objectID": "plan.html#nowy-program-przedmiotu",
    "href": "plan.html#nowy-program-przedmiotu",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "Nowy program przedmiotu",
    "text": "Nowy program przedmiotu\n\nBatch vs.Â Real-Time vs.Â Streaming Analytics â€“ RÃ³Å¼nice miÄ™dzy trybami przetwarzania danych, kluczowe koncepcje i zastosowania.\nModele przetwarzania danych w Big Data â€“ Od plikÃ³w pÅ‚askich do Data Lake, wady i zalety podejÅ›cia real-time. Mity i fakty o przetwarzaniu w czasie rzeczywistym.\nArchitektura IT dla przetwarzania w czasie rzeczywistym â€“ OmÃ³wienie architektur Lambda i Kappa w kontekÅ›cie strumieniowego przetwarzania danych.\nSystemy przetwarzania danych w czasie rzeczywistym â€“ PrzeglÄ…d technologii: Apache Kafka, Apache Spark Streaming, Apache Flink i ich zastosowania w Pythonie.\nPodstawy uczenia maszynowego w czasie rzeczywistym â€“ PorÃ³wnanie offline learning vs.Â online learning, problemy zwiÄ…zane z przyrostowym uczeniem maszynowym.\n\nğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej?\n2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce.\n3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym.\n4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w.\n5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych."
  },
  {
    "objectID": "indexS.html",
    "href": "indexS.html",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-S\nSemestr zimowy 2024/2025, SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nSzczegÃ³Å‚owy opis znajdziesz w sylabusie. Znajdziesz w nim opis wszystkich wykÅ‚adÃ³w i Ä‡wiczeÅ„ oraz proponowanÄ… literaturÄ™.\nInne ksiÄ…Å¼ki zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki"
  },
  {
    "objectID": "indexS.html#analiza-danych-w-czasie-rzeczywistym",
    "href": "indexS.html#analiza-danych-w-czasie-rzeczywistym",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-S\nSemestr zimowy 2024/2025, SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nSzczegÃ³Å‚owy opis znajdziesz w sylabusie. Znajdziesz w nim opis wszystkich wykÅ‚adÃ³w i Ä‡wiczeÅ„ oraz proponowanÄ… literaturÄ™.\nInne ksiÄ…Å¼ki zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki"
  },
  {
    "objectID": "indexS.html#kalendarz",
    "href": "indexS.html#kalendarz",
    "title": "Informacje ogÃ³lne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykÅ‚ad\nWykÅ‚ad jest realizowany w trybie stacjonarnym. Jest on NIEOBOWIÄ„ZKOWY i odbywa siÄ™ w Auli III bud G\n\n22-02-2025 (sobota) 08:00-09:30 - WykÅ‚ad 1\n08-03-2025 (sobota) 08:00-09:30 - WykÅ‚ad 2\n\n\n\nLaboratoria\n\nLab1\n22-03-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n23-03-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab2\n05-04-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n06-04-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab3\n26-04-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n27-04-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab4\n17-05-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n18-05-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab5\n31-05-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n01-06-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\n\nZaliczenie i Egzamin\nWykÅ‚ady zakoÅ„czÄ… siÄ™ testem (podczas ostatnich zajÄ™Ä‡) 20 pytaÅ„.\nAby zaliczyÄ‡ test, naleÅ¼y zdobyÄ‡ wiÄ™cej niÅ¼ 13 punktÃ³w â€“ jest to warunek konieczny do uczestnictwa w Ä‡wiczeniach.\nLaboratoria\nPodczas laboratoriÃ³w bÄ™dÄ… zadawane prace domowe, ktÃ³re naleÅ¼y przesyÅ‚aÄ‡ za poÅ›rednictwem MS Teams. KaÅ¼dy brak pracy domowej obniÅ¼a koÅ„cowÄ… ocenÄ™ o 0,5 stopnia.\n\nProjekt\nProjekty naleÅ¼y realizowaÄ‡ w grupach maksymalnie 5-osobowych.\nWymagania projektu\n\nProjekt powinien rozwiÄ…zywaÄ‡ realny problem biznesowy, ktÃ³ry moÅ¼na opracowaÄ‡ przy uÅ¼yciu danych przetwarzanych w trybie online. (Nie wyklucza to uÅ¼ycia przetwarzania wsadowego, np. do generowania modelu).\nDane powinny byÄ‡ przesyÅ‚ane do Apache Kafka, skÄ…d bÄ™dÄ… poddawane dalszemu przetwarzaniu i analizie.\nMoÅ¼na uÅ¼ywaÄ‡ dowolnego jÄ™zyka programowania w kaÅ¼dym komponencie projektu.\nMoÅ¼na wykorzystaÄ‡ narzÄ™dzia BI.\nÅ¹rÃ³dÅ‚em danych moÅ¼e byÄ‡ dowolne API, sztucznie generowane dane, IoT itp."
  },
  {
    "objectID": "indexS.html#technologie",
    "href": "indexS.html#technologie",
    "title": "Informacje ogÃ³lne",
    "section": "Technologie",
    "text": "Technologie\nUczestniczÄ…c w zajÄ™ciach musisz opanowaÄ‡ i przynajmniej w podstawowym zakresie posÅ‚ugiwaÄ‡ siÄ™ nastÄ™pujÄ…cymi technologiami informatycznymi:\n\nGIT\nPython, Jupyter notebook, Jupyter lab, Colab\nDocker\nApache Spark, Apache Kafka\nDatabricks Community edition Web page."
  },
  {
    "objectID": "info.html",
    "href": "info.html",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3.11 -m venv &lt;name of env&gt;\n# dla linux i mac os\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n# dla windows \n# &lt;name of env&gt;\\Scripts\\activate\n(venv)$ \nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#python",
    "href": "info.html#python",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3.11 -m venv &lt;name of env&gt;\n# dla linux i mac os\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n# dla windows \n# &lt;name of env&gt;\\Scripts\\activate\n(venv)$ \nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "href": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z serwisu GitHub",
    "text": "Zacznij korzystaÄ‡ z serwisu GitHub\n\n\n\nTekst na podstawie strony jak korzystaÄ‡ z serwisu github\nPracujÄ…c nad projektem np. praca magisterska, (samodzielnie lub w zespole) czÄ™sto potrzebujesz sprawdziÄ‡ jakie zmiany, kiedy i przez kogo zostaÅ‚y wprowadzone do projektu. W zadaniu tym Å›wietnie sprawdza siÄ™ system kontroli wersji czyli GIT.\nGit moÅ¼esz pobraÄ‡ i zainstalowaÄ‡ jak zwykÅ‚y program na dowolnym komputerze. Jednak najczÄ™Å›ciej (maÅ‚e projekty) korzysta siÄ™ z serwisÃ³w z jakimÅ› systemem git. Jednym z najbardziej rozpoznawanych jest GitHub dziÄ™ki ktÃ³remu moÅ¼esz korzystaÄ‡ z systemu git bez jego instalacji na swoim komputerze.\nW darmowej wersji serwisu GitHub swoje pliki moÅ¼esz przechowywaÄ‡ w publicznych (dostÄ™p majÄ… wszyscy) repozytoriach.\nSkupimy siÄ™ wyÅ‚Ä…cznie na darmowej wersji serwisu GitHub.\ngit --version\n\nStruktura GitHuba\nNa najwyÅ¼szym poziomie znajdujÄ… siÄ™ konta indywidualne np http://github.com/sebkaz, bÄ…dÅº zakÅ‚adane przez organizacje. UÅ¼ytkownicy indywidualni mogÄ… tworzyÄ‡ repozytoria publiczne (public ) bÄ…dÅº prywatne (private).\nJeden plik nie powinien przekraczaÄ‡ 100 MB.\nRepo (skrÃ³t do repozytorium) tworzymy za pomocÄ… Create a new repository. KaÅ¼de repo powinno mieÄ‡ swojÄ… indywidualnÄ… nazwÄ™.\n\n\nBranche\nGÅ‚Ã³wna (tworzona domyÅ›lnie) gaÅ‚Ä…Åº rapozytorium ma nazwÄ™ master.\n\n\nNajwaÅ¼niejsze polecnia do zapamiÄ™tania\n\nÅ›ciÄ…ganie repozytorium z sieci\n\ngit clone https://adres_repo.git\n\nW przypadku githuba moÅ¼esz pobraÄ‡ repozytorium jako plik zip.\n\n\nTworzenie repozytorium dla lokalnego katalogu\n\n# tworzenie nowego katalogu\nmkdir datamining\n# przejÅ›cie do katalogu\ncd datamining\n# inicjalizacja repozytorium w katalogu\ngit init\n# powinien pojawiÄ‡ siÄ™ ukryty katalog .git\n# dodajmy plik\necho \"Info \" &gt;&gt; README.md\n\nPoÅ‚Ä…cz lokalne repozytorium z kontem na githubie\n\ngit remote add origin https://github.com/&lt;twojGit&gt;/nazwa.git\n\nObsÅ‚uga w 3 krokach\n\n# sprawdÅº zmiany jakie zostaÅ‚y dokonane\ngit status\n# 1. dodaj wszystkie zmiany\ngit add .\n# 2. zapisz bierzÄ…cy stan wraz z informacjÄ… co zrobiÅ‚eÅ›\ngit commit -m \" opis \"\n# 3. potem juÅ¼ zostaje tylko\ngit push origin master\nWarto obejrzeÄ‡ Youtube course.\nCiekawe i proste wprowadzenie mozna znaleÅºÄ‡ tutaj"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "href": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z Dockera",
    "text": "Zacznij korzystaÄ‡ z Dockera\n\n\n\nW celu pobrania oprogramowania docker na swÃ³j system przejdÅº do strony.\nJeÅ¼li wszystko zainstalowaÅ‚o siÄ™ prawidÅ‚owo wykonaj nastÄ™pujÄ…ce polecenia:\n\nSprawdÅº zainstalowanÄ… wersjÄ™\n\ndocker --version\n\nÅšciÄ…gnij i uruchom obraz Hello World i\n\ndocker run hello-world\n\nPrzeglÄ…d Å›ciÄ…gnietych obrazÃ³w:\n\ndocker image ls\n\ndocker images\n\nPrzeglÄ…d uruchomionych kontenerÃ³w:\n\ndocker ps \n\ndocker ps -all\n\nZatrzymanie uruchomionego kontenera:\n\ndocker stop &lt;CONTAINER ID&gt;\n\nUsuniÄ™cie kontenera\n\ndocker rm -f &lt;CONTAINER ID&gt;\nPolecam rÃ³wnieÅ¼ krÃ³tkie intro"
  },
  {
    "objectID": "wyklad2.html",
    "href": "wyklad2.html",
    "title": "WykÅ‚ad 2",
    "section": "",
    "text": "â³ Czas trwania: 1,5h ğŸ¯ Cel wykÅ‚adu\nzrozumienie, jak dane ewoluowaÅ‚y w rÃ³Å¼nych branÅ¼ach i jakie narzÄ™dzia sÄ… dziÅ› wykorzystywane do ich analizy.\nW tym wstÄ™pie przedstawimy ewolucjÄ™ analizy danych, pokazujÄ…c, jak zmieniaÅ‚y siÄ™ technologie i podejÅ›cia do przetwarzania danych na przestrzeni lat. Rozpoczniemy od klasycznych struktur tabelarycznych, przez bardziej zaawansowane modele grafowe i tekstowe, aÅ¼ po nowoczesne podejÅ›cie do strumieniowego przetwarzania danych."
  },
  {
    "objectID": "wyklad2.html#ewolucja-danych",
    "href": "wyklad2.html#ewolucja-danych",
    "title": "WykÅ‚ad 2",
    "section": "Ewolucja danych:",
    "text": "Ewolucja danych:\n\nDane tabelaryczne (tabele SQL):\nPoczÄ…tkowo dane byÅ‚y przechowywane w postaci tabel, gdzie kaÅ¼da tabela zawieraÅ‚a zorganizowane informacje w kolumnach i wierszach (np. bazy danych SQL). Modele takie doskonale nadawaÅ‚y siÄ™ do danych ustrukturyzowanych.\nDane ustrukturyzowane zorganizowane sÄ… w kolumnach cech charakteryzujÄ…cych kaÅ¼dÄ… obserwacjÄ™ (wiersze). Kolumny posiadajÄ… etykietÄ™, ktÃ³ra wskazuje na ich interpretacjÄ™.\n\n\nDane grafowe:\nWraz z rozwojem potrzeb biznesowych pojawiÅ‚y siÄ™ dane grafowe, w ktÃ³rych relacje miÄ™dzy obiektami (np. uÅ¼ytkownikami, produktami) sÄ… reprezentowane jako wierzchoÅ‚ki i krawÄ™dzie grafu. PrzykÅ‚ady takich danych to sieci spoÅ‚ecznoÅ›ciowe, linki internetowe czy zaleÅ¼noÅ›ci miÄ™dzy produktami.\n\n\nDane tekstowe:\nKolejnym etapem byÅ‚a analiza danych tekstowych, ktÃ³re zaczÄ™Å‚y odgrywaÄ‡ istotnÄ… rolÄ™ w analizie danych z mediÃ³w spoÅ‚ecznoÅ›ciowych, e-maili, forÃ³w czy opinii. Technologie takie jak przetwarzanie jÄ™zyka naturalnego Natural Language Processing (NLP) pozwalajÄ… wydobywaÄ‡ sens z nieustrukturyzowanego tekstu.\n\n\nDane strumieniowe:\nObecnie najbardziej dynamicznie rozwija siÄ™ analiza danych strumieniowych, gdzie dane sÄ… analizowane na bieÅ¼Ä…co, w miarÄ™ ich napÅ‚ywania. PrzykÅ‚adem takiego podejÅ›cia jest monitorowanie zdarzeÅ„ w czasie rzeczywistym, np. transakcje finansowe, analiza social media, detekcja oszustw."
  },
  {
    "objectID": "wyklad2.html#popularne-narzÄ™dzia-do-przechowywania-i-przetwarzania-danych",
    "href": "wyklad2.html#popularne-narzÄ™dzia-do-przechowywania-i-przetwarzania-danych",
    "title": "WykÅ‚ad 2",
    "section": "Popularne narzÄ™dzia do przechowywania i przetwarzania danych:",
    "text": "Popularne narzÄ™dzia do przechowywania i przetwarzania danych:\n\nSQL i bazy tranzakcyjne OLTP ()\nTradycyjne bazy danych SQL sÄ… idealne do pracy z danymi ustrukturyzowanymi, ktÃ³re wymagajÄ… Å›cisÅ‚ej struktury tabel (np. dane o transakcjach, klientach). SQL jest standardem w analizie takich danych, ale nie jest wystarczajÄ…cy w przypadku pracy z duÅ¼ymi iloÅ›ciami danych nieustrukturyzowanych.\n\n\nNoSQL\nBazy danych NoSQL, takie jak MongoDB, Cassandra, pozwalajÄ… na bardziej elastyczne podejÅ›cie do danych, ktÃ³re mogÄ… przybieraÄ‡ rÃ³Å¼ne formy (np. dokumenty JSON, dane z sensorÃ³w, obrazy). NoSQL Å›wietnie sprawdza siÄ™ w przypadku danych, ktÃ³re nie pasujÄ… do tradycyjnych struktur tabelarycznych.\n\n\nData Lake\nData Lake to systemy przechowywania ogromnych zbiorÃ³w danych, zarÃ³wno ustrukturyzowanych, jak i nieustrukturyzowanych. DziÄ™ki Data Lake organizacje mogÄ… przechowywaÄ‡ dane w pierwotnej formie i analizowaÄ‡ je pÃ³Åºniej w miarÄ™ potrzeb, bez potrzeby wczeÅ›niejszego przetwarzania.\n\n\nApache Kafka\nKafka to system przetwarzania strumieniowego, ktÃ³ry umoÅ¼liwia zbieranie, przechowywanie i przetwarzanie danych w czasie rzeczywistym. Jest szeroko wykorzystywany w aplikacjach wymagajÄ…cych szybkiej reakcji na dane napÅ‚ywajÄ…ce w czasie rzeczywistym.\n\n\nApache Flink\nApache Flink to narzÄ™dzie do przetwarzania strumieniowego, ktÃ³re umoÅ¼liwia analizowanie danych w czasie rzeczywistym z minimalnym opÃ³Åºnieniem. W przeciwieÅ„stwie do Kafki, Flink nie tylko zbiera dane, ale takÅ¼e je przetwarza, co jest szczegÃ³lnie przydatne w analizach zÅ‚oÅ¼onych.\n\n\nPrzykÅ‚ad: Jak Netflix analizuje dane w czasie rzeczywistym?\nNetflix to doskonaÅ‚y przykÅ‚ad firmy, ktÃ³ra z powodzeniem wykorzystuje dane strumieniowe w celu dostarczania uÅ¼ytkownikom spersonalizowanych rekomendacji i analizowania ich zachowaÅ„. DziÄ™ki technologii strumieniowej, Netflix monitoruje dziaÅ‚ania swoich uÅ¼ytkownikÃ³w (co oglÄ…dajÄ…, jakie treÅ›ci przewijajÄ…, jak dÅ‚ugo oglÄ…dajÄ…), analizujÄ…c te dane w czasie rzeczywistym. Na podstawie tej analizy Netflix jest w stanie dostarczaÄ‡ rekomendacje filmÃ³w i seriali w czasie rzeczywistym, dostosowujÄ…c je do zmieniajÄ…cych siÄ™ preferencji uÅ¼ytkownika."
  },
  {
    "objectID": "wyklad2.html#przykÅ‚ad-strumieniowego-przetwarzania-w-netflix",
    "href": "wyklad2.html#przykÅ‚ad-strumieniowego-przetwarzania-w-netflix",
    "title": "WykÅ‚ad 2",
    "section": "PrzykÅ‚ad strumieniowego przetwarzania w Netflix:",
    "text": "PrzykÅ‚ad strumieniowego przetwarzania w Netflix:\nKiedy uÅ¼ytkownik zaczyna oglÄ…daÄ‡ film, system Å›ledzi jego reakcje (np. przerwanie filmu, przewijanie) i dostosowuje rekomendacje do jego preferencji. Takie dane mogÄ… byÄ‡ przesyÅ‚ane do systemu analitycznego za pomocÄ… narzÄ™dzi takich jak Apache Kafka i przetwarzane na Å¼ywo w Apache Flink."
  },
  {
    "objectID": "wyklad2.html#podsumowanie",
    "href": "wyklad2.html#podsumowanie",
    "title": "WykÅ‚ad 2",
    "section": "Podsumowanie",
    "text": "Podsumowanie\nDziÄ™ki ewolucji technologii, analiza danych przeszÅ‚a dÅ‚ugÄ… drogÄ™, od prostych tabel SQL, przez zÅ‚oÅ¼one dane grafowe i tekstowe, aÅ¼ do analiz strumieniowych. Zrozumienie rÃ³Å¼nic miÄ™dzy tymi podejÅ›ciami pozwala na lepsze dobieranie narzÄ™dzi do odpowiednich typÃ³w analiz, w tym wykorzystania nowoczesnych systemÃ³w przetwarzania danych w czasie rzeczywistym, takich jak Kafka i Flink."
  },
  {
    "objectID": "wyklad2.html#ewolucja-analizy-danych-od-struktur-tabelarycznych-do-strumieni",
    "href": "wyklad2.html#ewolucja-analizy-danych-od-struktur-tabelarycznych-do-strumieni",
    "title": "WykÅ‚ad 2",
    "section": "Ewolucja analizy danych: Od struktur tabelarycznych do strumieni",
    "text": "Ewolucja analizy danych: Od struktur tabelarycznych do strumieni\nRozwÃ³j technologii informatycznych stworzyÅ‚ nowe moÅ¼liwoÅ›ci przetwarzania ogromnych iloÅ›ci danych, zarÃ³wno ustrukturyzowanych, jak i nieustrukturyzowanych. W ciÄ…gu ostatnich kilku dekad obserwujemy wzrost dostÄ™pnych danych oraz technologii do ich przechowywania i analizy. DziÄ™ki temu dane staÅ‚y siÄ™ jednym z najcenniejszych zasobÃ³w wspÃ³Å‚czesnych organizacji."
  },
  {
    "objectID": "wyklad2.html#dane-ustrukturyzowane",
    "href": "wyklad2.html#dane-ustrukturyzowane",
    "title": "WykÅ‚ad 2",
    "section": "Dane ustrukturyzowane",
    "text": "Dane ustrukturyzowane\nDane ustrukturyzowane to dane, ktÃ³re sÄ… przechowywane w sposÃ³b zorganizowany i jednoznacznie okreÅ›lony. PrzykÅ‚adami takich danych sÄ… tabele w bazach SQL, w ktÃ³rych kaÅ¼da kolumna reprezentuje jednÄ… cechÄ™, a kaÅ¼dy wiersz to pojedynczy rekord. Tego typu dane sÄ… najczÄ™Å›ciej wykorzystywane w klasycznych algorytmach uczenia maszynowego, takich jak regresja logistyczna, XGBoost czy modele klasyfikacji.\nPrzykÅ‚ad: ZaÅ‚Ã³Å¼my, Å¼e mamy tabelÄ™, w ktÃ³rej kaÅ¼da linia przedstawia dane o kliencie: jego pÅ‚eÄ‡, wzrost, iloÅ›Ä‡ kredytÃ³w itd.\n\n\nCode\ndane_klientow = {\"sex\":[\"m\",\"f\",\"m\",\"m\",\"f\"],\n \"height\":[160, 172, 158, 174, 192],\n \"credits\":[0,0,1,3,1]\n }\n\ndf = pd.DataFrame(dane_klientow)\nprint(df)\n\n\n  sex  height  credits\n0   m     160        0\n1   f     172        0\n2   m     158        1\n3   m     174        3\n4   f     192        1\n\n\nNa tej podstawie moÅ¼emy przewidywaÄ‡ prawdopodobieÅ„stwo spÅ‚aty kredytu (regresja logistyczna). Takie przewidywanie rÃ³wnieÅ¼ oznaczane jest jako cecha (ang. target).\n\n\nCode\ndf['target'] = [0,1,1,0,0]\nprint(df)\n\n\n  sex  height  credits  target\n0   m     160        0       0\n1   f     172        0       1\n2   m     158        1       1\n3   m     174        3       0\n4   f     192        1       0"
  },
  {
    "objectID": "wyklad2.html#dane-nieustrukturyzowane",
    "href": "wyklad2.html#dane-nieustrukturyzowane",
    "title": "WykÅ‚ad 2",
    "section": "Dane nieustrukturyzowane",
    "text": "Dane nieustrukturyzowane\nDane nieustrukturyzowane to dane, ktÃ³re nie majÄ… okreÅ›lonej, tabelarycznej formy. NaleÅ¼Ä… do nich obrazy, dÅºwiÄ™ki, wideo i tekst. ChoÄ‡ te dane wydajÄ… siÄ™ chaotyczne, sÄ… one rÃ³wnieÅ¼ cennym ÅºrÃ³dÅ‚em informacji, ktÃ³re moÅ¼na przetwarzaÄ‡ za pomocÄ… odpowiednich algorytmÃ³w.\nPrzykÅ‚ad: Analiza obrazÃ³w (np. weryfikacja, czy zdjÄ™cie przedstawia psa czy kota) lub analizy tekstu (np. sentymentu w tweetach) sÄ… przykÅ‚adami pracy z danymi nieustrukturyzowanymi.\n\nJakie wyzwania niesie analiza danych w rÃ³Å¼nych formach?\n\nZwiÄ™kszajÄ…cy siÄ™ wolumen danych, a takÅ¼e ich rÃ³Å¼norodnoÅ›Ä‡, stawia przed nami kolejne wyzwania zwiÄ…zane z przetwarzaniem i analizowaniem tych danych.\n\nKluczowe pytanie brzmi: jak efektywnie przetwarzaÄ‡ ogromne iloÅ›ci danych w czasie rzeczywistym?"
  },
  {
    "objectID": "wyklad2.html#przetwarzanie-wsadowe-vs.-przetwarzanie-strumieniowe",
    "href": "wyklad2.html#przetwarzanie-wsadowe-vs.-przetwarzanie-strumieniowe",
    "title": "WykÅ‚ad 2",
    "section": "Przetwarzanie wsadowe vs.Â przetwarzanie strumieniowe",
    "text": "Przetwarzanie wsadowe vs.Â przetwarzanie strumieniowe\nW tradycyjnych systemach analizy danych, takich jak bazy danych SQL, przetwarzanie danych odbywa siÄ™ w trybie wsadowym (batch processing). Oznacza to, Å¼e dane sÄ… zbierane przez pewien czas, a nastÄ™pnie przetwarzane w partiach (np. raz dziennie, raz w tygodniu). Jest to podejÅ›cie, ktÃ³re Å›wietnie sprawdza siÄ™ w analizach historycznych i podejmowaniu decyzji na podstawie duÅ¼ych zbiorÃ³w danych.\n\nPrzykÅ‚ad batch processing:\nPrzetwarzanie wszystkich transakcji dokonanych przez klientÃ³w w ciÄ…gu dnia, aby na koÅ„cu dnia wyciÄ…gnÄ…Ä‡ raporty i wnioski dotyczÄ…ce aktywnoÅ›ci.\nNatomiast przetwarzanie strumieniowe (stream processing) pozwala na bieÅ¼Ä…ce analizowanie danych w momencie ich napÅ‚ywania. DziÄ™ki temu, dane mogÄ… byÄ‡ przetwarzane i analizowane w czasie rzeczywistym, co jest niezwykle waÅ¼ne w przypadku takich zastosowaÅ„ jak wykrywanie naduÅ¼yÄ‡ w czasie rzeczywistym, personalizowanie treÅ›ci czy monitorowanie urzÄ…dzeÅ„ IoT.\n\n\nPrzykÅ‚ad stream processing:\nSystem detekcji oszustw w kartach kredytowych, ktÃ³ry monitoruje transakcje na Å¼ywo, analizujÄ…c je pod kÄ…tem podejrzanych dziaÅ‚aÅ„ (np. przekroczenie typowego wzorca wydatkÃ³w).\nWspÃ³Å‚czesna analiza danych nie ogranicza siÄ™ do prostych zbiorÃ³w danych w formie tabelarycznej. Przechodzimy od danych ustrukturyzowanych do zaawansowanego przetwarzania strumieniowego, ktÃ³re pozwala na podejmowanie decyzji w czasie rzeczywistym. Zrozumienie rÃ³Å¼nicy miÄ™dzy przetwarzaniem wsadowym a strumieniowym to klucz do pracy z nowoczesnymi technologiami i narzÄ™dziami, ktÃ³re napÄ™dzajÄ… innowacje w wielu dziedzinach."
  },
  {
    "objectID": "wyklad2.html#ÅºrÃ³dÅ‚a-danych",
    "href": "wyklad2.html#ÅºrÃ³dÅ‚a-danych",
    "title": "WykÅ‚ad 2",
    "section": "Å¹rÃ³dÅ‚a danych",
    "text": "Å¹rÃ³dÅ‚a danych\nDo trzech najwiÄ™kszych â€œgeneratorÃ³wâ€ danych naleÅ¼Ä…:\n\ndane spoÅ‚eczne w formie tekstÃ³w (tweety, wpisy w portalach spoÅ‚ecznoÅ›ciowych, komentarze), zdjÄ™Ä‡ czy plikÃ³w wideo. Przydatne do problemÃ³w biznesowych realizujÄ…cych ocenÄ™ zachowaÅ„ i nastrojÃ³w konsumentÃ³w w analizach marketingowych.\nIoT: dane pochodzÄ…ce z czujnikÃ³w, czy teÅ¼ logi dziaÅ‚ania urzÄ…dzeÅ„ i uÅ¼ytkownikÃ³w (np. na stronie www).\ndane transakcyjne: czyli ogÃ³lnie to co w kaÅ¼dej chwili generowane jest jako transakcje pojawiajÄ…ce siÄ™ zarÃ³wno w trybie online jak i w trybie offline.\n\n\nRzeczywisty proces generowania danych\nDane generowane sÄ… w postaci nieograniczonej - pojawiajÄ… siÄ™ na skutek ciÄ…gÅ‚ych dziaÅ‚aÅ„ systemÃ³w. W swoim telefonie wygenerowaÅ‚eÅ› dziÅ› (a nawet na tych zajÄ™ciach!) wiele danych. Czy na nastÄ™pnych zajÄ™ciach lub tez jutro nie bÄ™dziesz ich generowaÅ‚?\nDane zawsze generowane sÄ… jako jakaÅ› forma strumienia danych.\nSystemy obsÅ‚ugujÄ…ce strumienie danych: - hurtownie danych - systemy monitorujÄ…ce dziaÅ‚ania urzÄ…dzeÅ„ (IoT) - systemy transakcyjne - systemy analityczne stron www - reklamy on-line - media spoÅ‚ecznoÅ›ciowe - systemy logowania - â€¦.\n\nfirma to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ danych. Zobacz\n\nW przetwarzaniu wsadowym ÅºrÃ³dÅ‚em (ale i wynikiem przetwarzania) danych jest plik. Jest on zapisywany raz i moÅ¼na siÄ™ do niego odwoÅ‚aÄ‡ (moÅ¼e na nim dziaÅ‚aÄ‡ wiele procesÃ³w - zadaÅ„). Nazwa pliku to element identyfikujÄ…cy zbiÃ³r rekordÃ³w.\nW przypadku strumienia zdarzenie jest generowane tylko raz przez tzw. producenta (zwanego teÅ¼ nadawcÄ… lub dostawcÄ…). PowstaÅ‚e zdarzenie przetwarzane moÅ¼e byÄ‡ przez wielu tzw. konsumentÃ³w (odbiorcÃ³w). Zdarzenia strumieniowe grupowane sÄ… w tzw. tematy (ang. topics)."
  },
  {
    "objectID": "wyklad2.html#architektura-systemÃ³w-real-time",
    "href": "wyklad2.html#architektura-systemÃ³w-real-time",
    "title": "WykÅ‚ad 2",
    "section": "Architektura systemÃ³w real-time",
    "text": "Architektura systemÃ³w real-time\nWykorzystanie systemÃ³w real-time (czas rzeczywisty) w analizie danych wymaga odpowiedniej architektury, ktÃ³ra bÄ™dzie mogÅ‚a szybko przetwarzaÄ‡ ogromne iloÅ›ci danych oraz reagowaÄ‡ na nie w czasie rzeczywistym. Architektura systemu real-time jest kluczowa, poniewaÅ¼ umoÅ¼liwia szybsze podejmowanie decyzji, monitorowanie procesÃ³w w czasie rzeczywistym i reagowanie na zdarzenia bez opÃ³Åºnienia.\nOmÃ³wimy gÅ‚Ã³wne elementy architektury systemÃ³w real-time, popularne wzorce architektoniczne oraz technologie, ktÃ³re sÄ… wykorzystywane do budowy takich systemÃ³w.\n\nPodstawowe elementy systemu real-time\nSystemy real-time muszÄ… speÅ‚niaÄ‡ szereg wymagaÅ„ zwiÄ…zanych z czasem przetwarzania danych. Istnieje kilka kluczowych komponentÃ³w w architekturze systemu, ktÃ³re zapewniajÄ… jego prawidÅ‚owe funkcjonowanie.\n\nProducent danych (Data Producer)\nDane w systemie real-time pochodzÄ… z rÃ³Å¼nych ÅºrÃ³deÅ‚, takich jak:\n\nCzujniki IoT: np. monitorowanie maszyn w fabryce, urzÄ…dzenia medyczne.\nTransakcje w czasie rzeczywistym: np. zakupy online, dane z gieÅ‚dy.\nDane uÅ¼ytkownikÃ³w: np. logi uÅ¼ytkownikÃ³w w aplikacjach mobilnych, dane z mediÃ³w spoÅ‚ecznoÅ›ciowych.\n\n\n\nPrzesyÅ‚anie danych (Data Transport)\nDane muszÄ… byÄ‡ szybko przesyÅ‚ane do systemÃ³w, ktÃ³re mogÄ… je analizowaÄ‡. W tym celu wykorzystywane sÄ… technologie strumieniowe, takie jak:\n\nApache Kafka: popularny system do przesyÅ‚ania danych w czasie rzeczywistym, zapewniajÄ…cy wysokÄ… wydajnoÅ›Ä‡ i niezawodnoÅ›Ä‡.\nApache Pulsar: alternatywa dla Kafki, dedykowana do przetwarzania danych w czasie rzeczywistym z duÅ¼Ä… iloÅ›ciÄ… subskrybentÃ³w.\n\n\n\nPrzetwarzanie danych (Data Processing)\nDane w systemach real-time sÄ… czÄ™sto przetwarzane w strumieniu. Dwa gÅ‚Ã³wne modele przetwarzania to:\n\nBatch processing: Przetwarzanie danych w partiach, ktÃ³re moÅ¼e mieÄ‡ opÃ³Åºnienie, ale przetwarza dane w sposÃ³b efektywny. MoÅ¼e byÄ‡ wykorzystywane w kombinacji z systemami real-time do agregacji danych.\nStream processing: Przetwarzanie danych w czasie rzeczywistym, bez opÃ³ÅºnieÅ„, w ktÃ³rym dane sÄ… natychmiastowo analizowane i przetwarzane.\n\n\n\nSkÅ‚adowanie danych (Data Storage)\nPrzechowywanie danych w systemie real-time zaleÅ¼y od wymagaÅ„ aplikacji. Dwa gÅ‚Ã³wne rodzaje przechowywania to:\n\nData Lake: skÅ‚adowanie ogromnych iloÅ›ci nieprzetworzonych danych w postaci surowych plikÃ³w. Bazy danych NoSQL: takie jak Cassandra, ktÃ³re umoÅ¼liwiajÄ… szybki dostÄ™p do danych w czasie rzeczywistym.\nData Warehouse: skÅ‚adowanie przetworzonych danych w celu ich analizy.\n\n\n\nAnaliza i wizualizacja danych (Data Analytics and Visualization)\nPo przetworzeniu danych w czasie rzeczywistym naleÅ¼y wykonaÄ‡ ich analizÄ™ i prezentacjÄ™ w sposÃ³b zrozumiaÅ‚y dla uÅ¼ytkownika:\n\nDashboardy: narzÄ™dzia takie jak Grafana lub Kibana, ktÃ³re sÅ‚uÅ¼Ä… do wizualizacji wynikÃ³w w czasie rzeczywistym.\nMachine Learning: zastosowanie algorytmÃ³w uczenia maszynowego w czasie rzeczywistym do klasyfikacji, wykrywania anomalii czy predykcji (np. wykrywanie oszustw).\n\n\n\n\nPopularne architektury systemÃ³w real-time\n\nLambda Architecture\nLambda Architecture to popularna koncepcja przetwarzania danych, ktÃ³ra Å‚Ä…czy przetwarzanie wsadowe z przetwarzaniem strumieniowym. To klasyczna architektura uÅ¼ywana w systemach przetwarzania Big Data, ktÃ³ra zakÅ‚ada dwie warstwy:\n\nBatch Layer: przetwarzanie (duÅ¼ych iloÅ›ci) danych wsadowych, ktÃ³re sÄ… pÃ³Åºniej wykorzystywane do analizy. Realizuje procesy przetwarzania w trybie offline\nSpeed Layer (Real-Time Layer): przetwarzanie danych w czasie rzeczywistym, czyli napÅ‚ywajÄ…ce dane strumieniowe, np. z sensorÃ³w, social media, transakcji, w celu uzyskania natychmiastowych wynikÃ³w.\nServing Layer: warstwa, ktÃ³ra Å‚Ä…czy wyniki obu poprzednich warstw i dostarcza je do uÅ¼ytkownika np. za pomocÄ… API.\n\n \n\n\nZalety i Wady Lambda Architecture:\n\nâœ… MoÅ¼liwoÅ›Ä‡ Å‚Ä…czenia przetwarzania wsadowego i strumieniowego,\nâœ… wsparcie dla duÅ¼ych zbiorÃ³w danych,\nâœ… elastycznoÅ›Ä‡ w przetwarzaniu zÅ‚oÅ¼onych zapytaÅ„.\nâŒ Wymaga utrzymywania dwÃ³ch oddzielnych systemÃ³w do przetwarzania danych (batch i stream), co prowadzi do zÅ‚oÅ¼onoÅ›ci implementacji i utrzymania.\n\n\n\nKappa Architecture\nKappa Architecture jest uproszczonÄ… wersjÄ… Lambda Architecture. Zamiast uÅ¼ywaÄ‡ dwÃ³ch osobnych warstw (batch i speed), Kappa wykorzystuje tylko jednÄ… warstwÄ™ przetwarzania strumieniowego, co upraszcza caÅ‚y system.\nJest to bardziej elastyczne podejÅ›cie do budowy systemÃ³w real-time, zwÅ‚aszcza w przypadku, gdy dane sÄ… przetwarzane tylko w jednym trybie (streaming).\n \n\n\nZalety i Wady Kappa Architecture:\n\nâœ… Prostota: Jako Å¼e przetwarzanie danych odbywa siÄ™ tylko w jednym strumieniu, caÅ‚y system jest prostszy i bardziej spÃ³jny.\nâœ… SkalowalnoÅ›Ä‡: DziÄ™ki eliminacji warstwy batch, system jest bardziej elastyczny i skalowalny w kontekÅ›cie analizy danych w czasie rzeczywistym.\nâœ… Idealne dla ML: Kappa Architecture Å›wietnie sprawdza siÄ™ w zastosowaniach zwiÄ…zanych z Machine Learning, poniewaÅ¼ przetwarzanie danych odbywa siÄ™ na bieÅ¼Ä…co, co pozwala na szybsze uczenie i wdraÅ¼anie modeli ML w czasie rzeczywistym.\nâŒ MoÅ¼e byÄ‡ mniej wydajna przy bardzo duÅ¼ych zbiorach danych, w przypadku, gdy wymagane jest skomplikowane przetwarzanie wsadowe.\n\n\n\nMicroservices Architecture\nArchitektura mikroserwisÃ³w jest powszechnie wykorzystywana w systemach real-time, poniewaÅ¼ umoÅ¼liwia:\n\nPodziaÅ‚ aplikacji na mniejsze, autonomiczne jednostki.\nElastycznoÅ›Ä‡ i skalowalnoÅ›Ä‡ systemu.\nMoÅ¼liwoÅ›Ä‡ przetwarzania rÃ³Å¼nych rodzajÃ³w danych przez rÃ³Å¼ne mikroserwisy.\nWykorzystanie komunikacji asynchronicznej, np. przez kolejki wiadomoÅ›ci.\n\n\n\nPrzykÅ‚ad\nUber to przykÅ‚ad firmy, ktÃ³ra skutecznie wykorzystuje narzÄ™dzia do przetwarzania strumieniowego, by monitorowaÄ‡ ruch drogowy w czasie rzeczywistym. DziÄ™ki systemowi Apache Kafka, Uber gromadzi dane o ruchu drogowym, lokalizacji pojazdÃ³w oraz czasach oczekiwania na przejazd, ktÃ³re sÄ… nastÄ™pnie analizowane na Å¼ywo.\nDane wejÅ›ciowe: Informacje o czasie i miejscu podrÃ³Å¼y, dane GPS z pojazdÃ³w, natÄ™Å¼enie ruchu.\nProces przetwarzania: Uber wykorzystuje Apache Kafka do przesyÅ‚ania tych danych w czasie rzeczywistym do systemÃ³w takich jak Apache Flink lub Spark Streaming, ktÃ³re analizujÄ… je na bieÅ¼Ä…co.\nAnaliza: System przewiduje czas oczekiwania na przejazd, monitoruje warunki drogowe oraz optymalizuje trasÄ™ w czasie rzeczywistym.\nWynik: UÅ¼ytkownicy Ubera otrzymujÄ… prognozy czasu przejazdu, a Uber dynamicznie dostosowuje zasoby (np. przydzielanie kierowcÃ³w), co umoÅ¼liwia optymalizacjÄ™ transportu."
  },
  {
    "objectID": "ksiazki.html",
    "href": "ksiazki.html",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "G. Maas, F. Garillot Stream Processing with Apache Spark Zobacz opis lub Kup e-book\nF. Hueske, V. Kalavri Stream Processing with Apache Flink Zobacz opis lub Kup e-book\n\n\n\nA. Bellemare MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™ Zobacz opis lub Kup\n\n\n\n\n\n\nW. McKinney Python w analizie danych. Przetwarzanie danych za pomocÄ… pakietÃ³w Pandas i NumPy oraz Å›rodowiska IPython. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. McIlwraith, H. Marmanis, D. Babenko Inteligentna sieÄ‡. Algorytmy przyszÅ‚oÅ›ci. Wydanie II (ebook) Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJoel Grus Data science od podstaw. Analiza danych w Pythonie. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nJohn W. Foreman Mistrz analizy danych. Od danych do wiedzy. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nA. Geron Uczenie maszynowe z uÅ¼yciem Scikit-Learn i TensorFlow. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nAlberto Boschetti, Luca Massaron Python. Podstawy nauki o danych. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nSebastian Raschka Python. Uczenie maszynowe. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nR. Schutt, C. Oâ€™Neil Badanie danych. Raport z pierwszej lini dziaÅ‚aÅ„. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nT. Segaran Nowe usÅ‚ugi 2.0. Przewodnik po analizie zbiorÃ³w danych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nF. Chollet Deep Learning. Praca z jÄ™zykiem Python i bibliotekÄ… Keras. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Patterson, A. Gibson Deep Learning. Praktyczne wprowadzenie (ebook) Zobacz opis lub Kup e-book\nV. Zocca, G. Spacagna, D. Slater, P. Roelants. Deep Learning. Uczenie gÅ‚Ä™bokie z jÄ™zykiem Python. Sztuczna inteligencja i sieci neuronowe Zobacz opis lub Kup ebook\nD. Osinga Deep Learning. Receptury Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Weidman Uczenie gÅ‚Ä™bokie od zera. Podstawy implementacji w Pythonie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. Foster Deep learning i modelowanie generatywne. Jak nauczyÄ‡ komputer malowania, pisania, komponowania i grania Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Howard, S. Gugger Deep learning dla programistÃ³w. Budowanie aplikacji AI za pomocÄ… fastai i PyTorch Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nJ. S. Damji, B. Wenig, T. Das, D. Lee Spark. BÅ‚yskawiczna analiza danych Zobacz opis lub Kup\nSpark. Zaawansowana analiza danych (ebook) Zobacz opis lub Kup e-book\nB. Chambers, M. Zaharia Spark: The Definitive Guide. Big Data Processing Made Simple (ebook) Zobacz opis lub Kup e-book\nJ. Quddus Machine Learning with Apache Spark Quick Start Guide (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nG. Coldwind ZrozumieÄ‡ programowanie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nA. Allain C++. Przewodnik dla poczÄ…tkujÄ…cych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Dasgupta, C. Papadimitriou, U. Vazirani Algorytmy PWN.\n\n\n\n\n\nJ. Krochmalski Docker. Projektowanie i wdraÅ¼anie aplikacji Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nR. McKendrick, S. Gallagher Docker. Programowanie aplikacji dla zaawansowanych. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nP. Bell, B. Beer GitHub. Przyjazny przewodnik (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nC. Althoff, Programista Samouk. Profesjonalny przewodnik do samodzielnej nauki kodowania. Zobacz opis lub Kup teraz, Kup e-book\nA. Sweigart, Automatyzacja nudnych zadaÅ„ z pythonem. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nK. Reitz, T. Schlusser Przewodnik po Pythonie. Dobre praktyki i praktyczne narzÄ™dzia. Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nB.Tate, L. Carslon, C. Hiibs, Ruby on Rails. Wprowadzenie. Wydanie II Zobacz opis lub Kup e-book\nB. Frain, Responsive Web Design. Projektowanie elastycznych witryn w HTML5 i CSS3, Zobacz opis lub Kup e-book\nK. Beck, TDD. Sztuda tworzenia, Zobacz opis lub Kup teraz, Kup e-book\nB. Dayley, Node.js, MongoDB, AngularJS. Kompendium wiedzy, Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage."
  },
  {
    "objectID": "ksiazki.html#ksiÄ…Å¼ki",
    "href": "ksiazki.html#ksiÄ…Å¼ki",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "G. Maas, F. Garillot Stream Processing with Apache Spark Zobacz opis lub Kup e-book\nF. Hueske, V. Kalavri Stream Processing with Apache Flink Zobacz opis lub Kup e-book\n\n\n\nA. Bellemare MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™ Zobacz opis lub Kup\n\n\n\n\n\n\nW. McKinney Python w analizie danych. Przetwarzanie danych za pomocÄ… pakietÃ³w Pandas i NumPy oraz Å›rodowiska IPython. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. McIlwraith, H. Marmanis, D. Babenko Inteligentna sieÄ‡. Algorytmy przyszÅ‚oÅ›ci. Wydanie II (ebook) Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJoel Grus Data science od podstaw. Analiza danych w Pythonie. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nJohn W. Foreman Mistrz analizy danych. Od danych do wiedzy. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nA. Geron Uczenie maszynowe z uÅ¼yciem Scikit-Learn i TensorFlow. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nAlberto Boschetti, Luca Massaron Python. Podstawy nauki o danych. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nSebastian Raschka Python. Uczenie maszynowe. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nR. Schutt, C. Oâ€™Neil Badanie danych. Raport z pierwszej lini dziaÅ‚aÅ„. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nT. Segaran Nowe usÅ‚ugi 2.0. Przewodnik po analizie zbiorÃ³w danych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nF. Chollet Deep Learning. Praca z jÄ™zykiem Python i bibliotekÄ… Keras. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Patterson, A. Gibson Deep Learning. Praktyczne wprowadzenie (ebook) Zobacz opis lub Kup e-book\nV. Zocca, G. Spacagna, D. Slater, P. Roelants. Deep Learning. Uczenie gÅ‚Ä™bokie z jÄ™zykiem Python. Sztuczna inteligencja i sieci neuronowe Zobacz opis lub Kup ebook\nD. Osinga Deep Learning. Receptury Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Weidman Uczenie gÅ‚Ä™bokie od zera. Podstawy implementacji w Pythonie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. Foster Deep learning i modelowanie generatywne. Jak nauczyÄ‡ komputer malowania, pisania, komponowania i grania Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Howard, S. Gugger Deep learning dla programistÃ³w. Budowanie aplikacji AI za pomocÄ… fastai i PyTorch Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nJ. S. Damji, B. Wenig, T. Das, D. Lee Spark. BÅ‚yskawiczna analiza danych Zobacz opis lub Kup\nSpark. Zaawansowana analiza danych (ebook) Zobacz opis lub Kup e-book\nB. Chambers, M. Zaharia Spark: The Definitive Guide. Big Data Processing Made Simple (ebook) Zobacz opis lub Kup e-book\nJ. Quddus Machine Learning with Apache Spark Quick Start Guide (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nG. Coldwind ZrozumieÄ‡ programowanie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nA. Allain C++. Przewodnik dla poczÄ…tkujÄ…cych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Dasgupta, C. Papadimitriou, U. Vazirani Algorytmy PWN.\n\n\n\n\n\nJ. Krochmalski Docker. Projektowanie i wdraÅ¼anie aplikacji Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nR. McKendrick, S. Gallagher Docker. Programowanie aplikacji dla zaawansowanych. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nP. Bell, B. Beer GitHub. Przyjazny przewodnik (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nC. Althoff, Programista Samouk. Profesjonalny przewodnik do samodzielnej nauki kodowania. Zobacz opis lub Kup teraz, Kup e-book\nA. Sweigart, Automatyzacja nudnych zadaÅ„ z pythonem. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nK. Reitz, T. Schlusser Przewodnik po Pythonie. Dobre praktyki i praktyczne narzÄ™dzia. Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nB.Tate, L. Carslon, C. Hiibs, Ruby on Rails. Wprowadzenie. Wydanie II Zobacz opis lub Kup e-book\nB. Frain, Responsive Web Design. Projektowanie elastycznych witryn w HTML5 i CSS3, Zobacz opis lub Kup e-book\nK. Beck, TDD. Sztuda tworzenia, Zobacz opis lub Kup teraz, Kup e-book\nB. Dayley, Node.js, MongoDB, AngularJS. Kompendium wiedzy, Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage."
  },
  {
    "objectID": "ksiazki.html#strony-www",
    "href": "ksiazki.html#strony-www",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "Strony WWW",
    "text": "Strony WWW\n\nSoftware\n\nGithub\nGit-instrukcja\nwww.python.org\nPyPI python libraries\nAnaconda\nDocker\n\n\n\nPakiety python dla analiz danych\n\nNumPy\nSciPy\nPandas\nScikit-learn\nJupyter\nMatplotlib\nBeautiful Soup\nTheano\nKeras\nTensorFlow\nVirtual ENV\n\n\n\nEdytory tekstu\n\nNotepad++\nSublime Text\nVisual Studio Code\n\n\n\nMarkdown\n\nMD\n\n\n\nJupyter notebook\n\nGaleria ciekawych notatnikÃ³w\nIntro\nKernels\nBringing the best out of jupyter for data science\nJupyter extensions\nI donâ€™t like notebooks\nJupyter lab\nSpeed up jupyter notebook\n\n\n\nPrzetwarzanie danych\n\ndata cookbook\n\n\n\nZbiory danych\n\nInternet Archive\nReddit\nKDnuggets\nKaggle\nList of datasets for machine learning research\nUCI Machine Learning Repo\nPublic API\nGoogle Datatset Search\n\n\n\nPython\n\nChris Albon Technical Notes on Using Data Science & AI\n40+ Python Statistics For Data Science Resources\nPractical Business Python\n\n\n\nkursy ML\n\nKurs Machine Learning - Andrew Ng, Stanford\nKurs Machine Learning - Andrew Ng, Stanford\nPython programming for data science"
  },
  {
    "objectID": "sylabus.html",
    "href": "sylabus.html",
    "title": "Sylabus",
    "section": "",
    "text": "Nazwa przedmiotu: Analiza danych w czasie rzeczywistym\nJednostka: SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nKod przedmiotu: 222890-D, 222890-S\nPunkty ECTS: 3\nJÄ™zyk prowadzenia: polski\nPoziom przedmiotu: Å›rednio-zaawansowany\nProwadzÄ…cy: Sebastian ZajÄ…c, sebastian.zajac@sgh.waw.pl\nWebsite: https://sebkaz-teaching.github.io/RTA_2025/"
  },
  {
    "objectID": "sylabus.html#cel-przedmiotu",
    "href": "sylabus.html#cel-przedmiotu",
    "title": "Sylabus",
    "section": "Cel Przedmiotu",
    "text": "Cel Przedmiotu\nWspÃ³Å‚czesny biznes opiera siÄ™ na podejmowaniu decyzji opartych na danych. Coraz wiÄ™ksza iloÅ›Ä‡ informacji, rosnÄ…ce wymagania rynku oraz potrzeba natychmiastowej reakcji sprawiajÄ…, Å¼e analiza danych w czasie rzeczywistym staje siÄ™ kluczowym elementem nowoczesnych procesÃ³w biznesowych.\nNa zajÄ™ciach studenci zapoznajÄ… siÄ™ z metodami i technologiami umoÅ¼liwiajÄ…cymi przetwarzanie danych w czasie rzeczywistym. SzczegÃ³lnÄ… uwagÄ™ poÅ›wiÄ™cimy zastosowaniu uczenia maszynowego (machine learning), sztucznej inteligencji (artificial intelligence) oraz gÅ‚Ä™bokich sieci neuronowych (deep learning) w analizie danych. Zrozumienie tych metod pozwala nie tylko lepiej interpretowaÄ‡ zjawiska biznesowe, ale takÅ¼e podejmowaÄ‡ szybkie i trafne decyzje.\nW ramach kursu omÃ³wimy zarÃ³wno dane ustrukturyzowane, jak i nieustrukturyzowane (obrazy, dÅºwiÄ™k, strumieniowanie wideo). Studenci poznajÄ… architektury przetwarzania danych, takie jak lambda i kappa, wykorzystywane w systemach data lake, a takÅ¼e wyzwania zwiÄ…zane z modelowaniem danych w czasie rzeczywistym na duÅ¼Ä… skalÄ™.\nKurs obejmuje czÄ™Å›Ä‡ teoretycznÄ… oraz praktyczne laboratoria, podczas ktÃ³rych studenci bÄ™dÄ… pracowaÄ‡ z rzeczywistymi danymi w Å›rodowiskach takich jak: JupyterLab, PyTorch, Apache Spark, Apache Kafka. DziÄ™ki temu studenci nie tylko zdobÄ™dÄ… wiedzÄ™ na temat metod analitycznych, ale takÅ¼e nauczÄ… siÄ™ korzystaÄ‡ z najnowszych technologii informatycznych stosowanych w analizie danych w czasie rzeczywistym."
  },
  {
    "objectID": "sylabus.html#program-przedmiotu",
    "href": "sylabus.html#program-przedmiotu",
    "title": "Sylabus",
    "section": "Program przedmiotu",
    "text": "Program przedmiotu\n\nModelowanie, uczenie i predykcja w trybie wsadowym (offline learning) i przyrostowym (online learning). Problemy przyrostowego uczenia maszynowego.\nModele przetwarzania danych w Big Data. Od plikoÌw pÅ‚askich do Data Lake. Mity i fakty przetwarzania danych w czasie rzeczywistym. (WykÅ‚ad)\nSystemy NRT (near real-time systems), pozyskiwanie danych, streaming, analityka.\nAlgorytmy estymacji parametroÌw modelu w trybie przyrostowym. Stochastic Gradient Descent.\nArchitektura Lambda i Kappa. Zaprojektowanie architektury IT dla przetwarzania danych w czasie rzeczywistym.\nPrzygotowanie mikroserwisu z modelem ML do zastosowania produkcyjnego.\nStrukturyzowane i niestrukturyzowane dane. Relacyjne bazy danych i bazy NoSQL\nAgregacje i raportowanie w bazach NoSQL (na przykÅ‚adzie bazy Cassandra).\nPodstawy obiektowego programowania w Pythonie w analizie regresji liniowej, logistycznej oraz sieci neuronowych z wykorzystaniem biblioteki sklearn, TensorFLow i Keras\nArchitektura IT przetwarzania Big Data. Przygotowanie wirtualnego sÌrodowiska dla Sparka. Pierwszy program w PySpark. Wykorzystanie przygotowanego sÌrodowiska do analizy danych z serwisu Twitter.\nAnaliza 1 Detekcja wyÅ‚udzenÌ w zgÅ‚oszeniach szkoÌd samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego sÌrodowiska. Cz 1.\nAnaliza 1 Detekcja wyÅ‚udzenÌ w zgÅ‚oszeniach szkoÌd samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego sÌrodowiska. Cz 2.\nPrzygotowanie sÌrodowiska Microsoft Azure. Detekcja anomalii i wartosÌci odstajaÌ¨cych w logowanych zdarzeniach sieci Ethernet cz 1.\nAnaliza 2 Detekcja anomalii i wartosÌci odstajaÌ¨cych w logowanych zdarzeniach sieci Ethernet cz 2. Inne narzeÌ¨dzia IT do szybkiej analizy logoÌw.\nNarzeÌ¨dzia SAS do strumieniowego przetwarzania danych"
  },
  {
    "objectID": "sylabus.html#efekty-ksztaÅ‚cenia",
    "href": "sylabus.html#efekty-ksztaÅ‚cenia",
    "title": "Sylabus",
    "section": "Efekty ksztaÅ‚cenia",
    "text": "Efekty ksztaÅ‚cenia\n\nWiedza:\n\n\nZna historieÌ¨ i filozofieÌ¨ modeli przetwarzania danych\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W02, (OGL)O2_W04, (OGL)O2_W07\nMetody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ z kolokwium\n\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W04, (OGL)O2_W04, (OGL) O2_W07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nZna mozÌ‡liwosÌci i obszary zastosowania procesowania danych w czasie rzeczywistym\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W02, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W08\nMetody weryfikacji: egzamin pisemny (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ egzaminacyjnych\n\nZna teoretyczne aspekty struktury lambda i kappa\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W03, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W04, (OGL) O2_W06, (OGL)O2_W08\nMetody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ z kolokwium\n\nUmie wybracÌ struktureÌ¨ IT dla danego problemu biznesowego\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nRozumie potrzeby biznesowe podejmowania decyzji w bardzo kroÌtkim czasie\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmiejÄ™tnoÅ›ci:\n\n\nRozroÌzÌ‡nia typy danych strukturyzowanych jak i niestrukturyzowanych\n\nPowiaÌ¨zania: K2A_U02, K2A_U07, K2A_U10, O2_U02\nMetody weryfikacji: test\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie przygotowacÌ, przetwarzacÌ oraz zachowywacÌ dane generowane w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U03, K2A_U05, K2A_U09, O2_U02, O2_U04\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nRozumie ograniczenia wynikajaÌ¨ce z czasu przetwarzania przez urzaÌ¨dzenia oraz systemy informatyczne\n\nPowiaÌ¨zania: K2A_U01, K2A_U07, K2A_U11, O2_U02\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie zastosowacÌ i skonstruowacÌ system do przetwarzania w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U05, K2A_U10, O2_U05, O2_U06, O2_U07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie przygotowacÌ raportowanie dla systemu przetwarzania w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U02, K2A_U08, K2A_U10, O2_U06, O2_U07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nKompetencje:\n\n\nFormuÅ‚uje problem analityczny wraz z jego informatycznym rozwiaÌ¨zaniem\n\nPowiaÌ¨zania: K2A_K01, K2A_K03, O2_K02, O2_K06, O2_K07\nMetody weryfikacji: projekt, prezentacja\nMetody dokumentacji: prace pisemne studenta (w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUtrwala umiejeÌ¨tnosÌcÌ samodzielnego uzupeÅ‚niania wiedzy teoretycznej jak i praktycznej w zakresie programowania, modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym.\n\nPowiaÌ¨zania: K2A_K02, K2A_K04, (OGL)O2_K01, (OGL) O2_K02, (OGL)O2_K05, (OGL)O2_K06\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)"
  },
  {
    "objectID": "sylabus.html#realizacja-przedmiotu",
    "href": "sylabus.html#realizacja-przedmiotu",
    "title": "Sylabus",
    "section": "Realizacja przedmiotu",
    "text": "Realizacja przedmiotu\n\negzamin testowy 20%\nZadania 40%\nProjekt 40%"
  },
  {
    "objectID": "sylabus.html#literatura",
    "href": "sylabus.html#literatura",
    "title": "Sylabus",
    "section": "Literatura",
    "text": "Literatura\n1ï¸âƒ£ ZajÄ…c S. (red.), Modelowanie dla biznesu, Analityka w czasie rzeczywistym - narzÄ™dzia informatyczne i biznesowe, SGH, Warszawa 2022.\n2ï¸âƒ£ FrÄ…tczak E. (red.), Modelowanie dla biznesu: Regresja logistyczna, Regresja Poissona, Survival Data Mining, CRM, Credit Scoring, SGH, Warszawa 2019.\n3ï¸âƒ£ Bellemare A., MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™, Oâ€™Reilly 2021.\n4ï¸âƒ£ Shapira G., Palino T., Sivaram R., Petty K., Kafka: The Definitive Guide. Real-time data and stream processing at scale, Oâ€™Reilly 2022.\n5ï¸âƒ£ Lakshmanan V., Robinson S., Munn M., Wzorce projektowe uczenia maszynowego. RozwiÄ…zania typowych problemÃ³w dotyczÄ…cych przygotowania danych, konstruowania modeli i MLOps, Oâ€™Reilly 2021.\n6ï¸âƒ£ Gift N., Deza A., Practical MLOps: Operationalizing Machine Learning Models, Oâ€™Reilly 2022.\n7ï¸âƒ£ Tiark Rompf, Streaming Systems: The What, Where, When, and How of Large-Scale Data Processing, Oâ€™Reilly 2018.\n8ï¸âƒ£ SebastiÃ¡n RamÃ­rez, FastAPI: Modern Web APIs with Python, Manning (w przygotowaniu, aktualnie dostÄ™pna online).\n9ï¸âƒ£ Trevor Hastie, Robert Tibshirani, Jerome Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer 2017.\nğŸ”Ÿ Anirudh Koul, Siddha Ganju, Meher Kasam, Practical Deep Learning for Cloud, Mobile & Edge, Oâ€™Reilly 2019."
  },
  {
    "objectID": "wyklad1.html",
    "href": "wyklad1.html",
    "title": "WykÅ‚ad 1",
    "section": "",
    "text": "â³ Czas trwania: 1,5h\nğŸ¯ Cel wykÅ‚adu\nZapoznanie studentÃ³w z podstawami real-time analytics, rÃ³Å¼nicami miÄ™dzy trybami przetwarzania danych (batch, streaming, real-time) oraz kluczowymi zastosowaniami i wyzwaniami."
  },
  {
    "objectID": "wyklad1.html#czym-jest-analiza-danych-w-czasie-rzeczywistym",
    "href": "wyklad1.html#czym-jest-analiza-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 1",
    "section": "Czym jest analiza danych w czasie rzeczywistym?",
    "text": "Czym jest analiza danych w czasie rzeczywistym?\n\nDefinicja i kluczowe koncepcje\nAnaliza danych w czasie rzeczywistym (ang. Real-Time Data Analytics) to proces przetwarzania i analizy danych natychmiast po ich wygenerowaniu, bez koniecznoÅ›ci przechowywania i oczekiwania na pÃ³Åºniejsze przetworzenie. Celem jest uzyskanie natychmiastowych wnioskÃ³w i reakcji na zmieniajÄ…ce siÄ™ warunki w systemach biznesowych, technologicznych i naukowych.\n\n\nKluczowe cechy analizy danych w czasie rzeczywistym:\n\nNiska latencja (ang. low-latency) â€“ dane sÄ… analizowane w ciÄ…gu milisekund lub sekund od ich wygenerowania.\nStreaming vs.Â Batch Processing â€“ analiza danych moÅ¼e odbywaÄ‡ siÄ™ w sposÃ³b ciÄ…gÅ‚y (streaming) lub w z gÃ³ry okreÅ›lonych interwaÅ‚ach (batch).\nIntegracja z IoT, AI i ML â€“ real-time analytics czÄ™sto wspÃ³Å‚pracuje z Internetem Rzeczy (IoT) oraz algorytmami sztucznej inteligencji.\nPodejmowanie decyzji w czasie rzeczywistym â€“ np. natychmiastowa detekcja oszustw w transakcjach bankowych."
  },
  {
    "objectID": "wyklad1.html#zastosowanie-analizy-danych-w-czasie-rzeczywistym-w-biznesie",
    "href": "wyklad1.html#zastosowanie-analizy-danych-w-czasie-rzeczywistym-w-biznesie",
    "title": "WykÅ‚ad 1",
    "section": "Zastosowanie analizy danych w czasie rzeczywistym w biznesie",
    "text": "Zastosowanie analizy danych w czasie rzeczywistym w biznesie\n\nFinanse i bankowoÅ›Ä‡\n\nWykrywanie oszustw â€“ analiza transakcji w czasie rzeczywistym pozwala na wykrycie anomalii wskazujÄ…cych na oszustwa.\nAutomatyczny trading â€“ systemy HFT (High-Frequency Trading) analizujÄ… miliony danych w uÅ‚amkach sekundy.\nDynamiczne oceny kredytowe â€“ natychmiastowa analiza ryzyka kredytowego klienta.\n\n\n\nE-commerce i marketing cyfrowy\n\nPersonalizacja ofert w czasie rzeczywistym â€“ dynamiczne rekomendacje produktÃ³w na podstawie aktualnego zachowania uÅ¼ytkownika.\nDynamiczne ceny â€“ np. Uber, Amazon i hotele stosujÄ… dynamiczne ustalanie cen na podstawie popytu.\nMonitorowanie mediÃ³w spoÅ‚ecznoÅ›ciowych â€“ analiza nastrojÃ³w klientÃ³w i natychmiastowa reakcja na negatywne komentarze.\n\n\n\nTelekomunikacja i IoT\n\nMonitorowanie infrastruktury sieciowej â€“ analiza logÃ³w w czasie rzeczywistym pozwala na wykrywanie awarii przed ich wystÄ…pieniem.\nSmart Cities â€“ analiza ruchu drogowego i natychmiastowa optymalizacja sygnalizacji Å›wietlnej.\nAnalityka IoT â€“ urzÄ…dzenia IoT generujÄ… strumienie danych, ktÃ³re moÅ¼na analizowaÄ‡ w czasie rzeczywistym (np. inteligentne liczniki energii).\n\n\n\nOchrona zdrowia\n\nMonitorowanie pacjentÃ³w â€“ analiza sygnaÅ‚Ã³w z urzÄ…dzeÅ„ medycznych w celu natychmiastowego wykrycia zagroÅ¼enia Å¼ycia.\nAnalityka epidemiologiczna â€“ Å›ledzenie rozprzestrzeniania siÄ™ chorÃ³b na podstawie danych w czasie rzeczywistym.\n\nAnaliza danych w czasie rzeczywistym to kluczowy element nowoczesnych systemÃ³w informatycznych, ktÃ³ry umoÅ¼liwia firmom podejmowanie decyzji szybciej i bardziej precyzyjnie. Jest wykorzystywana w wielu branÅ¼ach â€“ od finansÃ³w, przez e-commerce, aÅ¼ po ochronÄ™ zdrowia i IoT."
  },
  {
    "objectID": "wyklad1.html#rÃ³Å¼nice-miÄ™dzy-batch-processing-near-real-time-analytics-real-time-analytics",
    "href": "wyklad1.html#rÃ³Å¼nice-miÄ™dzy-batch-processing-near-real-time-analytics-real-time-analytics",
    "title": "WykÅ‚ad 1",
    "section": "RÃ³Å¼nice miÄ™dzy Batch Processing, Near Real-Time Analytics, Real-Time Analytics",
    "text": "RÃ³Å¼nice miÄ™dzy Batch Processing, Near Real-Time Analytics, Real-Time Analytics\nIstniejÄ… trzy gÅ‚Ã³wne podejÅ›cia do przetwarzania informacji:\n\nBatch Processing (Przetwarzanie wsadowe)\nNear Real-Time Analytics (Analiza niemal w czasie rzeczywistym)\nReal-Time Analytics (Analiza w czasie rzeczywistym)\n\nKaÅ¼de z nich rÃ³Å¼ni siÄ™ szybkoÅ›ciÄ… przetwarzania, wymaganiami technologicznymi oraz zastosowaniami biznesowymi.\n\nBatch Processing â€“ Przetwarzanie wsadowe\nğŸ“Œ Definicja:\nBatch Processing polega na zbieraniu duÅ¼ych iloÅ›ci danych i ich przetwarzaniu w okreÅ›lonych odstÄ™pach czasu (np. co godzinÄ™, codziennie, co tydzieÅ„).\nğŸ“Œ Cechy:\n\nâœ… Wysoka wydajnoÅ›Ä‡ dla duÅ¼ych zbiorÃ³w danych\nâœ… Przetwarzanie danych po ich zgromadzeniu\nâœ… Nie wymaga natychmiastowej analizy\nâœ… Zwykle taÅ„sze niÅ¼ przetwarzanie w czasie rzeczywistym\nâŒ OpÃ³Åºnienia â€“ wyniki sÄ… dostÄ™pne dopiero po zakoÅ„czeniu przetwarzania\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nGenerowanie raportÃ³w finansowych na koniec dnia/miesiÄ…ca\nAnaliza trendÃ³w sprzedaÅ¼y na podstawie historycznych danych\nTworzenie modeli uczenia maszynowego offline\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nHadoop MapReduce\nApache Spark (w trybie batch)\nGoogle BigQuery\n\nimport pandas as pd  \ndf = pd.read_csv(\"transactions.csv\")  \n\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\ndf['month'] = df['transaction_date'].dt.to_period('M')  # Ekstrakcja miesiÄ…ca\n\n# Agregacja danych - miesiÄ™czne sumy transakcji\nmonthly_sales = df.groupby(['month'])['amount'].sum()\n\n# Zapis wynikÃ³w do pliku (np. raportu)\nmonthly_sales.to_csv(\"monthly_report.csv\")  \n\nprint(\"Raport zapisany!\")\nGdybyÅ› chciaÅ‚ utworzyÄ‡ dane do przykÅ‚adu\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\ndata = {\n    'transaction_id': [f'TX{str(i).zfill(4)}' for i in range(1, 1001)],\n    'amount': np.random.uniform(10, 10000, 1000), \n    'transaction_date': pd.date_range(start=\"2025-01-01\", periods=1000, freq='h'), \n    'merchant': np.random.choice(['Merchant_A', 'Merchant_B', 'Merchant_C', 'Merchant_D'], 1000),\n    'card_type': np.random.choice(['Visa', 'MasterCard', 'AmEx'], 1000)\n}\n\ndf = pd.DataFrame(data)\ncsv_file = 'transactions.csv'\ndf.to_csv(csv_file, index=False)\n\n\nNear Real-Time Analytics â€“ Analiza niemal w czasie rzeczywistym\nğŸ“Œ Definicja:\nNear Real-Time Analytics to analiza danych, ktÃ³ra odbywa siÄ™ z minimalnym opÃ³Åºnieniem (zazwyczaj od kilku sekund do kilku minut). Jest stosowana tam, gdzie peÅ‚na analiza w czasie rzeczywistym nie jest konieczna, ale zbyt duÅ¼e opÃ³Åºnienia mogÄ… wpÅ‚ynÄ…Ä‡ na biznes.\nğŸ“Œ Cechy:\n\nâœ… Przetwarzanie danych w krÃ³tkich odstÄ™pach czasu (kilka sekund â€“ minut)\nâœ… UmoÅ¼liwia szybkie podejmowanie decyzji, ale nie wymaga reakcji w milisekundach\nâœ… Optymalny balans miÄ™dzy kosztami a szybkoÅ›ciÄ…\nâŒ Nie nadaje siÄ™ do systemÃ³w wymagajÄ…cych natychmiastowej reakcji\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nMonitorowanie transakcji bankowych i wykrywanie oszustw (np. analiza w ciÄ…gu 30 sekund)\nDynamiczne dostosowywanie reklam online na podstawie zachowaÅ„ uÅ¼ytkownikÃ³w\nAnaliza logÃ³w serwerÃ³w i sieci w celu wykrycia anomalii\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nApache Kafka + Spark Streaming\nElasticsearch + Kibana (np. analiza logÃ³w IT)\nAmazon Kinesis\n\nPrzykÅ‚ad producenta danych realizujÄ…cego tranzakcje wysyÅ‚ane do systemu Apache Kafka.\nfrom kafka import KafkaProducer\nimport json\nimport random\nimport time\nfrom datetime import datetime\n\n# Ustawienia dla producenta\nbootstrap_servers = 'localhost:9092'\ntopic = 'transactions' \n\n# Funkcja generujÄ…ca przykÅ‚adowe dane transakcji\ndef generate_transaction():\n    transaction = {\n        'transaction_id': f'TX{random.randint(1000, 9999)}',\n        'amount': round(random.uniform(10, 10000), 2),  # Kwota miÄ™dzy 10 a 10 000\n        'transaction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'merchant': random.choice(['Merchant_A', 'Merchant_B', 'Merchant_C', 'Merchant_D']),\n        'card_type': random.choice(['Visa', 'MasterCard', 'AmEx']),\n    }\n    return transaction\n\nproducer = KafkaProducer(\n    bootstrap_servers=bootstrap_servers,\n    value_serializer=lambda v: json.dumps(v).encode('utf-8') \n)\n\n\nfor _ in range(1000):  \n    transaction = generate_transaction()\n    producer.send(topic, value=transaction) \n    print(f\"Sent: {transaction}\")\n    time.sleep(1) \n\n# ZakoÅ„czenie dziaÅ‚ania producenta\nproducer.flush()\nproducer.close()\nPrzykÅ‚ad consumenta - programu sparawdzajÄ…cego zbyt duÅ¼e transakcje\nfrom kafka import KafkaConsumer\nimport json  \n\n# Konsumer do pobierania danych z Kafka\nconsumer = KafkaConsumer(\n    'transactions',\n    bootstrap_servers='localhost:9092',\n    auto_offset_reset='earliest',\n    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n)\n\n# Pobieranie transakcji w niemal real-time i analiza\nfor message in consumer:\n    transaction = message.value\n    if transaction[\"amount\"] &gt; 8000:\n        print(f\"ğŸš¨ Wykryto duÅ¼Ä… transakcjÄ™: {transaction}\")\nPrzykÅ‚adowy zestaw danych\n{\n    \"transaction_id\": \"TX1234\",\n    \"amount\": 523.47,\n    \"transaction_date\": \"2025-02-11 08:10:45\",\n    \"merchant\": \"Merchant_A\",\n    \"card_type\": \"Visa\"\n}\n\n\nReal-Time Analytics â€“ Analiza w czasie rzeczywistym\nğŸ“Œ Definicja:\nReal-Time Analytics to natychmiastowa analiza danych i podejmowanie decyzji w uÅ‚amku sekundy (milisekundy do jednej sekundy). Wykorzystywana w systemach wymagajÄ…cych reakcji w czasie rzeczywistym, np. w transakcjach gieÅ‚dowych, systemach IoT czy cyberbezpieczeÅ„stwie.\nğŸ“Œ Cechy:\n\nâœ… Bardzo niskie opÃ³Åºnienie (milliseconds-seconds)\nâœ… UmoÅ¼liwia natychmiastowÄ… reakcjÄ™ systemu\nâœ… Wymaga wysokiej mocy obliczeniowej i skalowalnej architektury\nâŒ DroÅ¼sze i bardziej zÅ‚oÅ¼one technologicznie niÅ¼ batch processing\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nHigh-Frequency Trading (HFT) â€“ analiza i podejmowanie decyzji w transakcjach gieÅ‚dowych w milisekundach\nAutonomiczne samochody â€“ analiza strumieni danych z kamer i sensorÃ³w w czasie rzeczywistym\nCyberbezpieczeÅ„stwo â€“ detekcja atakÃ³w w sieciach komputerowych w uÅ‚amku sekundy\nAnalityka IoT â€“ np. natychmiastowa detekcja anomalii w danych z czujnikÃ³w przemysÅ‚owych\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nApache Flink\nApache Storm\nGoogle Dataflow\n\nğŸ” PorÃ³wnanie:\n\n\n\n\n\n\n\n\n\nCecha\nBatch Processing\nNear Real-Time Analytics\nReal-Time Analytics\n\n\n\n\nOpÃ³Åºnienie\nMinuty â€“ godziny â€“ dni\nSekundy â€“ minuty\nMilisekundy â€“ sekundy\n\n\nTyp przetwarzania\nWsadowe (offline)\nStrumieniowe (ale nie w peÅ‚ni natychmiastowe)\nStrumieniowe (prawdziwy real-time)\n\n\nKoszt infrastruktury\nğŸ“‰ Niski\nğŸ“ˆ Åšredni\nğŸ“ˆğŸ“ˆ Wysoki\n\n\nZÅ‚oÅ¼onoÅ›Ä‡ implementacji\nğŸ“‰ Prosta\nğŸ“ˆ Åšrednia\nğŸ“ˆğŸ“ˆ Trudna\n\n\nPrzykÅ‚ady zastosowaÅ„\nRaporty, ML offline, analizy historyczne\nMonitorowanie transakcji, dynamiczne reklamy\nHFT, IoT, detekcja oszustw w czasie rzeczywistym\n\n\n\nğŸ“Œ Kiedy stosowaÄ‡ Batch Processing?\n\nâœ… Gdy nie wymagasz natychmiastowej analizy\nâœ… Gdy masz duÅ¼e iloÅ›ci danych, ale przetwarzane sÄ… one okresowo\nâœ… Gdy chcesz obniÅ¼yÄ‡ koszty\n\nğŸ“Œ Kiedy stosowaÄ‡ Near Real-Time Analytics?\n\nâœ… Gdy wymagasz analizy w krÃ³tkim czasie (sekundy â€“ minuty)\nâœ… Gdy potrzebujesz bardziej aktualnych danych, ale nie w peÅ‚nym real-time\nâœ… Gdy szukasz kompromisu miÄ™dzy wydajnoÅ›ciÄ… a kosztami\n\nğŸ“Œ Kiedy stosowaÄ‡ Real-Time Analytics?\n\nâœ… Gdy kaÅ¼da milisekunda ma znaczenie (np. gieÅ‚da, autonomiczne pojazdy)\nâœ… Gdy chcesz wykrywaÄ‡ oszustwa, anomalie lub incydenty natychmiast\nâœ… Gdy system musi natychmiast reagowaÄ‡ na zdarzenia\n\nReal-time analytics nie zawsze jest konieczne â€“ w wielu przypadkach near real-time jest wystarczajÄ…ce i bardziej opÅ‚acalne. Kluczowe jest zrozumienie wymagaÅ„ biznesowych przed wyborem odpowiedniego rozwiÄ…zania."
  },
  {
    "objectID": "wyklad1.html#dlaczego-real-time-analytics-jest-waÅ¼ne",
    "href": "wyklad1.html#dlaczego-real-time-analytics-jest-waÅ¼ne",
    "title": "WykÅ‚ad 1",
    "section": "Dlaczego Real-Time Analytics jest waÅ¼ne?",
    "text": "Dlaczego Real-Time Analytics jest waÅ¼ne?\nReal-time analytics (analiza danych w czasie rzeczywistym) staje siÄ™ coraz bardziej istotna w wielu branÅ¼ach, poniewaÅ¼ umoÅ¼liwia organizacjom podejmowanie natychmiastowych decyzji na podstawie aktualnych danych. Oto kilka kluczowych powodÃ³w, dla ktÃ³rych real-time analytics jest waÅ¼ne:\n\nSzybkie podejmowanie decyzji\nReal-time analytics pozwala firmom reagowaÄ‡ na zmiany i wydarzenia w czasie rzeczywistym. DziÄ™ki temu moÅ¼na podejmowaÄ‡ decyzje szybciej, co jest kluczowe w dynamicznych Å›rodowiskach, takich jak:\n\nMarketing: Reklamy mogÄ… byÄ‡ dostosowane do zachowaÅ„ uÅ¼ytkownikÃ³w w czasie rzeczywistym (np. personalizacja treÅ›ci reklamowych).\nFinanse: Wykrywanie oszustw w czasie rzeczywistym, gdzie kaÅ¼da minuta moÅ¼e oznaczaÄ‡ rÃ³Å¼nicÄ™ w prewencji strat finansowych.\n\n\n\nMonitorowanie w czasie rzeczywistym\nFirmy mogÄ… monitorowaÄ‡ kluczowe wskaÅºniki operacyjne na bieÅ¼Ä…co. PrzykÅ‚ady:\n\nIoT (Internet of Things): Monitorowanie stanu maszyn i urzÄ…dzeÅ„ w fabrykach, aby natychmiast wykrywaÄ‡ awarie i zapobiegaÄ‡ przestojom.\nHealthtech: Åšledzenie parametrÃ³w Å¼yciowych pacjentÃ³w i wykrywanie anomalii, co moÅ¼e ratowaÄ‡ Å¼ycie.\n\n\n\nZwiÄ™kszenie efektywnoÅ›ci operacyjnej\nReal-time analytics umoÅ¼liwia natychmiastowe wykrywanie i eliminowanie problemÃ³w operacyjnych, zanim stanÄ… siÄ™ powaÅ¼niejsze. PrzykÅ‚ady:\n\nLogistyka: Åšledzenie przesyÅ‚ek i monitorowanie statusu transportu w czasie rzeczywistym, co poprawia efektywnoÅ›Ä‡ i zmniejsza opÃ³Åºnienia.\nRetail: Monitorowanie poziomu zapasÃ³w na bieÅ¼Ä…co i dostosowywanie zamÃ³wieÅ„ do aktualnych potrzeb.\n\n\n\nKonkurencyjnoÅ›Ä‡\nOrganizacje, ktÃ³re wykorzystujÄ… analitykÄ™ w czasie rzeczywistym, majÄ… przewagÄ™ nad konkurencjÄ…, poniewaÅ¼ mogÄ… szybciej reagowaÄ‡ na zmiany na rynku, nowe potrzeby klientÃ³w i sytuacje kryzysowe. DziÄ™ki natychmiastowym informacjom:\n\nMoÅ¼na podejmowaÄ‡ decyzje z wyprzedzeniem przed konkurentami.\nUtrzymywaÄ‡ lepsze relacje z klientami, reagujÄ…c na ich potrzeby w czasie rzeczywistym (np. dostosowywanie oferty).\n\n\n\nLepsze doÅ›wiadczenia uÅ¼ytkownikÃ³w (Customer Experience)\nAnaliza danych w czasie rzeczywistym pozwala na dostosowywanie interakcji z uÅ¼ytkownikami w trakcie ich trwania. PrzykÅ‚ady:\n\nE-commerce: Analiza koszyka zakupowego uÅ¼ytkownika w czasie rzeczywistym, aby np. zaoferowaÄ‡ rabat lub przypomnieÄ‡ o porzuconych produktach.\nStreaming: Optymalizacja jakoÅ›ci usÅ‚ugi wideo/streamingowej w zaleÅ¼noÅ›ci od dostÄ™pnej przepustowoÅ›ci Å‚Ä…cza.\n\n\n\nWykrywanie i reagowanie na anomalie\nW dzisiejszym Å›wiecie peÅ‚nym danych, wykrywanie anomalii w czasie rzeczywistym jest kluczowe dla bezpieczeÅ„stwa. PrzykÅ‚ady:\n\nCyberbezpieczeÅ„stwo: Real-time analytics umoÅ¼liwia wykrywanie podejrzanych dziaÅ‚aÅ„ w sieci i zapobieganie atakom w czasie rzeczywistym (np. ataki DDoS, nieautoryzowane logowanie).\nWykrywanie oszustw: Natychmiastowa identyfikacja podejrzanych transakcji w systemach bankowych i kartach kredytowych.\n\n\n\nOptymalizacja kosztÃ³w\nDziÄ™ki analizie w czasie rzeczywistym moÅ¼na optymalizowaÄ‡ zasoby i zmniejszaÄ‡ koszty. Na przykÅ‚ad:\n\nZarzÄ…dzanie energiÄ…: Analiza zuÅ¼ycia energii w czasie rzeczywistym, umoÅ¼liwiajÄ…ca optymalizacjÄ™ wydatkÃ³w na energiÄ™ w firmach.\nOptymalizacja Å‚aÅ„cucha dostaw: DziÄ™ki bieÅ¼Ä…cemu Å›ledzeniu zapasÃ³w i dostaw moÅ¼na lepiej zarzÄ…dzaÄ‡ kosztami magazynowania i transportu.\n\n\n\nZdolnoÅ›Ä‡ do przewidywania i zapobiegania\nAnaliza w czasie rzeczywistym wspiera procesy predykcyjne, ktÃ³re mogÄ… przewidywaÄ‡ przyszÅ‚e zachowania lub problemy, a takÅ¼e je eliminowaÄ‡ zanim siÄ™ pojawiÄ…. Na przykÅ‚ad:\n\nUtrzymanie predykcyjne w produkcji: Wykorzystanie analizy w czasie rzeczywistym w poÅ‚Ä…czeniu z modelami predykcyjnymi pozwala przewidywaÄ‡ awarie maszyn.\nPrognozy popytu: W czasie rzeczywistym moÅ¼na dostosowywaÄ‡ produkcjÄ™ lub zapasy na podstawie bieÅ¼Ä…cych trendÃ³w.\n\nReal-time analytics to nie tylko analiza danych â€“ to kluczowy element strategii firm w Å›wiecie, ktÃ³ry wymaga szybkich reakcji, elastycznoÅ›ci i dostosowywania siÄ™ do zmieniajÄ…cego siÄ™ otoczenia. Firmy, ktÃ³re wdraÅ¼ajÄ… te technologie, mogÄ… znaczÄ…co poprawiÄ‡ swoje wyniki finansowe, obsÅ‚ugÄ™ klienta, wydajnoÅ›Ä‡ operacyjnÄ…, a takÅ¼e przewagÄ™ konkurencyjnÄ…."
  },
  {
    "objectID": "wyklad1.html#wyzwania-i-problemy-analizy-danych-w-czasie-rzeczywistym",
    "href": "wyklad1.html#wyzwania-i-problemy-analizy-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 1",
    "section": "Wyzwania i problemy analizy danych w czasie rzeczywistym",
    "text": "Wyzwania i problemy analizy danych w czasie rzeczywistym\nAnaliza danych w czasie rzeczywistym wiÄ…Å¼e siÄ™ z wieloma wyzwaniami i trudnoÅ›ciami, ktÃ³re trzeba rozwiÄ…zaÄ‡, aby systemy real-time dziaÅ‚aÅ‚y efektywnie i niezawodnie. Pomimo ogromnego potencjaÅ‚u, jaki daje moÅ¼liwoÅ›Ä‡ natychmiastowego przetwarzania danych, realizacja tych procesÃ³w w praktyce wiÄ…Å¼e siÄ™ z licznymi problemami technologicznymi, organizacyjnymi i dotyczÄ…cymi zarzÄ…dzania danymi.\nPoniÅ¼ej przedstawiamy najwaÅ¼niejsze wyzwania oraz moÅ¼liwe rozwiÄ…zania, ktÃ³re naleÅ¼y uwzglÄ™dniÄ‡ podczas implementacji systemÃ³w analizy danych w czasie rzeczywistym.\n\nSkalowalnoÅ›Ä‡ systemÃ³w\n\nWyzwanie:\nSkalowanie systemu analitycznego w czasie rzeczywistym jest jednym z najtrudniejszych zadaÅ„. W miarÄ™ jak iloÅ›Ä‡ generowanych danych roÅ›nie, systemy muszÄ… byÄ‡ w stanie obsÅ‚ugiwaÄ‡ wiÄ™ksze obciÄ…Å¼enie bez opÃ³Åºnienia w przetwarzaniu.\nZwiÄ™kszona iloÅ›Ä‡ danych: W systemach real-time, jak np. monitorowanie danych IoT czy transakcje w systemach finansowych, iloÅ›Ä‡ generowanych danych moÅ¼e byÄ‡ olbrzymia. Potrzebna jest elastycznoÅ›Ä‡: System musi automatycznie dostosowywaÄ‡ zasoby w zaleÅ¼noÅ›ci od obciÄ…Å¼enia.\n\n\nRozwiÄ…zanie:\nWykorzystanie skalowalnych systemÃ³w chmurowych, ktÃ³re pozwalajÄ… na dynamiczne zwiÄ™kszanie zasobÃ³w obliczeniowych (np. AWS, Azure, Google Cloud). Kubernetes do zarzÄ…dzania kontenerami i automatycznego skalowania mikroserwisÃ³w. Technologie strumieniowe (Apache Kafka, Apache Flink) umoÅ¼liwiajÄ…ce przetwarzanie danych w sposÃ³b wydajny i rozproszony.\n\n\n\nOpÃ³Åºnienia (Latency)\n\nWyzwanie:\nW systemach analizy danych w czasie rzeczywistym, kaÅ¼de opÃ³Åºnienie w przetwarzaniu danych moÅ¼e mieÄ‡ powaÅ¼ne konsekwencje. Dotyczy to zwÅ‚aszcza obszarÃ³w takich jak:\nWykrywanie oszustw: W przypadku systemÃ³w pÅ‚atnoÅ›ci online, opÃ³Åºnienie w analizie transakcji moÅ¼e oznaczaÄ‡ przegapienie nieautoryzowanej transakcji. Monitorowanie zdrowia pacjentÃ³w: OpÃ³Åºnienia mogÄ… wpÅ‚ynÄ…Ä‡ na skutecznoÅ›Ä‡ reakcji w sytuacjach kryzysowych.\n\n\nRozwiÄ…zanie:\nUÅ¼ywanie algorytmÃ³w optymalizujÄ…cych czas przetwarzania, np. stream processing z wykorzystaniem systemÃ³w takich jak Apache Kafka lub Apache Flink. Edge computing: Przesuwanie przetwarzania danych bliÅ¼ej ÅºrÃ³dÅ‚a (np. urzÄ…dzenia IoT), aby zmniejszyÄ‡ opÃ³Åºnienia w transmisji danych do chmury.\n\n\n\nJakoÅ›Ä‡ danych i zarzÄ…dzanie danymi\n\nWyzwanie:\nW systemach real-time musimy nie tylko analizowaÄ‡ dane w czasie rzeczywistym, ale takÅ¼e zapewniÄ‡ ich wysokÄ… jakoÅ›Ä‡. W przeciwnym razie analizy mogÄ… prowadziÄ‡ do bÅ‚Ä™dnych wnioskÃ³w lub opÃ³ÅºnieÅ„ w reagowaniu na nieprawidÅ‚owe dane.\nZanieczyszczone dane: W systemach real-time dane czÄ™sto sÄ… niepeÅ‚ne, brudne, bÅ‚Ä™dne lub nieuporzÄ…dkowane. Zmiana charakterystyki danych: Dane mogÄ… zmieniaÄ‡ siÄ™ w czasie, co moÅ¼e utrudniaÄ‡ ich przetwarzanie i analizÄ™. #### RozwiÄ…zanie:\nData cleansing i data validation na wstÄ™pnym etapie procesu. Automatyczne systemy monitorowania jakoÅ›ci danych w celu wykrywania bÅ‚Ä™dÃ³w w czasie rzeczywistym. ZarzÄ…dzanie danymi w strumieniu: NarzÄ™dzia takie jak Apache Kafka pozwalajÄ… na filtrowanie i oczyszczanie danych w locie.\n\n\n\nZÅ‚oÅ¼onoÅ›Ä‡ integracji systemÃ³w\n\nWyzwanie:\nSystemy analizy danych w czasie rzeczywistym czÄ™sto muszÄ… wspÃ³Å‚pracowaÄ‡ z istniejÄ…cymi systemami IT i ÅºrÃ³dÅ‚ami danych (np. bazami danych, czujnikami IoT, aplikacjami). Integracja tych systemÃ³w, zwÅ‚aszcza w rozproszonej architekturze, moÅ¼e byÄ‡ skomplikowana.\n\n\nRozwiÄ…zanie:\nUÅ¼ywanie API do Å‚atwiejszej integracji z zewnÄ™trznymi systemami. Mikroserwisy i konteneryzacja z pomocÄ… narzÄ™dzi takich jak Docker i Kubernetes. Przetwarzanie w chmurze, ktÃ³re umoÅ¼liwia Å‚atwÄ… integracjÄ™ rÃ³Å¼nych ÅºrÃ³deÅ‚ danych oraz zapewnia elastycznoÅ›Ä‡ w dostosowywaniu systemÃ³w do rosnÄ…cych potrzeb.\n\n\n\nBezpieczeÅ„stwo i prywatnoÅ›Ä‡\n\nWyzwanie:\nPrzetwarzanie danych w czasie rzeczywistym wiÄ…Å¼e siÄ™ z ogromnÄ… iloÅ›ciÄ… wraÅ¼liwych informacji, szczegÃ³lnie w branÅ¼ach takich jak finanse, zdrowie czy e-commerce. Zapewnienie, Å¼e dane sÄ… odpowiednio chronione przed nieautoryzowanym dostÄ™pem, jest kluczowe.\nOchrona danych w czasie transmisji: MuszÄ… byÄ‡ szyfrowane zarÃ³wno podczas przesyÅ‚ania, jak i przechowywania. Zabezpieczenia przed atakami: Przetwarzanie danych w czasie rzeczywistym moÅ¼e byÄ‡ celem atakÃ³w, takich jak DDoS czy SQL injection.\n\n\nRozwiÄ…zanie:\nSzyfrowanie danych zarÃ³wno w spoczynku, jak i podczas przesyÅ‚ania (np. TLS). Autentykacja i autoryzacja z wykorzystaniem nowoczesnych technologii bezpieczeÅ„stwa. ZgodnoÅ›Ä‡ z regulacjami prawnymi, np. RODO w Unii Europejskiej czy GDPR w przypadku danych osobowych.\n\n\n\nZarzÄ…dzanie bÅ‚Ä™dami i awariami\n\nWyzwanie:\nBÅ‚Ä™dy i awarie w systemach real-time mogÄ… prowadziÄ‡ do powaÅ¼nych konsekwencji, w tym utraty danych, opÃ³ÅºnieÅ„ w analizach czy nawet usuniÄ™cia usÅ‚ug. W systemach rozproszonych trudno jest osiÄ…gnÄ…Ä‡ peÅ‚nÄ… niezawodnoÅ›Ä‡.\n\n\nRozwiÄ…zanie:\nRedundancja: Tworzenie kopii zapasowych systemÃ³w i danych. Systemy monitorowania i alertowania (np. Prometheus, Grafana), ktÃ³re pozwalajÄ… na szybkie wykrycie i naprawienie problemÃ³w. ZarzÄ…dzanie stanem: DziÄ™ki uÅ¼yciu narzÄ™dzi jak Apache Kafka, moÅ¼na ponownie przetwarzaÄ‡ dane, jeÅ›li wystÄ…piÅ‚ bÅ‚Ä…d w transmisji.\n\n\n\nKoszty zwiÄ…zane z infrastrukturÄ…\n\nWyzwanie:\nPrzetwarzanie danych w czasie rzeczywistym wymaga odpowiedniej infrastruktury, ktÃ³ra zapewni odpowiedniÄ… moc obliczeniowÄ… i pamiÄ™Ä‡. To moÅ¼e wiÄ…zaÄ‡ siÄ™ z duÅ¼ymi kosztami, szczegÃ³lnie gdy dane muszÄ… byÄ‡ przechowywane i przetwarzane w czasie rzeczywistym na duÅ¼Ä… skalÄ™.\n\n\nRozwiÄ…zanie:\nChmura obliczeniowa: MoÅ¼liwoÅ›Ä‡ elastycznego skalowania zasobÃ³w w chmurze. Serverless computing: Technologie takie jak AWS Lambda pozwalajÄ… na uruchamianie procesÃ³w bez potrzeby utrzymywania staÅ‚ej infrastruktury.\nChociaÅ¼ analiza danych w czasie rzeczywistym oferuje ogromne korzyÅ›ci, wiÄ…Å¼e siÄ™ takÅ¼e z wieloma wyzwaniami. WÅ‚aÅ›ciwa architektura, narzÄ™dzia i technologie, takie jak Apache Kafka, Flink, Spark czy Kubernetes, mogÄ… pomÃ³c w przezwyciÄ™Å¼eniu wielu z tych trudnoÅ›ci. Warto rÃ³wnieÅ¼ pamiÄ™taÄ‡ o koniecznoÅ›ci zapewnienia wysokiej jakoÅ›ci danych, ich bezpieczeÅ„stwa, a takÅ¼e elastycznoÅ›ci i skalowalnoÅ›ci systemÃ³w, ktÃ³re bÄ™dÄ… w stanie sprostaÄ‡ rosnÄ…cym wymaganiom."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-D\nSemestr: 2024/2025 Uczelnia: SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nPodstawowe informacje o kursie znajdziesz w sylabusie.\nPolecane materiaÅ‚y znajdziesz na liÅ›cie ksiÄ…Å¼ek.\nMateriaÅ‚y z wykÅ‚adu i laboratoriÃ³w nie sÄ… wspierane przez Google. ObecnoÅ›Ä‡ na wykÅ‚adach i Ä‡wiczeniach nie zmniejszy Twoich 5 dolarÃ³w."
  },
  {
    "objectID": "index.html#analiza-danych-w-czasie-rzeczywistym",
    "href": "index.html#analiza-danych-w-czasie-rzeczywistym",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-D\nSemestr: 2024/2025 Uczelnia: SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nPodstawowe informacje o kursie znajdziesz w sylabusie.\nPolecane materiaÅ‚y znajdziesz na liÅ›cie ksiÄ…Å¼ek.\nMateriaÅ‚y z wykÅ‚adu i laboratoriÃ³w nie sÄ… wspierane przez Google. ObecnoÅ›Ä‡ na wykÅ‚adach i Ä‡wiczeniach nie zmniejszy Twoich 5 dolarÃ³w."
  },
  {
    "objectID": "index.html#kalendarz",
    "href": "index.html#kalendarz",
    "title": "Informacje ogÃ³lne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykÅ‚ad\nWykÅ‚ad jest realizowany w trybie stacjonarnym. Jest on NIEOBOWIÄ„ZKOWY i odbywa siÄ™ w Auli VI bud G\n\n\n18-02-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 1\n\n25-02-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 2\n04-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 3\n11-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 4\n18-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 5\n\nWykÅ‚ad 5 koÅ„czy siÄ™ TESTEM: 20 pytaÅ„ - 30 minut. Test przeprowadzany jest za poÅ›rednictwem MS Teams.\n\n\nLaboratoria\n\nLab1\n24-03-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n25-03-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab2\n31-03-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n01-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab3\n07-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n08-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab4\n14-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n15-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab5\n28-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n29-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab6\n05-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n06-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab7\n12-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n13-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab8\n19-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n20-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab9\n26-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n27-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab10\n02-06-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n03-06-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\n\nZaliczenie i Egzamin\nWykÅ‚ady zakoÅ„czÄ… siÄ™ testem (podczas ostatnich zajÄ™Ä‡).\nAby zaliczyÄ‡ test, naleÅ¼y zdobyÄ‡ wiÄ™cej niÅ¼ 13 punktÃ³w â€“ jest to warunek konieczny do uczestnictwa w Ä‡wiczeniach.\nLaboratoria\nPodczas laboratoriÃ³w bÄ™dÄ… zadawane prace domowe, ktÃ³re naleÅ¼y przesyÅ‚aÄ‡ za poÅ›rednictwem MS Teams. KaÅ¼dy brak pracy domowej obniÅ¼a koÅ„cowÄ… ocenÄ™ o 0,5 stopnia.\n\nProjekt\nProjekty naleÅ¼y realizowaÄ‡ w grupach maksymalnie 5-osobowych.\nWymagania projektu\n\nProjekt powinien rozwiÄ…zywaÄ‡ realny problem biznesowy, ktÃ³ry moÅ¼na opracowaÄ‡ przy uÅ¼yciu danych przetwarzanych w trybie online. (Nie wyklucza to uÅ¼ycia przetwarzania wsadowego, np. do generowania modelu).\nDane powinny byÄ‡ przesyÅ‚ane do Apache Kafka, skÄ…d bÄ™dÄ… poddawane dalszemu przetwarzaniu i analizie.\nMoÅ¼na uÅ¼ywaÄ‡ dowolnego jÄ™zyka programowania w kaÅ¼dym komponencie projektu.\nMoÅ¼na wykorzystaÄ‡ narzÄ™dzia BI.\nÅ¹rÃ³dÅ‚em danych moÅ¼e byÄ‡ dowolne API, sztucznie generowane dane, IoT itp."
  },
  {
    "objectID": "index.html#technologie",
    "href": "index.html#technologie",
    "title": "Informacje ogÃ³lne",
    "section": "Technologie",
    "text": "Technologie\nUczestniczÄ…c w zajÄ™ciach musisz opanowaÄ‡ i przynajmniej w podstawowym zakresie posÅ‚ugiwaÄ‡ siÄ™ nastÄ™pujÄ…cymi technologiami informatycznymi:\n\nGIT\nPython, Jupyter notebook, Jupyter lab, Colab\nDocker\nApache Spark, Apache Kafka\nDatabricks Community edition Web page."
  },
  {
    "objectID": "plan_wyklady.html",
    "href": "plan_wyklady.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "ğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej? 2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce. 3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym. 4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w. 5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych. ğŸ›  Laboratoria (praktyka + implementacja w Pythonie)\nğŸ”¹ Lab 1: Struktury danych w Pythonie â€“ Pandas, SQL (PostgreSQL, SQLite). ğŸ”¹ Lab 2: Dane grafowe w analizie relacji â€“ NetworkX i algorytmy grafowe. ğŸ”¹ Lab 3: Analiza tekstÃ³w i NLP â€“ przetwarzanie danych tekstowych (spaCy, TF-IDF). ğŸ”¹ Lab 4: Strumieniowanie danych w Apache Kafka â€“ pierwsza aplikacja Python + Kafka. ğŸ”¹ Lab 5: Uczenie maszynowe na strumieniu â€“ klasyfikacja w czasie rzeczywistym (SGDClassifier). ğŸ”¹ Lab 6: Przygotowanie API w FastAPI â€“ serwowanie modelu ML. ğŸ”¹ Lab 7: Zastosowanie modelu ML w reguÅ‚ach decyzyjnych â€“ integracja API z logikÄ… biznesowÄ…. ğŸ”¹ Lab 8: Przetwarzanie obrazÃ³w w czasie rzeczywistym â€“ OpenCV + klasyfikacja wideo. ğŸ”¹ Lab 9: Wykrywanie oszustw w transakcjach finansowych â€“ online learning na Kafka. ğŸ”¹ Lab 10: Projekt koÅ„cowy â€“ budowa mikroserwisu do analizy danych w czasie rzeczywistym."
  },
  {
    "objectID": "plan_wyklady.html#plan-wykÅ‚adu",
    "href": "plan_wyklady.html#plan-wykÅ‚adu",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "ğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej? 2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce. 3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym. 4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w. 5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych. ğŸ›  Laboratoria (praktyka + implementacja w Pythonie)\nğŸ”¹ Lab 1: Struktury danych w Pythonie â€“ Pandas, SQL (PostgreSQL, SQLite). ğŸ”¹ Lab 2: Dane grafowe w analizie relacji â€“ NetworkX i algorytmy grafowe. ğŸ”¹ Lab 3: Analiza tekstÃ³w i NLP â€“ przetwarzanie danych tekstowych (spaCy, TF-IDF). ğŸ”¹ Lab 4: Strumieniowanie danych w Apache Kafka â€“ pierwsza aplikacja Python + Kafka. ğŸ”¹ Lab 5: Uczenie maszynowe na strumieniu â€“ klasyfikacja w czasie rzeczywistym (SGDClassifier). ğŸ”¹ Lab 6: Przygotowanie API w FastAPI â€“ serwowanie modelu ML. ğŸ”¹ Lab 7: Zastosowanie modelu ML w reguÅ‚ach decyzyjnych â€“ integracja API z logikÄ… biznesowÄ…. ğŸ”¹ Lab 8: Przetwarzanie obrazÃ³w w czasie rzeczywistym â€“ OpenCV + klasyfikacja wideo. ğŸ”¹ Lab 9: Wykrywanie oszustw w transakcjach finansowych â€“ online learning na Kafka. ğŸ”¹ Lab 10: Projekt koÅ„cowy â€“ budowa mikroserwisu do analizy danych w czasie rzeczywistym."
  },
  {
    "objectID": "plan_wyklady.html#moje",
    "href": "plan_wyklady.html#moje",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "Moje",
    "text": "Moje\n\nwprowadzenie\nBatch processing\n\n\ntypy danych\nBig data\nETL\nMAP Reduce\nSparkowe przetwarzanie klastrowe\nBazy SQL - OLTP, OLAP\n\n\nAPI online\n\n\nwystawienie serwisu LLM\nbatching\n\n\nNear Real-Time i Real Time\n\n\nStrumienie danych, definicje, biznes,\nLambda/Kappa\nPub Sub, Kafka"
  }
]