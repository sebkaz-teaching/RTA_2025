[
  {
    "objectID": "plan.html",
    "href": "plan.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "Lecture 1: Introduction to Real-Time Data Analysis\nLecture 2: Data Ingestion and Processing for Real-Time Analysis\nLecture 3: Real-Time Data Analysis Techniques\nLecture 4: Real-Time Data Visualization and Communication\nLecture 5: Case Studies and Implementation\nThroughout the lectures, Iâ€™ll incorporate interactive elements, such as:\nThis comprehensive lecture plan will provide students with a solid foundation in real-time data analysis, covering the technical aspects of data ingestion, processing, and visualization, as well as practical applications and best practices."
  },
  {
    "objectID": "plan.html#nowy-program-przedmiotu",
    "href": "plan.html#nowy-program-przedmiotu",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "Nowy program przedmiotu",
    "text": "Nowy program przedmiotu\n\nBatch vs.Â Real-Time vs.Â Streaming Analytics â€“ RÃ³Å¼nice miÄ™dzy trybami przetwarzania danych, kluczowe koncepcje i zastosowania.\nModele przetwarzania danych w Big Data â€“ Od plikÃ³w pÅ‚askich do Data Lake, wady i zalety podejÅ›cia real-time. Mity i fakty o przetwarzaniu w czasie rzeczywistym.\nArchitektura IT dla przetwarzania w czasie rzeczywistym â€“ OmÃ³wienie architektur Lambda i Kappa w kontekÅ›cie strumieniowego przetwarzania danych.\nSystemy przetwarzania danych w czasie rzeczywistym â€“ PrzeglÄ…d technologii: Apache Kafka, Apache Spark Streaming, Apache Flink i ich zastosowania w Pythonie.\nPodstawy uczenia maszynowego w czasie rzeczywistym â€“ PorÃ³wnanie offline learning vs.Â online learning, problemy zwiÄ…zane z przyrostowym uczeniem maszynowym.\n\nğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej?\n2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce.\n3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym.\n4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w.\n5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych."
  },
  {
    "objectID": "indexS.html",
    "href": "indexS.html",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-S\nSemestr zimowy 2024/2025, SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nSzczegÃ³Å‚owy opis znajdziesz w sylabusie. Znajdziesz w nim opis wszystkich wykÅ‚adÃ³w i Ä‡wiczeÅ„ oraz proponowanÄ… literaturÄ™.\nInne ksiÄ…Å¼ki zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki"
  },
  {
    "objectID": "indexS.html#analiza-danych-w-czasie-rzeczywistym",
    "href": "indexS.html#analiza-danych-w-czasie-rzeczywistym",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-S\nSemestr zimowy 2024/2025, SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nSzczegÃ³Å‚owy opis znajdziesz w sylabusie. Znajdziesz w nim opis wszystkich wykÅ‚adÃ³w i Ä‡wiczeÅ„ oraz proponowanÄ… literaturÄ™.\nInne ksiÄ…Å¼ki zamieszczone zostaÅ‚y w zakÅ‚adce ksiÄ…Å¼ki"
  },
  {
    "objectID": "indexS.html#kalendarz",
    "href": "indexS.html#kalendarz",
    "title": "Informacje ogÃ³lne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykÅ‚ad\nWykÅ‚ad jest realizowany w trybie stacjonarnym. Jest on NIEOBOWIÄ„ZKOWY i odbywa siÄ™ w Auli III bud G\n\n22-02-2025 (sobota) 08:00-09:30 - WykÅ‚ad 1\n08-03-2025 (sobota) 08:00-09:30 - WykÅ‚ad 2\n\n\n\nLaboratoria\n\nLab1\n22-03-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n23-03-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab2\n05-04-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n06-04-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab3\n26-04-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n27-04-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab4\n17-05-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n18-05-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\nLab5\n31-05-2025 (sobota) 08:00-13:20 - G-210 grupy 11, 17, 18\n01-06-2025 (niedziela) 13:30-17:00 - G-116 grupy 15, 16\n\n\n\nZaliczenie i Egzamin\nWykÅ‚ady zakoÅ„czÄ… siÄ™ testem (podczas ostatnich zajÄ™Ä‡) 20 pytaÅ„.\nAby zaliczyÄ‡ test, naleÅ¼y zdobyÄ‡ wiÄ™cej niÅ¼ 13 punktÃ³w â€“ jest to warunek konieczny do uczestnictwa w Ä‡wiczeniach.\nLaboratoria\nPodczas laboratoriÃ³w bÄ™dÄ… zadawane prace domowe, ktÃ³re naleÅ¼y przesyÅ‚aÄ‡ za poÅ›rednictwem MS Teams. KaÅ¼dy brak pracy domowej obniÅ¼a koÅ„cowÄ… ocenÄ™ o 0,5 stopnia.\n\nProjekt\nProjekty naleÅ¼y realizowaÄ‡ w grupach maksymalnie 5-osobowych.\nWymagania projektu\n\nProjekt powinien rozwiÄ…zywaÄ‡ realny problem biznesowy, ktÃ³ry moÅ¼na opracowaÄ‡ przy uÅ¼yciu danych przetwarzanych w trybie online. (Nie wyklucza to uÅ¼ycia przetwarzania wsadowego, np. do generowania modelu).\nDane powinny byÄ‡ przesyÅ‚ane do Apache Kafka, skÄ…d bÄ™dÄ… poddawane dalszemu przetwarzaniu i analizie.\nMoÅ¼na uÅ¼ywaÄ‡ dowolnego jÄ™zyka programowania w kaÅ¼dym komponencie projektu.\nMoÅ¼na wykorzystaÄ‡ narzÄ™dzia BI.\nÅ¹rÃ³dÅ‚em danych moÅ¼e byÄ‡ dowolne API, sztucznie generowane dane, IoT itp."
  },
  {
    "objectID": "indexS.html#technologie",
    "href": "indexS.html#technologie",
    "title": "Informacje ogÃ³lne",
    "section": "Technologie",
    "text": "Technologie\nUczestniczÄ…c w zajÄ™ciach musisz opanowaÄ‡ i przynajmniej w podstawowym zakresie posÅ‚ugiwaÄ‡ siÄ™ nastÄ™pujÄ…cymi technologiami informatycznymi:\n\nGIT\nPython, Jupyter notebook, Jupyter lab, Colab\nDocker\nApache Spark, Apache Kafka\nDatabricks Community edition Web page."
  },
  {
    "objectID": "info.html",
    "href": "info.html",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3.11 -m venv &lt;name of env&gt;\n# dla linux i mac os\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n# dla windows \n# &lt;name of env&gt;\\Scripts\\activate\n(venv)$ \nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#python",
    "href": "info.html#python",
    "title": "NarzÄ™dzia",
    "section": "",
    "text": "W terminalu (Windows CMD) wpisz\npython\nJeÅ›li nie odnaleziono komendy uruchom polecenie:\npython3\nZwrÃ³Ä‡ uwagÄ™, aby Twoja wersja nie byÅ‚a niÅ¼sza niÅ¼ 3.X Aby wyjÅ›Ä‡ z powÅ‚oki pythona uÅ¼yj funkcji exit()\nPython 3.13.2 (main, Feb  4 2025, 14:51:09) [Clang 16.0.0 (clang-1600.0.26.6)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; exit()\n\n\npython3.11 -m venv &lt;name of env&gt;\n# dla linux i mac os\nsource &lt;name of env&gt;/bin/activate\n# . env/bin/activate\n# dla windows \n# &lt;name of env&gt;\\Scripts\\activate\n(venv)$ \nSzybka instalacja podstawowych bibliotek i jupyterlab.\npip install --no-cache --upgrade pip setuptools\n\npip install jupyterlab numpy pandas matplotlib scipy\n# jeÅ›li masz plik requirements.txt z potrzebnymi bibliotekami\npip install -r requirements.txt\n# uruchom \njupyterlab\nW przeglÄ…darce internetowej wpisz: localhost:8888\nPo ponownym uruchomieniu przejdÅº do katalogu w ktÃ³rym utworzyÅ‚eÅ› Å›rodowisko, nastÄ™pnie uruchom Å›rodowisko i jupyterlab.\nsource &lt;name of env&gt;/bin/activate\njupyterlab\n\n\n\nKurs podstaw pythona Tomas Beuzen polecam.\nUtwÃ³rz konto na Kaggle, przejdÅº do zakÅ‚adki Courses i przerÃ³b caÅ‚y moduÅ‚ Pythona. Zawiera on:\n\nwyraÅ¼enia i zmienne\nfunkcje\nwarunki i flow programu\nlisty\npÄ™tle\nstringi i sÅ‚owniki\ndodawanie i uÅ¼ywanie zewnÄ™trznych bibliotek"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "href": "info.html#zacznij-korzystaÄ‡-z-serwisu-github",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z serwisu GitHub",
    "text": "Zacznij korzystaÄ‡ z serwisu GitHub\n\n\n\nTekst na podstawie strony jak korzystaÄ‡ z serwisu github\nPracujÄ…c nad projektem np. praca magisterska, (samodzielnie lub w zespole) czÄ™sto potrzebujesz sprawdziÄ‡ jakie zmiany, kiedy i przez kogo zostaÅ‚y wprowadzone do projektu. W zadaniu tym Å›wietnie sprawdza siÄ™ system kontroli wersji czyli GIT.\nGit moÅ¼esz pobraÄ‡ i zainstalowaÄ‡ jak zwykÅ‚y program na dowolnym komputerze. Jednak najczÄ™Å›ciej (maÅ‚e projekty) korzysta siÄ™ z serwisÃ³w z jakimÅ› systemem git. Jednym z najbardziej rozpoznawanych jest GitHub dziÄ™ki ktÃ³remu moÅ¼esz korzystaÄ‡ z systemu git bez jego instalacji na swoim komputerze.\nW darmowej wersji serwisu GitHub swoje pliki moÅ¼esz przechowywaÄ‡ w publicznych (dostÄ™p majÄ… wszyscy) repozytoriach.\nSkupimy siÄ™ wyÅ‚Ä…cznie na darmowej wersji serwisu GitHub.\ngit --version\n\nStruktura GitHuba\nNa najwyÅ¼szym poziomie znajdujÄ… siÄ™ konta indywidualne np http://github.com/sebkaz, bÄ…dÅº zakÅ‚adane przez organizacje. UÅ¼ytkownicy indywidualni mogÄ… tworzyÄ‡ repozytoria publiczne (public ) bÄ…dÅº prywatne (private).\nJeden plik nie powinien przekraczaÄ‡ 100 MB.\nRepo (skrÃ³t do repozytorium) tworzymy za pomocÄ… Create a new repository. KaÅ¼de repo powinno mieÄ‡ swojÄ… indywidualnÄ… nazwÄ™.\n\n\nBranche\nGÅ‚Ã³wna (tworzona domyÅ›lnie) gaÅ‚Ä…Åº rapozytorium ma nazwÄ™ master.\n\n\nNajwaÅ¼niejsze polecnia do zapamiÄ™tania\n\nÅ›ciÄ…ganie repozytorium z sieci\n\ngit clone https://adres_repo.git\n\nW przypadku githuba moÅ¼esz pobraÄ‡ repozytorium jako plik zip.\n\n\nTworzenie repozytorium dla lokalnego katalogu\n\n# tworzenie nowego katalogu\nmkdir datamining\n# przejÅ›cie do katalogu\ncd datamining\n# inicjalizacja repozytorium w katalogu\ngit init\n# powinien pojawiÄ‡ siÄ™ ukryty katalog .git\n# dodajmy plik\necho \"Info \" &gt;&gt; README.md\n\nPoÅ‚Ä…cz lokalne repozytorium z kontem na githubie\n\ngit remote add origin https://github.com/&lt;twojGit&gt;/nazwa.git\n\nObsÅ‚uga w 3 krokach\n\n# sprawdÅº zmiany jakie zostaÅ‚y dokonane\ngit status\n# 1. dodaj wszystkie zmiany\ngit add .\n# 2. zapisz bierzÄ…cy stan wraz z informacjÄ… co zrobiÅ‚eÅ›\ngit commit -m \" opis \"\n# 3. potem juÅ¼ zostaje tylko\ngit push origin master\nWarto obejrzeÄ‡ Youtube course.\nCiekawe i proste wprowadzenie mozna znaleÅºÄ‡ tutaj"
  },
  {
    "objectID": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "href": "info.html#zacznij-korzystaÄ‡-z-dockera",
    "title": "NarzÄ™dzia",
    "section": "Zacznij korzystaÄ‡ z Dockera",
    "text": "Zacznij korzystaÄ‡ z Dockera\n\n\n\nW celu pobrania oprogramowania docker na swÃ³j system przejdÅº do strony.\nJeÅ¼li wszystko zainstalowaÅ‚o siÄ™ prawidÅ‚owo wykonaj nastÄ™pujÄ…ce polecenia:\n\nSprawdÅº zainstalowanÄ… wersjÄ™\n\ndocker --version\n\nÅšciÄ…gnij i uruchom obraz Hello World i\n\ndocker run hello-world\n\nPrzeglÄ…d Å›ciÄ…gnietych obrazÃ³w:\n\ndocker image ls\n\ndocker images\n\nPrzeglÄ…d uruchomionych kontenerÃ³w:\n\ndocker ps \n\ndocker ps -all\n\nZatrzymanie uruchomionego kontenera:\n\ndocker stop &lt;CONTAINER ID&gt;\n\nUsuniÄ™cie kontenera\n\ndocker rm -f &lt;CONTAINER ID&gt;\nPolecam rÃ³wnieÅ¼ krÃ³tkie intro"
  },
  {
    "objectID": "w3.html",
    "href": "w3.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "Wykorzystanie systemÃ³w real-time (czas rzeczywisty) w analizie danych wymaga odpowiedniej architektury, ktÃ³ra bÄ™dzie mogÅ‚a szybko przetwarzaÄ‡ ogromne iloÅ›ci danych oraz reagowaÄ‡ na nie w czasie rzeczywistym. Architektura systemu real-time jest kluczowa, poniewaÅ¼ umoÅ¼liwia szybsze podejmowanie decyzji, monitorowanie procesÃ³w w czasie rzeczywistym i reagowanie na zdarzenia bez opÃ³Åºnienia.\nOmÃ³wimy gÅ‚Ã³wne elementy architektury systemÃ³w real-time, popularne wzorce architektoniczne oraz technologie, ktÃ³re sÄ… wykorzystywane do budowy takich systemÃ³w.\n\n\nSystemy real-time muszÄ… speÅ‚niaÄ‡ szereg wymagaÅ„ zwiÄ…zanych z czasem przetwarzania danych. Istnieje kilka kluczowych komponentÃ³w w architekturze systemu, ktÃ³re zapewniajÄ… jego prawidÅ‚owe funkcjonowanie.\n\n\nDane w systemie real-time pochodzÄ… z rÃ³Å¼nych ÅºrÃ³deÅ‚, takich jak:\n\nCzujniki IoT: np. monitorowanie maszyn w fabryce, urzÄ…dzenia medyczne.\nTransakcje w czasie rzeczywistym: np. zakupy online, dane z gieÅ‚dy.\nDane uÅ¼ytkownikÃ³w: np. logi uÅ¼ytkownikÃ³w w aplikacjach mobilnych, dane z mediÃ³w spoÅ‚ecznoÅ›ciowych.\n\n\n\n\nDane muszÄ… byÄ‡ szybko przesyÅ‚ane do systemÃ³w, ktÃ³re mogÄ… je analizowaÄ‡. W tym celu wykorzystywane sÄ… technologie strumieniowe, takie jak:\n\nApache Kafka: popularny system do przesyÅ‚ania danych w czasie rzeczywistym, zapewniajÄ…cy wysokÄ… wydajnoÅ›Ä‡ i niezawodnoÅ›Ä‡.\nApache Pulsar: alternatywa dla Kafki, dedykowana do przetwarzania danych w czasie rzeczywistym z duÅ¼Ä… iloÅ›ciÄ… subskrybentÃ³w.\n\n\n\n\nDane w systemach real-time sÄ… czÄ™sto przetwarzane w strumieniu. Dwa gÅ‚Ã³wne modele przetwarzania to:\n\nBatch processing: Przetwarzanie danych w partiach, ktÃ³re moÅ¼e mieÄ‡ opÃ³Åºnienie, ale przetwarza dane w sposÃ³b efektywny. MoÅ¼e byÄ‡ wykorzystywane w kombinacji z systemami real-time do agregacji danych.\nStream processing: Przetwarzanie danych w czasie rzeczywistym, bez opÃ³ÅºnieÅ„, w ktÃ³rym dane sÄ… natychmiastowo analizowane i przetwarzane.\n\n\n\n\nPrzechowywanie danych w systemie real-time zaleÅ¼y od wymagaÅ„ aplikacji. Dwa gÅ‚Ã³wne rodzaje przechowywania to:\n\nData Lake: skÅ‚adowanie ogromnych iloÅ›ci nieprzetworzonych danych w postaci surowych plikÃ³w. Bazy danych NoSQL: takie jak Cassandra, ktÃ³re umoÅ¼liwiajÄ… szybki dostÄ™p do danych w czasie rzeczywistym.\nData Warehouse: skÅ‚adowanie przetworzonych danych w celu ich analizy.\n\n\n\n\nPo przetworzeniu danych w czasie rzeczywistym naleÅ¼y wykonaÄ‡ ich analizÄ™ i prezentacjÄ™ w sposÃ³b zrozumiaÅ‚y dla uÅ¼ytkownika:\n\nDashboardy: narzÄ™dzia takie jak Grafana lub Kibana, ktÃ³re sÅ‚uÅ¼Ä… do wizualizacji wynikÃ³w w czasie rzeczywistym.\nMachine Learning: zastosowanie algorytmÃ³w uczenia maszynowego w czasie rzeczywistym do klasyfikacji, wykrywania anomalii czy predykcji (np. wykrywanie oszustw).\n\n\n\n\n\n\n\nLambda Architecture to popularna koncepcja przetwarzania danych, ktÃ³ra Å‚Ä…czy przetwarzanie wsadowe z przetwarzaniem strumieniowym. To klasyczna architektura uÅ¼ywana w systemach przetwarzania Big Data, ktÃ³ra zakÅ‚ada dwie warstwy:\n\nBatch Layer: przetwarzanie (duÅ¼ych iloÅ›ci) danych wsadowych, ktÃ³re sÄ… pÃ³Åºniej wykorzystywane do analizy. Realizuje procesy przetwarzania w trybie offline\nSpeed Layer (Real-Time Layer): przetwarzanie danych w czasie rzeczywistym, czyli napÅ‚ywajÄ…ce dane strumieniowe, np. z sensorÃ³w, social media, transakcji, w celu uzyskania natychmiastowych wynikÃ³w.\nServing Layer: warstwa, ktÃ³ra Å‚Ä…czy wyniki obu poprzednich warstw i dostarcza je do uÅ¼ytkownika np. za pomocÄ… API.\n\n \n\n\n\n\nâœ… MoÅ¼liwoÅ›Ä‡ Å‚Ä…czenia przetwarzania wsadowego i strumieniowego,\nâœ… wsparcie dla duÅ¼ych zbiorÃ³w danych,\nâœ… elastycznoÅ›Ä‡ w przetwarzaniu zÅ‚oÅ¼onych zapytaÅ„.\nâŒ Wymaga utrzymywania dwÃ³ch oddzielnych systemÃ³w do przetwarzania danych (batch i stream), co prowadzi do zÅ‚oÅ¼onoÅ›ci implementacji i utrzymania.\n\n\n\n\nKappa Architecture jest uproszczonÄ… wersjÄ… Lambda Architecture. Zamiast uÅ¼ywaÄ‡ dwÃ³ch osobnych warstw (batch i speed), Kappa wykorzystuje tylko jednÄ… warstwÄ™ przetwarzania strumieniowego, co upraszcza caÅ‚y system.\nJest to bardziej elastyczne podejÅ›cie do budowy systemÃ³w real-time, zwÅ‚aszcza w przypadku, gdy dane sÄ… przetwarzane tylko w jednym trybie (streaming).\n \n\n\n\n\nâœ… Prostota: Jako Å¼e przetwarzanie danych odbywa siÄ™ tylko w jednym strumieniu, caÅ‚y system jest prostszy i bardziej spÃ³jny.\nâœ… SkalowalnoÅ›Ä‡: DziÄ™ki eliminacji warstwy batch, system jest bardziej elastyczny i skalowalny w kontekÅ›cie analizy danych w czasie rzeczywistym.\nâœ… Idealne dla ML: Kappa Architecture Å›wietnie sprawdza siÄ™ w zastosowaniach zwiÄ…zanych z Machine Learning, poniewaÅ¼ przetwarzanie danych odbywa siÄ™ na bieÅ¼Ä…co, co pozwala na szybsze uczenie i wdraÅ¼anie modeli ML w czasie rzeczywistym.\nâŒ MoÅ¼e byÄ‡ mniej wydajna przy bardzo duÅ¼ych zbiorach danych, w przypadku, gdy wymagane jest skomplikowane przetwarzanie wsadowe.\n\n\n\n\nArchitektura mikroserwisÃ³w jest powszechnie wykorzystywana w systemach real-time, poniewaÅ¼ umoÅ¼liwia:\n\nPodziaÅ‚ aplikacji na mniejsze, autonomiczne jednostki.\nElastycznoÅ›Ä‡ i skalowalnoÅ›Ä‡ systemu.\nMoÅ¼liwoÅ›Ä‡ przetwarzania rÃ³Å¼nych rodzajÃ³w danych przez rÃ³Å¼ne mikroserwisy.\nWykorzystanie komunikacji asynchronicznej, np. przez kolejki wiadomoÅ›ci.\n\n\n\n\nUber to przykÅ‚ad firmy, ktÃ³ra skutecznie wykorzystuje narzÄ™dzia do przetwarzania strumieniowego, by monitorowaÄ‡ ruch drogowy w czasie rzeczywistym. DziÄ™ki systemowi Apache Kafka, Uber gromadzi dane o ruchu drogowym, lokalizacji pojazdÃ³w oraz czasach oczekiwania na przejazd, ktÃ³re sÄ… nastÄ™pnie analizowane na Å¼ywo.\nDane wejÅ›ciowe: Informacje o czasie i miejscu podrÃ³Å¼y, dane GPS z pojazdÃ³w, natÄ™Å¼enie ruchu.\nProces przetwarzania: Uber wykorzystuje Apache Kafka do przesyÅ‚ania tych danych w czasie rzeczywistym do systemÃ³w takich jak Apache Flink lub Spark Streaming, ktÃ³re analizujÄ… je na bieÅ¼Ä…co.\nAnaliza: System przewiduje czas oczekiwania na przejazd, monitoruje warunki drogowe oraz optymalizuje trasÄ™ w czasie rzeczywistym.\nWynik: UÅ¼ytkownicy Ubera otrzymujÄ… prognozy czasu przejazdu, a Uber dynamicznie dostosowuje zasoby (np. przydzielanie kierowcÃ³w), co umoÅ¼liwia optymalizacjÄ™ transportu."
  },
  {
    "objectID": "w3.html#architektura-systemÃ³w-real-time",
    "href": "w3.html#architektura-systemÃ³w-real-time",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "Wykorzystanie systemÃ³w real-time (czas rzeczywisty) w analizie danych wymaga odpowiedniej architektury, ktÃ³ra bÄ™dzie mogÅ‚a szybko przetwarzaÄ‡ ogromne iloÅ›ci danych oraz reagowaÄ‡ na nie w czasie rzeczywistym. Architektura systemu real-time jest kluczowa, poniewaÅ¼ umoÅ¼liwia szybsze podejmowanie decyzji, monitorowanie procesÃ³w w czasie rzeczywistym i reagowanie na zdarzenia bez opÃ³Åºnienia.\nOmÃ³wimy gÅ‚Ã³wne elementy architektury systemÃ³w real-time, popularne wzorce architektoniczne oraz technologie, ktÃ³re sÄ… wykorzystywane do budowy takich systemÃ³w.\n\n\nSystemy real-time muszÄ… speÅ‚niaÄ‡ szereg wymagaÅ„ zwiÄ…zanych z czasem przetwarzania danych. Istnieje kilka kluczowych komponentÃ³w w architekturze systemu, ktÃ³re zapewniajÄ… jego prawidÅ‚owe funkcjonowanie.\n\n\nDane w systemie real-time pochodzÄ… z rÃ³Å¼nych ÅºrÃ³deÅ‚, takich jak:\n\nCzujniki IoT: np. monitorowanie maszyn w fabryce, urzÄ…dzenia medyczne.\nTransakcje w czasie rzeczywistym: np. zakupy online, dane z gieÅ‚dy.\nDane uÅ¼ytkownikÃ³w: np. logi uÅ¼ytkownikÃ³w w aplikacjach mobilnych, dane z mediÃ³w spoÅ‚ecznoÅ›ciowych.\n\n\n\n\nDane muszÄ… byÄ‡ szybko przesyÅ‚ane do systemÃ³w, ktÃ³re mogÄ… je analizowaÄ‡. W tym celu wykorzystywane sÄ… technologie strumieniowe, takie jak:\n\nApache Kafka: popularny system do przesyÅ‚ania danych w czasie rzeczywistym, zapewniajÄ…cy wysokÄ… wydajnoÅ›Ä‡ i niezawodnoÅ›Ä‡.\nApache Pulsar: alternatywa dla Kafki, dedykowana do przetwarzania danych w czasie rzeczywistym z duÅ¼Ä… iloÅ›ciÄ… subskrybentÃ³w.\n\n\n\n\nDane w systemach real-time sÄ… czÄ™sto przetwarzane w strumieniu. Dwa gÅ‚Ã³wne modele przetwarzania to:\n\nBatch processing: Przetwarzanie danych w partiach, ktÃ³re moÅ¼e mieÄ‡ opÃ³Åºnienie, ale przetwarza dane w sposÃ³b efektywny. MoÅ¼e byÄ‡ wykorzystywane w kombinacji z systemami real-time do agregacji danych.\nStream processing: Przetwarzanie danych w czasie rzeczywistym, bez opÃ³ÅºnieÅ„, w ktÃ³rym dane sÄ… natychmiastowo analizowane i przetwarzane.\n\n\n\n\nPrzechowywanie danych w systemie real-time zaleÅ¼y od wymagaÅ„ aplikacji. Dwa gÅ‚Ã³wne rodzaje przechowywania to:\n\nData Lake: skÅ‚adowanie ogromnych iloÅ›ci nieprzetworzonych danych w postaci surowych plikÃ³w. Bazy danych NoSQL: takie jak Cassandra, ktÃ³re umoÅ¼liwiajÄ… szybki dostÄ™p do danych w czasie rzeczywistym.\nData Warehouse: skÅ‚adowanie przetworzonych danych w celu ich analizy.\n\n\n\n\nPo przetworzeniu danych w czasie rzeczywistym naleÅ¼y wykonaÄ‡ ich analizÄ™ i prezentacjÄ™ w sposÃ³b zrozumiaÅ‚y dla uÅ¼ytkownika:\n\nDashboardy: narzÄ™dzia takie jak Grafana lub Kibana, ktÃ³re sÅ‚uÅ¼Ä… do wizualizacji wynikÃ³w w czasie rzeczywistym.\nMachine Learning: zastosowanie algorytmÃ³w uczenia maszynowego w czasie rzeczywistym do klasyfikacji, wykrywania anomalii czy predykcji (np. wykrywanie oszustw).\n\n\n\n\n\n\n\nLambda Architecture to popularna koncepcja przetwarzania danych, ktÃ³ra Å‚Ä…czy przetwarzanie wsadowe z przetwarzaniem strumieniowym. To klasyczna architektura uÅ¼ywana w systemach przetwarzania Big Data, ktÃ³ra zakÅ‚ada dwie warstwy:\n\nBatch Layer: przetwarzanie (duÅ¼ych iloÅ›ci) danych wsadowych, ktÃ³re sÄ… pÃ³Åºniej wykorzystywane do analizy. Realizuje procesy przetwarzania w trybie offline\nSpeed Layer (Real-Time Layer): przetwarzanie danych w czasie rzeczywistym, czyli napÅ‚ywajÄ…ce dane strumieniowe, np. z sensorÃ³w, social media, transakcji, w celu uzyskania natychmiastowych wynikÃ³w.\nServing Layer: warstwa, ktÃ³ra Å‚Ä…czy wyniki obu poprzednich warstw i dostarcza je do uÅ¼ytkownika np. za pomocÄ… API.\n\n \n\n\n\n\nâœ… MoÅ¼liwoÅ›Ä‡ Å‚Ä…czenia przetwarzania wsadowego i strumieniowego,\nâœ… wsparcie dla duÅ¼ych zbiorÃ³w danych,\nâœ… elastycznoÅ›Ä‡ w przetwarzaniu zÅ‚oÅ¼onych zapytaÅ„.\nâŒ Wymaga utrzymywania dwÃ³ch oddzielnych systemÃ³w do przetwarzania danych (batch i stream), co prowadzi do zÅ‚oÅ¼onoÅ›ci implementacji i utrzymania.\n\n\n\n\nKappa Architecture jest uproszczonÄ… wersjÄ… Lambda Architecture. Zamiast uÅ¼ywaÄ‡ dwÃ³ch osobnych warstw (batch i speed), Kappa wykorzystuje tylko jednÄ… warstwÄ™ przetwarzania strumieniowego, co upraszcza caÅ‚y system.\nJest to bardziej elastyczne podejÅ›cie do budowy systemÃ³w real-time, zwÅ‚aszcza w przypadku, gdy dane sÄ… przetwarzane tylko w jednym trybie (streaming).\n \n\n\n\n\nâœ… Prostota: Jako Å¼e przetwarzanie danych odbywa siÄ™ tylko w jednym strumieniu, caÅ‚y system jest prostszy i bardziej spÃ³jny.\nâœ… SkalowalnoÅ›Ä‡: DziÄ™ki eliminacji warstwy batch, system jest bardziej elastyczny i skalowalny w kontekÅ›cie analizy danych w czasie rzeczywistym.\nâœ… Idealne dla ML: Kappa Architecture Å›wietnie sprawdza siÄ™ w zastosowaniach zwiÄ…zanych z Machine Learning, poniewaÅ¼ przetwarzanie danych odbywa siÄ™ na bieÅ¼Ä…co, co pozwala na szybsze uczenie i wdraÅ¼anie modeli ML w czasie rzeczywistym.\nâŒ MoÅ¼e byÄ‡ mniej wydajna przy bardzo duÅ¼ych zbiorach danych, w przypadku, gdy wymagane jest skomplikowane przetwarzanie wsadowe.\n\n\n\n\nArchitektura mikroserwisÃ³w jest powszechnie wykorzystywana w systemach real-time, poniewaÅ¼ umoÅ¼liwia:\n\nPodziaÅ‚ aplikacji na mniejsze, autonomiczne jednostki.\nElastycznoÅ›Ä‡ i skalowalnoÅ›Ä‡ systemu.\nMoÅ¼liwoÅ›Ä‡ przetwarzania rÃ³Å¼nych rodzajÃ³w danych przez rÃ³Å¼ne mikroserwisy.\nWykorzystanie komunikacji asynchronicznej, np. przez kolejki wiadomoÅ›ci.\n\n\n\n\nUber to przykÅ‚ad firmy, ktÃ³ra skutecznie wykorzystuje narzÄ™dzia do przetwarzania strumieniowego, by monitorowaÄ‡ ruch drogowy w czasie rzeczywistym. DziÄ™ki systemowi Apache Kafka, Uber gromadzi dane o ruchu drogowym, lokalizacji pojazdÃ³w oraz czasach oczekiwania na przejazd, ktÃ³re sÄ… nastÄ™pnie analizowane na Å¼ywo.\nDane wejÅ›ciowe: Informacje o czasie i miejscu podrÃ³Å¼y, dane GPS z pojazdÃ³w, natÄ™Å¼enie ruchu.\nProces przetwarzania: Uber wykorzystuje Apache Kafka do przesyÅ‚ania tych danych w czasie rzeczywistym do systemÃ³w takich jak Apache Flink lub Spark Streaming, ktÃ³re analizujÄ… je na bieÅ¼Ä…co.\nAnaliza: System przewiduje czas oczekiwania na przejazd, monitoruje warunki drogowe oraz optymalizuje trasÄ™ w czasie rzeczywistym.\nWynik: UÅ¼ytkownicy Ubera otrzymujÄ… prognozy czasu przejazdu, a Uber dynamicznie dostosowuje zasoby (np. przydzielanie kierowcÃ³w), co umoÅ¼liwia optymalizacjÄ™ transportu."
  },
  {
    "objectID": "sylabus.html",
    "href": "sylabus.html",
    "title": "Sylabus",
    "section": "",
    "text": "Nazwa przedmiotu: Analiza danych w czasie rzeczywistym\nJednostka: SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nKod przedmiotu: 222890-D, 222890-S\nPunkty ECTS: 3\nJÄ™zyk prowadzenia: polski\nPoziom przedmiotu: Å›rednio-zaawansowany\nProwadzÄ…cy: Sebastian ZajÄ…c, sebastian.zajac@sgh.waw.pl\nWebsite: https://sebkaz-teaching.github.io/RTA_2025/"
  },
  {
    "objectID": "sylabus.html#cel-przedmiotu",
    "href": "sylabus.html#cel-przedmiotu",
    "title": "Sylabus",
    "section": "Cel Przedmiotu",
    "text": "Cel Przedmiotu\nWspÃ³Å‚czesny biznes opiera siÄ™ na podejmowaniu decyzji opartych na danych. Coraz wiÄ™ksza iloÅ›Ä‡ informacji, rosnÄ…ce wymagania rynku oraz potrzeba natychmiastowej reakcji sprawiajÄ…, Å¼e analiza danych w czasie rzeczywistym staje siÄ™ kluczowym elementem nowoczesnych procesÃ³w biznesowych.\nNa zajÄ™ciach studenci zapoznajÄ… siÄ™ z metodami i technologiami umoÅ¼liwiajÄ…cymi przetwarzanie danych w czasie rzeczywistym. SzczegÃ³lnÄ… uwagÄ™ poÅ›wiÄ™cimy zastosowaniu uczenia maszynowego (machine learning), sztucznej inteligencji (artificial intelligence) oraz gÅ‚Ä™bokich sieci neuronowych (deep learning) w analizie danych. Zrozumienie tych metod pozwala nie tylko lepiej interpretowaÄ‡ zjawiska biznesowe, ale takÅ¼e podejmowaÄ‡ szybkie i trafne decyzje.\nW ramach kursu omÃ³wimy zarÃ³wno dane ustrukturyzowane, jak i nieustrukturyzowane (obrazy, dÅºwiÄ™k, strumieniowanie wideo). Studenci poznajÄ… architektury przetwarzania danych, takie jak lambda i kappa, wykorzystywane w systemach data lake, a takÅ¼e wyzwania zwiÄ…zane z modelowaniem danych w czasie rzeczywistym na duÅ¼Ä… skalÄ™.\nKurs obejmuje czÄ™Å›Ä‡ teoretycznÄ… oraz praktyczne laboratoria, podczas ktÃ³rych studenci bÄ™dÄ… pracowaÄ‡ z rzeczywistymi danymi w Å›rodowiskach takich jak: JupyterLab, PyTorch, Apache Spark, Apache Kafka. DziÄ™ki temu studenci nie tylko zdobÄ™dÄ… wiedzÄ™ na temat metod analitycznych, ale takÅ¼e nauczÄ… siÄ™ korzystaÄ‡ z najnowszych technologii informatycznych stosowanych w analizie danych w czasie rzeczywistym."
  },
  {
    "objectID": "sylabus.html#program-przedmiotu",
    "href": "sylabus.html#program-przedmiotu",
    "title": "Sylabus",
    "section": "Program przedmiotu",
    "text": "Program przedmiotu\n\nModelowanie, uczenie i predykcja w trybie wsadowym (offline learning) i przyrostowym (online learning). Problemy przyrostowego uczenia maszynowego.\nModele przetwarzania danych w Big Data. Od plikoÌw pÅ‚askich do Data Lake. Mity i fakty przetwarzania danych w czasie rzeczywistym. (WykÅ‚ad)\nSystemy NRT (near real-time systems), pozyskiwanie danych, streaming, analityka.\nAlgorytmy estymacji parametroÌw modelu w trybie przyrostowym. Stochastic Gradient Descent.\nArchitektura Lambda i Kappa. Zaprojektowanie architektury IT dla przetwarzania danych w czasie rzeczywistym.\nPrzygotowanie mikroserwisu z modelem ML do zastosowania produkcyjnego.\nStrukturyzowane i niestrukturyzowane dane. Relacyjne bazy danych i bazy NoSQL\nAgregacje i raportowanie w bazach NoSQL (na przykÅ‚adzie bazy Cassandra).\nPodstawy obiektowego programowania w Pythonie w analizie regresji liniowej, logistycznej oraz sieci neuronowych z wykorzystaniem biblioteki sklearn, TensorFLow i Keras\nArchitektura IT przetwarzania Big Data. Przygotowanie wirtualnego sÌrodowiska dla Sparka. Pierwszy program w PySpark. Wykorzystanie przygotowanego sÌrodowiska do analizy danych z serwisu Twitter.\nAnaliza 1 Detekcja wyÅ‚udzenÌ w zgÅ‚oszeniach szkoÌd samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego sÌrodowiska. Cz 1.\nAnaliza 1 Detekcja wyÅ‚udzenÌ w zgÅ‚oszeniach szkoÌd samochodowych w czasie rzeczywistym z wykorzystaniem przygotowanego, darmowego sÌrodowiska. Cz 2.\nPrzygotowanie sÌrodowiska Microsoft Azure. Detekcja anomalii i wartosÌci odstajaÌ¨cych w logowanych zdarzeniach sieci Ethernet cz 1.\nAnaliza 2 Detekcja anomalii i wartosÌci odstajaÌ¨cych w logowanych zdarzeniach sieci Ethernet cz 2. Inne narzeÌ¨dzia IT do szybkiej analizy logoÌw.\nNarzeÌ¨dzia SAS do strumieniowego przetwarzania danych"
  },
  {
    "objectID": "sylabus.html#efekty-ksztaÅ‚cenia",
    "href": "sylabus.html#efekty-ksztaÅ‚cenia",
    "title": "Sylabus",
    "section": "Efekty ksztaÅ‚cenia",
    "text": "Efekty ksztaÅ‚cenia\n\nWiedza:\n\n\nZna historieÌ¨ i filozofieÌ¨ modeli przetwarzania danych\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W02, (OGL)O2_W04, (OGL)O2_W07\nMetody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ z kolokwium\n\nZna typy danych ustrukturyzowanych jak i nieustrukturyzowanych\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W04, (OGL)O2_W04, (OGL) O2_W07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nZna mozÌ‡liwosÌci i obszary zastosowania procesowania danych w czasie rzeczywistym\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W02, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W08\nMetody weryfikacji: egzamin pisemny (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ egzaminacyjnych\n\nZna teoretyczne aspekty struktury lambda i kappa\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W03, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W04, (OGL) O2_W06, (OGL)O2_W08\nMetody weryfikacji: kolokwium pisemne (pytania otwarte, zadania)\nMetody dokumentacji: wykaz pytanÌ z kolokwium\n\nUmie wybracÌ struktureÌ¨ IT dla danego problemu biznesowego\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W02, (Analiza danych - Big Data)K2A_W03, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nRozumie potrzeby biznesowe podejmowania decyzji w bardzo kroÌtkim czasie\n\nPowiaÌ¨zania: (Analiza danych - Big Data)K2A_W01, (Analiza danych - Big Data)K2A_W05, (OGL)O2_W01, (OGL) O2_W04, (OGL)O2_W06, (OGL)O2_W08\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmiejÄ™tnoÅ›ci:\n\n\nRozroÌzÌ‡nia typy danych strukturyzowanych jak i niestrukturyzowanych\n\nPowiaÌ¨zania: K2A_U02, K2A_U07, K2A_U10, O2_U02\nMetody weryfikacji: test\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie przygotowacÌ, przetwarzacÌ oraz zachowywacÌ dane generowane w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U03, K2A_U05, K2A_U09, O2_U02, O2_U04\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nRozumie ograniczenia wynikajaÌ¨ce z czasu przetwarzania przez urzaÌ¨dzenia oraz systemy informatyczne\n\nPowiaÌ¨zania: K2A_U01, K2A_U07, K2A_U11, O2_U02\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie zastosowacÌ i skonstruowacÌ system do przetwarzania w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U05, K2A_U10, O2_U05, O2_U06, O2_U07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUmie przygotowacÌ raportowanie dla systemu przetwarzania w czasie rzeczywistym\n\nPowiaÌ¨zania: K2A_U02, K2A_U08, K2A_U10, O2_U06, O2_U07\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nKompetencje:\n\n\nFormuÅ‚uje problem analityczny wraz z jego informatycznym rozwiaÌ¨zaniem\n\nPowiaÌ¨zania: K2A_K01, K2A_K03, O2_K02, O2_K06, O2_K07\nMetody weryfikacji: projekt, prezentacja\nMetody dokumentacji: prace pisemne studenta (w trakcie semestru, zaliczeniowe, egzaminacyjne)\n\nUtrwala umiejeÌ¨tnosÌcÌ samodzielnego uzupeÅ‚niania wiedzy teoretycznej jak i praktycznej w zakresie programowania, modelowania, nowych technologii informatycznych z wykorzystaniem analizy w czasie rzeczywistym.\n\nPowiaÌ¨zania: K2A_K02, K2A_K04, (OGL)O2_K01, (OGL) O2_K02, (OGL)O2_K05, (OGL)O2_K06\nMetody weryfikacji: projekt\nMetody dokumentacji: prace pisemne studenta ( w trakcie semestru, zaliczeniowe, egzaminacyjne)"
  },
  {
    "objectID": "sylabus.html#realizacja-przedmiotu",
    "href": "sylabus.html#realizacja-przedmiotu",
    "title": "Sylabus",
    "section": "Realizacja przedmiotu",
    "text": "Realizacja przedmiotu\n\negzamin testowy 20%\nZadania 40%\nProjekt 40%"
  },
  {
    "objectID": "sylabus.html#literatura",
    "href": "sylabus.html#literatura",
    "title": "Sylabus",
    "section": "Literatura",
    "text": "Literatura\n1ï¸âƒ£ ZajÄ…c S. (red.), Modelowanie dla biznesu, Analityka w czasie rzeczywistym - narzÄ™dzia informatyczne i biznesowe, SGH, Warszawa 2022.\n2ï¸âƒ£ FrÄ…tczak E. (red.), Modelowanie dla biznesu: Regresja logistyczna, Regresja Poissona, Survival Data Mining, CRM, Credit Scoring, SGH, Warszawa 2019.\n3ï¸âƒ£ Bellemare A., MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™, Oâ€™Reilly 2021.\n4ï¸âƒ£ Shapira G., Palino T., Sivaram R., Petty K., Kafka: The Definitive Guide. Real-time data and stream processing at scale, Oâ€™Reilly 2022.\n5ï¸âƒ£ Lakshmanan V., Robinson S., Munn M., Wzorce projektowe uczenia maszynowego. RozwiÄ…zania typowych problemÃ³w dotyczÄ…cych przygotowania danych, konstruowania modeli i MLOps, Oâ€™Reilly 2021.\n6ï¸âƒ£ Gift N., Deza A., Practical MLOps: Operationalizing Machine Learning Models, Oâ€™Reilly 2022.\n7ï¸âƒ£ Tiark Rompf, Streaming Systems: The What, Where, When, and How of Large-Scale Data Processing, Oâ€™Reilly 2018.\n8ï¸âƒ£ SebastiÃ¡n RamÃ­rez, FastAPI: Modern Web APIs with Python, Manning (w przygotowaniu, aktualnie dostÄ™pna online).\n9ï¸âƒ£ Trevor Hastie, Robert Tibshirani, Jerome Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Springer 2017.\nğŸ”Ÿ Anirudh Koul, Siddha Ganju, Meher Kasam, Practical Deep Learning for Cloud, Mobile & Edge, Oâ€™Reilly 2019."
  },
  {
    "objectID": "ksiazki.html",
    "href": "ksiazki.html",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "G. Maas, F. Garillot Stream Processing with Apache Spark Zobacz opis lub Kup e-book\nF. Hueske, V. Kalavri Stream Processing with Apache Flink Zobacz opis lub Kup e-book\n\n\n\nA. Bellemare MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™ Zobacz opis lub Kup\n\n\n\n\n\n\nW. McKinney Python w analizie danych. Przetwarzanie danych za pomocÄ… pakietÃ³w Pandas i NumPy oraz Å›rodowiska IPython. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. McIlwraith, H. Marmanis, D. Babenko Inteligentna sieÄ‡. Algorytmy przyszÅ‚oÅ›ci. Wydanie II (ebook) Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJoel Grus Data science od podstaw. Analiza danych w Pythonie. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nJohn W. Foreman Mistrz analizy danych. Od danych do wiedzy. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nA. Geron Uczenie maszynowe z uÅ¼yciem Scikit-Learn i TensorFlow. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nAlberto Boschetti, Luca Massaron Python. Podstawy nauki o danych. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nSebastian Raschka Python. Uczenie maszynowe. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nR. Schutt, C. Oâ€™Neil Badanie danych. Raport z pierwszej lini dziaÅ‚aÅ„. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nT. Segaran Nowe usÅ‚ugi 2.0. Przewodnik po analizie zbiorÃ³w danych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nF. Chollet Deep Learning. Praca z jÄ™zykiem Python i bibliotekÄ… Keras. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Patterson, A. Gibson Deep Learning. Praktyczne wprowadzenie (ebook) Zobacz opis lub Kup e-book\nV. Zocca, G. Spacagna, D. Slater, P. Roelants. Deep Learning. Uczenie gÅ‚Ä™bokie z jÄ™zykiem Python. Sztuczna inteligencja i sieci neuronowe Zobacz opis lub Kup ebook\nD. Osinga Deep Learning. Receptury Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Weidman Uczenie gÅ‚Ä™bokie od zera. Podstawy implementacji w Pythonie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. Foster Deep learning i modelowanie generatywne. Jak nauczyÄ‡ komputer malowania, pisania, komponowania i grania Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Howard, S. Gugger Deep learning dla programistÃ³w. Budowanie aplikacji AI za pomocÄ… fastai i PyTorch Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nJ. S. Damji, B. Wenig, T. Das, D. Lee Spark. BÅ‚yskawiczna analiza danych Zobacz opis lub Kup\nSpark. Zaawansowana analiza danych (ebook) Zobacz opis lub Kup e-book\nB. Chambers, M. Zaharia Spark: The Definitive Guide. Big Data Processing Made Simple (ebook) Zobacz opis lub Kup e-book\nJ. Quddus Machine Learning with Apache Spark Quick Start Guide (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nG. Coldwind ZrozumieÄ‡ programowanie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nA. Allain C++. Przewodnik dla poczÄ…tkujÄ…cych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Dasgupta, C. Papadimitriou, U. Vazirani Algorytmy PWN.\n\n\n\n\n\nJ. Krochmalski Docker. Projektowanie i wdraÅ¼anie aplikacji Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nR. McKendrick, S. Gallagher Docker. Programowanie aplikacji dla zaawansowanych. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nP. Bell, B. Beer GitHub. Przyjazny przewodnik (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nC. Althoff, Programista Samouk. Profesjonalny przewodnik do samodzielnej nauki kodowania. Zobacz opis lub Kup teraz, Kup e-book\nA. Sweigart, Automatyzacja nudnych zadaÅ„ z pythonem. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nK. Reitz, T. Schlusser Przewodnik po Pythonie. Dobre praktyki i praktyczne narzÄ™dzia. Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nB.Tate, L. Carslon, C. Hiibs, Ruby on Rails. Wprowadzenie. Wydanie II Zobacz opis lub Kup e-book\nB. Frain, Responsive Web Design. Projektowanie elastycznych witryn w HTML5 i CSS3, Zobacz opis lub Kup e-book\nK. Beck, TDD. Sztuda tworzenia, Zobacz opis lub Kup teraz, Kup e-book\nB. Dayley, Node.js, MongoDB, AngularJS. Kompendium wiedzy, Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage."
  },
  {
    "objectID": "ksiazki.html#ksiÄ…Å¼ki",
    "href": "ksiazki.html#ksiÄ…Å¼ki",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "",
    "text": "G. Maas, F. Garillot Stream Processing with Apache Spark Zobacz opis lub Kup e-book\nF. Hueske, V. Kalavri Stream Processing with Apache Flink Zobacz opis lub Kup e-book\n\n\n\nA. Bellemare MikrousÅ‚ugi oparte na zdarzeniach. Wykorzystanie danych w organizacji na duÅ¼Ä… skalÄ™ Zobacz opis lub Kup\n\n\n\n\n\n\nW. McKinney Python w analizie danych. Przetwarzanie danych za pomocÄ… pakietÃ³w Pandas i NumPy oraz Å›rodowiska IPython. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. McIlwraith, H. Marmanis, D. Babenko Inteligentna sieÄ‡. Algorytmy przyszÅ‚oÅ›ci. Wydanie II (ebook) Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJoel Grus Data science od podstaw. Analiza danych w Pythonie. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nJohn W. Foreman Mistrz analizy danych. Od danych do wiedzy. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nA. Geron Uczenie maszynowe z uÅ¼yciem Scikit-Learn i TensorFlow. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book.\nAlberto Boschetti, Luca Massaron Python. Podstawy nauki o danych. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nSebastian Raschka Python. Uczenie maszynowe. Wydanie II. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nR. Schutt, C. Oâ€™Neil Badanie danych. Raport z pierwszej lini dziaÅ‚aÅ„. Zobacz opis lub Kup ksiÄ…Å¼kÄ™.\nT. Segaran Nowe usÅ‚ugi 2.0. Przewodnik po analizie zbiorÃ³w danych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nF. Chollet Deep Learning. Praca z jÄ™zykiem Python i bibliotekÄ… Keras. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Patterson, A. Gibson Deep Learning. Praktyczne wprowadzenie (ebook) Zobacz opis lub Kup e-book\nV. Zocca, G. Spacagna, D. Slater, P. Roelants. Deep Learning. Uczenie gÅ‚Ä™bokie z jÄ™zykiem Python. Sztuczna inteligencja i sieci neuronowe Zobacz opis lub Kup ebook\nD. Osinga Deep Learning. Receptury Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Weidman Uczenie gÅ‚Ä™bokie od zera. Podstawy implementacji w Pythonie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nD. Foster Deep learning i modelowanie generatywne. Jak nauczyÄ‡ komputer malowania, pisania, komponowania i grania Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nJ. Howard, S. Gugger Deep learning dla programistÃ³w. Budowanie aplikacji AI za pomocÄ… fastai i PyTorch Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nJ. S. Damji, B. Wenig, T. Das, D. Lee Spark. BÅ‚yskawiczna analiza danych Zobacz opis lub Kup\nSpark. Zaawansowana analiza danych (ebook) Zobacz opis lub Kup e-book\nB. Chambers, M. Zaharia Spark: The Definitive Guide. Big Data Processing Made Simple (ebook) Zobacz opis lub Kup e-book\nJ. Quddus Machine Learning with Apache Spark Quick Start Guide (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nG. Coldwind ZrozumieÄ‡ programowanie Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nA. Allain C++. Przewodnik dla poczÄ…tkujÄ…cych Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nS. Dasgupta, C. Papadimitriou, U. Vazirani Algorytmy PWN.\n\n\n\n\n\nJ. Krochmalski Docker. Projektowanie i wdraÅ¼anie aplikacji Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nR. McKendrick, S. Gallagher Docker. Programowanie aplikacji dla zaawansowanych. Wydanie II Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\n\n\n\n\n\nP. Bell, B. Beer GitHub. Przyjazny przewodnik (ebook) Zobacz opis lub Kup e-book\n\n\n\n\n\nC. Althoff, Programista Samouk. Profesjonalny przewodnik do samodzielnej nauki kodowania. Zobacz opis lub Kup teraz, Kup e-book\nA. Sweigart, Automatyzacja nudnych zadaÅ„ z pythonem. Zobacz opis lub Kup ksiÄ…Å¼kÄ™, Kup e-book\nK. Reitz, T. Schlusser Przewodnik po Pythonie. Dobre praktyki i praktyczne narzÄ™dzia. Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nB.Tate, L. Carslon, C. Hiibs, Ruby on Rails. Wprowadzenie. Wydanie II Zobacz opis lub Kup e-book\nB. Frain, Responsive Web Design. Projektowanie elastycznych witryn w HTML5 i CSS3, Zobacz opis lub Kup e-book\nK. Beck, TDD. Sztuda tworzenia, Zobacz opis lub Kup teraz, Kup e-book\nB. Dayley, Node.js, MongoDB, AngularJS. Kompendium wiedzy, Zobacz opis lub Kup teraz, Kup e-book\n\n\n\n\n\nA. Jacquier, O. Kondratyev, Quantum Machine Learning and Optimisation in Finance. On the Road to Quantum Advantage."
  },
  {
    "objectID": "ksiazki.html#strony-www",
    "href": "ksiazki.html#strony-www",
    "title": "KsiÄ…Å¼ki i strony WWW",
    "section": "Strony WWW",
    "text": "Strony WWW\n\nSoftware\n\nGithub\nGit-instrukcja\nwww.python.org\nPyPI python libraries\nAnaconda\nDocker\n\n\n\nPakiety python dla analiz danych\n\nNumPy\nSciPy\nPandas\nScikit-learn\nJupyter\nMatplotlib\nBeautiful Soup\nTheano\nKeras\nTensorFlow\nVirtual ENV\n\n\n\nEdytory tekstu\n\nNotepad++\nSublime Text\nVisual Studio Code\n\n\n\nMarkdown\n\nMD\n\n\n\nJupyter notebook\n\nGaleria ciekawych notatnikÃ³w\nIntro\nKernels\nBringing the best out of jupyter for data science\nJupyter extensions\nI donâ€™t like notebooks\nJupyter lab\nSpeed up jupyter notebook\n\n\n\nPrzetwarzanie danych\n\ndata cookbook\n\n\n\nZbiory danych\n\nInternet Archive\nReddit\nKDnuggets\nKaggle\nList of datasets for machine learning research\nUCI Machine Learning Repo\nPublic API\nGoogle Datatset Search\n\n\n\nPython\n\nChris Albon Technical Notes on Using Data Science & AI\n40+ Python Statistics For Data Science Resources\nPractical Business Python\n\n\n\nkursy ML\n\nKurs Machine Learning - Andrew Ng, Stanford\nKurs Machine Learning - Andrew Ng, Stanford\nPython programming for data science"
  },
  {
    "objectID": "wyklad2.html",
    "href": "wyklad2.html",
    "title": "WykÅ‚ad 2",
    "section": "",
    "text": "â³ Czas trwania: 1,5h ğŸ¯ Cel wykÅ‚adu\nzrozumienie, jak dane ewoluowaÅ‚y w rÃ³Å¼nych branÅ¼ach i jakie narzÄ™dzia sÄ… dziÅ› wykorzystywane do ich analizy.\nNa tym wykÅ‚adzie przedstawimy ewolucjÄ™ analizy danych, pokazujÄ…c, jak zmieniaÅ‚y siÄ™ technologie i podejÅ›cia do przetwarzania danych na przestrzeni lat. Rozpoczniemy od klasycznych struktur tabelarycznych, przez bardziej zaawansowane modele grafowe i tekstowe, aÅ¼ po nowoczesne podejÅ›cie do strumieniowego przetwarzania danych."
  },
  {
    "objectID": "wyklad2.html#dane-tabelaryczne-tabele-sql",
    "href": "wyklad2.html#dane-tabelaryczne-tabele-sql",
    "title": "WykÅ‚ad 2",
    "section": "1. Dane tabelaryczne (tabele SQL)",
    "text": "1. Dane tabelaryczne (tabele SQL)\nPoczÄ…tkowo dane byÅ‚y przechowywane w postaci tabel, gdzie kaÅ¼da tabela zawieraÅ‚a zorganizowane informacje w kolumnach i wierszach (np. bazy danych SQL).\nModele takie doskonale nadawaÅ‚y siÄ™ do danych ustrukturyzowanych.\n\nğŸ“Œ Cechy:\nâœ… Dane podzielone na kolumny o staÅ‚ej strukturze.\nâœ… MoÅ¼liwoÅ›Ä‡ stosowania operacji CRUD (Create, Read, Update, Delete).\nâœ… ÅšcisÅ‚e reguÅ‚y spÃ³jnoÅ›ci i normalizacji.\n\n\nğŸ“Œ PrzykÅ‚ady:\nâ¡ï¸ Systemy bankowe, e-commerce, ERP, systemy CRM.\n\n\nğŸ–¥ï¸ PrzykÅ‚adowy kod w Pythonie (SQLite):\nimport sqlite3\nconn = sqlite3.connect(':memory:')\ncursor = conn.cursor()\ncursor.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT, age INTEGER)\")\ncursor.execute(\"INSERT INTO users (name, age) VALUES ('Alice', 30)\")\ncursor.execute(\"SELECT * FROM users\")\nprint(cursor.fetchall())\nconn.close()"
  },
  {
    "objectID": "wyklad2.html#dane-grafowe",
    "href": "wyklad2.html#dane-grafowe",
    "title": "WykÅ‚ad 2",
    "section": "2. Dane grafowe",
    "text": "2. Dane grafowe\nWraz z rozwojem potrzeb biznesowych pojawiÅ‚y siÄ™ dane grafowe, w ktÃ³rych relacje miÄ™dzy obiektami sÄ… reprezentowane jako wierzchoÅ‚ki i krawÄ™dzie.\n\nğŸ“Œ Cechy:\nâœ… Dane opisujÄ…ce relacje i powiÄ…zania.\nâœ… Elastyczna struktura (grafy zamiast tabel).\nâœ… MoÅ¼liwoÅ›Ä‡ analizy poÅ‚Ä…czeÅ„ (np. algorytmy PageRank, centralnoÅ›Ä‡).\n\n\nğŸ“Œ PrzykÅ‚ady:\nâ¡ï¸ Sieci spoÅ‚ecznoÅ›ciowe (Facebook, LinkedIn), wyszukiwarki (Google), systemy rekomendacji (Netflix, Amazon).\n\n\nğŸ–¥ï¸ PrzykÅ‚adowy kod w Pythonie (Graf Karate - NetworkX):\n\n\nCode\nimport networkx as nx\nG = nx.karate_club_graph()\nnx.draw(G, with_labels=True)"
  },
  {
    "objectID": "wyklad2.html#dane-pÃ³Å‚strukturyzowane-json-xml-yaml",
    "href": "wyklad2.html#dane-pÃ³Å‚strukturyzowane-json-xml-yaml",
    "title": "WykÅ‚ad 2",
    "section": "3. Dane pÃ³Å‚strukturyzowane (JSON, XML, YAML)",
    "text": "3. Dane pÃ³Å‚strukturyzowane (JSON, XML, YAML)\nDane te nie sÄ… w peÅ‚ni ustrukturyzowane jak w bazach SQL, ale majÄ… pewien schemat.\n\nğŸ“Œ Cechy:\nâœ… Hierarchiczna struktura (np. klucz-wartoÅ›Ä‡, obiekty zagnieÅ¼dÅ¼one).\nâœ… Brak Å›cisÅ‚ego schematu (moÅ¼liwoÅ›Ä‡ dodawania nowych pÃ³l).\nâœ… PopularnoÅ›Ä‡ w systemach NoSQL i API.\n\n\nğŸ“Œ PrzykÅ‚ady:\nâ¡ï¸ Dokumenty w MongoDB, pliki konfiguracyjne, REST API, pliki logÃ³w.\n\n\nğŸ–¥ï¸ PrzykÅ‚adowy kod w Pythonie (JSON):\n\n\nCode\nimport json\ndata = {'name': 'Alice', 'age': 30, 'city': 'New York'}\njson_str = json.dumps(data)\nprint(json.loads(json_str))\n\n\n{'name': 'Alice', 'age': 30, 'city': 'New York'}"
  },
  {
    "objectID": "wyklad2.html#dane-tekstowe-nlp",
    "href": "wyklad2.html#dane-tekstowe-nlp",
    "title": "WykÅ‚ad 2",
    "section": "4. Dane tekstowe (NLP)",
    "text": "4. Dane tekstowe (NLP)\nTekst staÅ‚ siÄ™ kluczowym ÅºrÃ³dÅ‚em informacji, szczegÃ³lnie w analizie opinii, chatbotach czy wyszukiwarkach.\n\nğŸ“Œ Cechy:\nâœ… Nieustrukturyzowane dane wymagajÄ…ce przeksztaÅ‚cenia.\nâœ… Stosowanie embeddingÃ³w (np. Word2Vec, BERT, GPT).\nâœ… DuÅ¼e zastosowanie w analizie sentymentu i chatbotach.\n\n\nğŸ“Œ PrzykÅ‚ady:\nâ¡ï¸ Media spoÅ‚ecznoÅ›ciowe, e-maile, chatboty, tÅ‚umaczenie maszynowe.\n\n\nğŸ–¥ï¸ PrzykÅ‚adowy kod w Pythonie:\n\n\nCode\nimport ollama\n\n# PrzykÅ‚adowe zdanie\nsentence = \"Sztuczna inteligencja zmienia Å›wiat.\"\nresponse = ollama.embeddings(model='llama3.2', prompt=sentence)\nembedding = response['embedding']\nprint(embedding[:4])\n\n\n[-1.6777262687683105, 3.036857843399048, -6.600795745849609, -1.749084234237671]"
  },
  {
    "objectID": "wyklad2.html#dane-multimedialne-obrazy-dÅºwiÄ™k-wideo",
    "href": "wyklad2.html#dane-multimedialne-obrazy-dÅºwiÄ™k-wideo",
    "title": "WykÅ‚ad 2",
    "section": "5. Dane multimedialne (obrazy, dÅºwiÄ™k, wideo)",
    "text": "5. Dane multimedialne (obrazy, dÅºwiÄ™k, wideo)\nNowoczesne systemy analizy danych wykorzystujÄ… rÃ³wnieÅ¼ obrazy i dÅºwiÄ™k.\n\nğŸ“Œ Cechy:\nâœ… WymagajÄ… duÅ¼ej mocy obliczeniowej (sztuczna inteligencja, deep learning).\nâœ… Przetwarzane przez modele CNN (obrazy) i RNN/Transformers (dÅºwiÄ™k).\n\n\nğŸ“Œ PrzykÅ‚ady:\nâ¡ï¸ Rozpoznawanie twarzy, analiza mowy, biometria, analiza treÅ›ci wideo.\n\n\nğŸ–¥ï¸ PrzykÅ‚adowy kod w Pythonie (Obraz - OpenCV):\nimport cv2\nimage = cv2.imread('cloud.jpeg')\ncv2.waitKey(0)\ncv2.destroyAllWindows()"
  },
  {
    "objectID": "wyklad2.html#dane-strumieniowe",
    "href": "wyklad2.html#dane-strumieniowe",
    "title": "WykÅ‚ad 2",
    "section": "6. Dane strumieniowe",
    "text": "6. Dane strumieniowe\nObecnie najbardziej dynamicznie rozwija siÄ™ analiza danych strumieniowych, gdzie dane sÄ… analizowane na bieÅ¼Ä…co, w miarÄ™ ich napÅ‚ywania.\n\nğŸ“Œ Cechy:\nâœ… Przetwarzanie w czasie rzeczywistym.\nâœ… Wykorzystanie technologii takich jak Apache Kafka, Flink, Spark Streaming.\n\n\nğŸ“Œ PrzykÅ‚ady:\nâ¡ï¸ Transakcje bankowe (detekcja oszustw), analiza social media, IoT.\n\n\nğŸ–¥ï¸ PrzykÅ‚adowy kod w Pythonie (Strumieniowe transakcje bankowe):\n\n\nCode\nimport time\ntransactions = [{'id': 1, 'amount': 100}, {'id': 2, 'amount': 200}]\nfor transaction in transactions:\n    print(f\"Processing transaction: {transaction}\")\n    time.sleep(1)\n\n\nProcessing transaction: {'id': 1, 'amount': 100}\nProcessing transaction: {'id': 2, 'amount': 200}"
  },
  {
    "objectID": "wyklad2.html#dane-sensoryczne-i-iot",
    "href": "wyklad2.html#dane-sensoryczne-i-iot",
    "title": "WykÅ‚ad 2",
    "section": "7. Dane sensoryczne i IoT",
    "text": "7. Dane sensoryczne i IoT\nDane z czujnikÃ³w i urzÄ…dzeÅ„ IoT sÄ… kolejnym krokiem w ewolucji.\n\nğŸ“Œ Cechy:\nâœ… CzÄ™sto pochodzÄ… z miliardÃ³w urzÄ…dzeÅ„ (big data).\nâœ… WymagajÄ… analizy brzegowej (edge computing).\n\n\nğŸ“Œ PrzykÅ‚ady:\nâ¡ï¸ Smart home, wearables, samochody autonomiczne, systemy przemysÅ‚owe.\n\n\nğŸ–¥ï¸ PrzykÅ‚adowy kod w Pythonie (Sensor - temperatura):\n\n\nCode\nimport random\ndef get_temperature():\n    return round(random.uniform(20.0, 25.0), 2)\nprint(f\"Current temperature: {get_temperature()}Â°C\")\n\n\nCurrent temperature: 21.9Â°C"
  },
  {
    "objectID": "wyklad2.html#hadoop-map-reduce-skalowanie-obliczeÅ„-na-big-data",
    "href": "wyklad2.html#hadoop-map-reduce-skalowanie-obliczeÅ„-na-big-data",
    "title": "WykÅ‚ad 2",
    "section": "Hadoop Map-Reduce â€“ Skalowanie obliczeÅ„ na Big Data",
    "text": "Hadoop Map-Reduce â€“ Skalowanie obliczeÅ„ na Big Data\nKiedy mÃ³wimy o skalowalnym przetwarzaniu danych, pierwszym skojarzeniem moÅ¼e byÄ‡ Google.\nAle co tak naprawdÄ™ sprawia, Å¼e moÅ¼emy wyszukiwaÄ‡ informacje w uÅ‚amku sekundy, przetwarzajÄ…c petabajty danych?\nğŸ‘‰ Czy wiesz, Å¼e nazwa â€œGoogleâ€ pochodzi od sÅ‚owa â€œGoogolâ€, czyli liczby rÃ³wnej 10Â¹â°â°?\nTo wiÄ™cej niÅ¼ liczba atomÃ³w w znanym WszechÅ›wiecie! ğŸŒŒ\n\nğŸ”¥ Wyzwanie: Czy uda Ci siÄ™ zapisaÄ‡ liczbÄ™ Googol do koÅ„ca zajÄ™Ä‡?"
  },
  {
    "objectID": "wyklad2.html#dlaczego-sql-i-klasyczne-algorytmy-nie-wystarczajÄ…",
    "href": "wyklad2.html#dlaczego-sql-i-klasyczne-algorytmy-nie-wystarczajÄ…",
    "title": "WykÅ‚ad 2",
    "section": "ğŸ” Dlaczego SQL i klasyczne algorytmy nie wystarczajÄ…?",
    "text": "ğŸ” Dlaczego SQL i klasyczne algorytmy nie wystarczajÄ…?\nTradycyjne bazy danych SQL czy jednowÄ…tkowe algorytmy zawodzÄ…, gdy skala danych przekracza pojedynczy komputer.\nW tym miejscu pojawia siÄ™ MapReduce â€“ rewolucyjny model obliczeniowy stworzony przez Google.\n\nğŸ› ï¸ RozwiÄ…zania Google dla Big Data:\nâœ… Google File System (GFS) â€“ rozproszony system plikÃ³w.\nâœ… Bigtable â€“ system do przechowywania ogromnych iloÅ›ci ustrukturyzowanych danych.\nâœ… MapReduce â€“ algorytm podziaÅ‚u pracy na wiele maszyn."
  },
  {
    "objectID": "wyklad2.html#graficzne-przedstawienie-mapreduce",
    "href": "wyklad2.html#graficzne-przedstawienie-mapreduce",
    "title": "WykÅ‚ad 2",
    "section": "ğŸ–¼ï¸ Graficzne przedstawienie MapReduce",
    "text": "ğŸ–¼ï¸ Graficzne przedstawienie MapReduce\n\n1. Mapowanie rozdziela zadania (Map)\nKaÅ¼de wejÅ›cie dzielone jest na mniejsze czÄ™Å›ci i przetwarzane rÃ³wnolegle.\nğŸŒ WyobraÅº sobie, Å¼e masz ksiÄ…Å¼kÄ™ telefonicznÄ… i chcesz znaleÅºÄ‡ wszystkie osoby o nazwisku â€œNowakâ€.\nâ¡ï¸ Podziel ksiÄ…Å¼kÄ™ na fragmenty i daj kaÅ¼demu do przeanalizowania jeden fragment.\n\n\n2. Redukcja zbiera wyniki (Reduce)\nWszystkie czÄ™Å›ciowe wyniki sÄ… Å‚Ä…czone w jednÄ…, koÅ„cowÄ… odpowiedÅº.\nğŸ”„ Wszyscy uczniowie zgÅ‚aszajÄ… swoje wyniki, a jeden student zbiera i podsumowuje odpowiedÅº."
  },
  {
    "objectID": "wyklad2.html#klasyczny-przykÅ‚ad-liczenie-sÅ‚Ã³w-w-tekÅ›cie",
    "href": "wyklad2.html#klasyczny-przykÅ‚ad-liczenie-sÅ‚Ã³w-w-tekÅ›cie",
    "title": "WykÅ‚ad 2",
    "section": "ğŸ’¡ Klasyczny przykÅ‚ad: Liczenie sÅ‚Ã³w w tekÅ›cie",
    "text": "ğŸ’¡ Klasyczny przykÅ‚ad: Liczenie sÅ‚Ã³w w tekÅ›cie\nZaÅ‚Ã³Å¼my, Å¼e mamy miliony ksiÄ…Å¼ek i chcemy policzyÄ‡, ile razy wystÄ™puje kaÅ¼de sÅ‚owo.\n\nğŸ–¥ï¸ Kod MapReduce w Pythonie (z uÅ¼yciem multiprocessing)\nfrom multiprocessing import Pool\nfrom collections import Counter\n\n# Funkcja Map (podziaÅ‚ tekstu na sÅ‚owa)\ndef map_function(text):\n    words = text.split()\n    return Counter(words)\n\n# Funkcja Reduce (sumowanie wynikÃ³w)\ndef reduce_function(counters):\n    total_count = Counter()\n    for counter in counters:\n        total_count.update(counter)\n    return total_count\n\ntexts = [\n        \"big data is amazing\",\n        \"data science and big data\",\n        \"big data is everywhere\"\n    ]\nif __name__ == '__main__':    \n    with Pool() as pool:\n        mapped_results = pool.map(map_function, texts)\n    \n    final_result = reduce_function(mapped_results)\n    print(final_result)\n\n# Counter({'data': 4, 'big': 3, 'is': 2, 'amazing': 1, 'science': 1, 'and': 1, 'everywhere': 1})\n\n\nğŸ”¹ Co tu siÄ™ dzieje?\nâœ… KaÅ¼dy fragment tekstu jest przetwarzany niezaleÅ¼nie (map).\nâœ… Wyniki sÄ… zbierane i sumowane (reduce).\nâœ… Efekt: MoÅ¼emy przetwarzaÄ‡ terabajty tekstu rÃ³wnolegle!"
  },
  {
    "objectID": "wyklad2.html#wizualizacja-porÃ³wnanie-klasycznego-podejÅ›cia-i-mapreduce",
    "href": "wyklad2.html#wizualizacja-porÃ³wnanie-klasycznego-podejÅ›cia-i-mapreduce",
    "title": "WykÅ‚ad 2",
    "section": "ğŸ¨ Wizualizacja â€“ PorÃ³wnanie klasycznego podejÅ›cia i MapReduce",
    "text": "ğŸ¨ Wizualizacja â€“ PorÃ³wnanie klasycznego podejÅ›cia i MapReduce\nğŸ“Š Stare podejÅ›cie â€“ Jeden komputer wykonuje wszystko sekwencyjnie.\nğŸ“Š Nowe podejÅ›cie (MapReduce) â€“ KaÅ¼da maszyna liczy fragment i wyniki sÄ… agregowane."
  },
  {
    "objectID": "wyklad2.html#wyzwanie-dla-ciebie",
    "href": "wyklad2.html#wyzwanie-dla-ciebie",
    "title": "WykÅ‚ad 2",
    "section": "ğŸš€ Wyzwanie dla Ciebie!",
    "text": "ğŸš€ Wyzwanie dla Ciebie!\nğŸ”¹ ZnajdÅº i uruchom swÃ³j wÅ‚asny algorytm MapReduce w dowolnym jÄ™zyku!\nğŸ”¹ Czy potrafisz zaimplementowaÄ‡ wÅ‚asny MapReduce do innego zadania? (np. analiza logÃ³w, zliczanie klikniÄ™Ä‡ na stronie)"
  },
  {
    "objectID": "wyklad2.html#big-data",
    "href": "wyklad2.html#big-data",
    "title": "WykÅ‚ad 2",
    "section": "Big Data",
    "text": "Big Data\nSystemy Big data mogÄ… byÄ‡ czÄ™Å›ciÄ… (ÅºrÃ³dÅ‚em) dla hurtowni danych (np. Data Lake, Enterprise Data Hub)\nAle Hurtownie danych nie sÄ… systemami Big Data!\n\nHurtownie danych\n\n\nprzetrzymywanie danych wysoko strukturyzowanych\nskupione na analizach i procesie raportowania\n100% accuracy\n\n\nBig Data\n\n\ndane o dowolnej strukturze\nsÅ‚uÅ¼y do rÃ³Å¼norodnych celÃ³w opartych na danych (analityka, data science â€¦)\nponiÅ¼ej 100% accuracy\n\n\n,,Big Data is like teenage sex: everyone talks about it, nobody really knows how to do it, everyone thinks everyone else is doing it, so every one claims they are doing it.â€™â€™ â€” Dan Ariely, Professor of Psychology and Behavioral Economics, Duke University\n\n\none, two, â€¦ four V\n\nVolume (ObjÄ™toÅ›Ä‡) - rozmiar danych produkowanych na caÅ‚ym Å›wiecie przyrasta w tempie wykÅ‚adniczym.\nVelocity (SzybkoÅ›Ä‡) - tempo produkowania danych, szybkoÅ›ci ich przesyÅ‚ania i przetwarzania.\nVariety (ZrÃ³Å¼nicowanie) - tradycyjne dane kojarzÄ… siÄ™ nam z postaciÄ… alfanumerycznÄ… zÅ‚oÅ¼onÄ… z liter i cyfr. Obecnie mamy do dyspozycji obrazy, dÅºwiÄ™ki, pliki wideo, strumienie danych z IoT\nVeracity (WiarygodnoÅ›Ä‡) - Czy dane sÄ… kompletne i poprawne? Czy obiektywnie odzwierciedlajÄ… rzeczywistoÅ›Ä‡? Czy sÄ… podstawÄ… do podejmowania decyzji?\nValue - The value that the data actually holds. In the end, itâ€™s all about cost and benefits.\n\n\nCelem obliczeÅ„ nie sÄ… liczby, lecz ich zrozumienie R.W. Hamming 1962."
  },
  {
    "objectID": "wyklad2.html#modele-przetwarzania-danych",
    "href": "wyklad2.html#modele-przetwarzania-danych",
    "title": "WykÅ‚ad 2",
    "section": "Modele przetwarzania danych",
    "text": "Modele przetwarzania danych\nDane w biznesie przetwarzane sÄ… praktycznie od zawsze. W ciÄ…gu ostatnich dziesiÄ™cioleci iloÅ›Ä‡ przetwarzanych danych systematycznie roÅ›nie co wpÅ‚ywa na proces przygotowania i przetwarzania danych.\n\nTrochÄ™ historii\n\nLata 60-te : Kolekcje danych, bazy danych\nLata 70-te : Relacyjne modele danych i ich implementacja w systemach OLTP\n1975 : Pierwsze komputery osobiste\nLata 80-te : Zaawansowane modele danych, extended-relational, objective oriented, aplikacyjno-zorientowane itp.\n1983 : PoczÄ…tek internetu\nLata 90-te : Data mining, hurtownie danych, systemy OLAP\nPÃ³Åºniej : NoSQL, Hadoop, SPARK, data lake\n2002 : AWS , 2005: Hadoop, Cloud computing\n\nWiÄ™kszoÅ›Ä‡ danych przechowywana jest w bazach lub hurtowniach danych. Standardowo dostÄ™p do danych sprowadza siÄ™ najczÄ™Å›ciej do realizacji zapytaÅ„ poprzez aplikacjÄ™.\nSposÃ³b wykorzystania i realizacji procesu dostÄ™pu do bazy danych nazywamy modelem przetwarzania. NajczÄ™Å›ciej uÅ¼ywane sÄ… dwie implementacje:\n\n\nModel Tradycyjny\nModel tradycyjny - przetwarzanie transakcyjne w trybie on-line, OLTP (on-line transaction processing). Åšwietnie sprawdza siÄ™ w przypadku obsÅ‚ugi bieÅ¼Ä…cej np. obsÅ‚uga klienta, rejestr zamÃ³wieÅ„, obsÅ‚uga sprzedaÅ¼y itp. Wykorzystywany w systemach Enterprise Resource Planning (ERP) Systems, Customer Relationship Management (CRM) software, and web-based applications.\n\nModel ten dostarcza efektywnych rozwiÄ…zaÅ„ m.in do:\n\nefektywnego i bezpiecznego przechowywania danych,\ntransakcyjnego odtwarzanie danych po awarii,\noptymalizacji dostÄ™pu do danych,\nzarzÄ…dzania wspÃ³Å‚bieÅ¼noÅ›ciÄ…,\nprzetwarzania zdarzeÅ„ -&gt; odczyt -&gt; zapis\n\nCo w przypadku gdy mamy do czynienia z:\n\nagregacjami danych z wielu systemÃ³w (np. dla wielu sklepÃ³w),\nraportowanie i podsumowania danych,\noptymalizacja zÅ‚oÅ¼onych zapytaÅ„,\nwspomaganie decyzji biznesowych.\n\nBadania nad tego typu zagadnieniami doprowadziÅ‚y do sformuÅ‚owania nowego modelu przetwarzania danych oraz nowego typu baz danych - Hurtownie Danych (Data warehouse).\n\n\nModel OLAP\nPrzetwarzanie analityczne on-line OLAP (on-line analytic processing).\nWspieranie procesÃ³w analizy i dostarczanie narzÄ™dzi umoÅ¼liwiajÄ…cych analizÄ™ wielowymiarowÄ… (czas, miejsce, produkt).\nProces zrzucania danych z rÃ³Å¼nych systemÃ³w do jednej bazy nazywamy Extract-Transform-Load (ETL) (normalizacja i encoding and schema transaction).\nAnaliza danych z hurtowni to przede wszystkim obliczanie agregatÃ³w (podsumowaÅ„) dotyczÄ…cych wymiarÃ³w hurtowni. Proces ten jest caÅ‚kowicie sterowany przez uÅ¼ytkownika.\nPrzykÅ‚ad\nZaÅ‚Ã³Å¼my, Å¼e mamy dostÄ™p do hurtowni danych gdzie przechowywane sÄ… informacje dotyczÄ…ce sprzedaÅ¼y produktÃ³w w supermarkecie. Jak przeanalizowaÄ‡ zapytania:\n\nJaka jest Å‚Ä…czna sprzedaÅ¼ produktÃ³w w kolejnych kwartaÅ‚ach, miesiÄ…cach, tygodniach ?\nJaka jest sprzedaÅ¼ produktÃ³w z podziaÅ‚em na rodzaje produktÃ³w ?\nJaka jest sprzedaÅ¼ produktÃ³w z podziaÅ‚em na oddziaÅ‚y supermarketu ?\n\nOdpowiedzi na te pytania pozwalajÄ… okreÅ›liÄ‡ wÄ…skie gardÅ‚a sprzedaÅ¼y produktÃ³w przynoszÄ…cych deficyt, zaplanowaÄ‡ zapasy w magazynach czy porÃ³wnaÄ‡ sprzedaÅ¼ rÃ³Å¼nych grup w rÃ³Å¼nych oddziaÅ‚ach supermarketu.\nW ramach Hurtowni Danych najczÄ™Å›ciej wykonuje siÄ™ dwa rodzaje zapytaÅ„(oba w trybie batchowym): 1. Wykonywane okresowo w czasie zapytania raportowe obliczajÄ…ce biznesowe statystyki 2. Wykonywane ad-hoc zapytania wspomagajÄ…ce krytyczne decyzje biznesowe."
  },
  {
    "objectID": "wyklad2.html#definicje",
    "href": "wyklad2.html#definicje",
    "title": "WykÅ‚ad 2",
    "section": "Definicje",
    "text": "Definicje\n\nZapoznaj siÄ™ z tematem danych strumieniowych\n\nDefinicja 1 â€“ Zdarzenie to wszystko, co moÅ¼na zaobserwowaÄ‡ w danym momencie czasu. Jest generowane jako bezpoÅ›redni skutek dziaÅ‚ania.\nDefinicja 2 â€“ W kontekÅ›cie danych zdarzenie to niezmienialny rekord w strumieniu danych, zakodowany jako JSON, XML, CSV lub w formacie binarnym.\nDefinicja 3 â€“ CiÄ…gÅ‚y strumieÅ„ zdarzeÅ„ to nieskoÅ„czony zbiÃ³r pojedynczych zdarzeÅ„ uporzÄ…dkowanych w czasie, np. logi z urzÄ…dzeÅ„.\nDefinicja 4 â€“ StrumieÅ„ danych to dane tworzone przyrostowo w czasie, generowane ze ÅºrÃ³deÅ‚ statycznych (baza danych, odczyt linii z pliku) lub dynamicznych (logi, sensory, funkcje).\nPrzedsiÄ™biorstwo to organizacja, ktÃ³ra generuje i odpowiada na ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„.\n\n\n\n\nAnalityka strumieniowa\nAnalityka strumieniowa (ang. stream analytics) nazywana jest rÃ³wnieÅ¼ przetwarzaniem strumieniowym zdarzeÅ„ (ang. event stream processing) â€“ czyli przetwarzaniem duÅ¼ych iloÅ›ci danych juÅ¼ na etapie ich generowania.\nNiezaleÅ¼nie od zastosowanej technologii, wszystkie dane powstajÄ… jako ciÄ…gÅ‚y strumieÅ„ zdarzeÅ„ â€“ obejmuje to m.in.:\n- dziaÅ‚ania uÅ¼ytkownikÃ³w na stronach internetowych,\n- logi systemowe,\n- pomiary z sensorÃ³w."
  },
  {
    "objectID": "wyklad2.html#czas-w-analizie-danych-w-czasie-rzeczywistym",
    "href": "wyklad2.html#czas-w-analizie-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 2",
    "section": "Czas w analizie danych w czasie rzeczywistym",
    "text": "Czas w analizie danych w czasie rzeczywistym\nW przypadku przetwarzania wsadowego analizujemy dane historyczne, a czas uruchomienia procesu nie ma Å¼adnego zwiÄ…zku z momentem wystÄ…pienia analizowanych zdarzeÅ„.\nNatomiast w przetwarzaniu strumieniowym wyrÃ³Å¼niamy dwie koncepcje czasu: 1. Czas zdarzenia (event time) â€“ moment, w ktÃ³rym zdarzenie faktycznie miaÅ‚o miejsce. 2. Czas przetwarzania (processing time) â€“ moment, w ktÃ³rym system przetwarza zdarzenie.\nIdealne przetwarzanie danych\nW idealnej sytuacji przetwarzanie nastÄ™puje natychmiast po wystÄ…pieniu zdarzenia:\n\nRzeczywiste przetwarzanie danych\nW praktyce przetwarzanie danych zawsze odbywa siÄ™ z pewnym opÃ³Åºnieniem, co jest widoczne jako punkty poniÅ¼ej linii idealnego przetwarzania (poniÅ¼ej przekÄ…tnej na wykresie).\n\nW aplikacjach przetwarzania strumieniowego istotna jest rÃ³Å¼nica miÄ™dzy czasem powstania zdarzenia a czasem jego przetwarzania. Do najczÄ™stszych przyczyn opÃ³ÅºnieÅ„ naleÅ¼Ä…:\n\nprzesyÅ‚anie danych przez sieÄ‡,\nbrak komunikacji miÄ™dzy urzÄ…dzeniem a sieciÄ….\n\nPrzykÅ‚adem jest Å›ledzenie poÅ‚oÅ¼enia samochodu przez aplikacjÄ™ GPS â€“ przejazd przez tunel moÅ¼e spowodowaÄ‡ chwilowÄ… utratÄ™ danych.\nObsÅ‚uga opÃ³ÅºnieÅ„ w przetwarzaniu strumieniowym\nOpÃ³Åºnienia w przetwarzaniu zdarzeÅ„ moÅ¼na obsÅ‚uÅ¼yÄ‡ na dwa sposoby: 1. Monitorowanie liczby pominiÄ™tych zdarzeÅ„ i wyzwalanie alarmu w przypadku zbyt duÅ¼ej liczby odrzuceÅ„. 2. Zastosowanie korekty za pomocÄ… watermarkingu, czyli dodatkowego mechanizmu uwzglÄ™dniajÄ…cego opÃ³Åºnione zdarzenia.\nProces przetwarzania zdarzeÅ„ w czasie rzeczywistym moÅ¼na przedstawiÄ‡ jako funkcjÄ™ schodkowÄ…:\n\nNie wszystkie zdarzenia wnoszÄ… wkÅ‚ad do analizy â€“ niektÃ³re mogÄ… zostaÄ‡ odrzucone ze wzglÄ™du na zbyt duÅ¼e opÃ³Åºnienie.\nWykorzystanie watermarkingu pozwala na uwzglÄ™dnienie dodatkowego czasu na pojawienie siÄ™ opÃ³Åºnionych zdarzeÅ„. Proces ten obejmuje wszystkie zdarzenia powyÅ¼ej przerywanej linii. Mimo to nadal mogÄ… zdarzyÄ‡ siÄ™ przypadki, w ktÃ³rych niektÃ³re punkty zostanÄ… pominiÄ™te.\n\nPrzedstawione na wykresach sytuacje jawnie wskazujÄ… dlaczego pojÄ™cie czasu jest istotnym czynnikiem i wymaga Å›cisÅ‚ego okreÅ›lenia juÅ¼ na poziomie definiowania potrzeb biznesowych. Przypisywanie znacznikÃ³w czasu do danych (zdarzeÅ„) to trudne zadanie."
  },
  {
    "objectID": "wyklad2.html#okna-czasowe-w-analizie-strumieniowej",
    "href": "wyklad2.html#okna-czasowe-w-analizie-strumieniowej",
    "title": "WykÅ‚ad 2",
    "section": "Okna czasowe w analizie strumieniowej",
    "text": "Okna czasowe w analizie strumieniowej\nW przetwarzaniu strumieniowym okna czasowe pozwalajÄ… na grupowanie danych w ograniczone czasowo segmenty, co umoÅ¼liwia analizÄ™ zdarzeÅ„ w okreÅ›lonych przedziaÅ‚ach czasowych. W zaleÅ¼noÅ›ci od zastosowania stosuje siÄ™ rÃ³Å¼ne typy okien, dostosowane do charakterystyki danych i wymagaÅ„ analitycznych.\n\n\n1. Okno rozÅ‚Ä…czne (Tumbling Window)\nJest to okno o staÅ‚ej dÅ‚ugoÅ›ci, ktÃ³re nie nakÅ‚ada siÄ™ na siebie â€“ kaÅ¼de zdarzenie naleÅ¼y tylko do jednego okna.\nâœ… Charakterystyka:\n- StaÅ‚a dÅ‚ugoÅ›Ä‡ okna\n- Brak nakÅ‚adania siÄ™ na siebie\n- Idealne do podziaÅ‚u danych na rÃ³wne segmenty czasowe\nğŸ“Œ PrzykÅ‚ad: Analiza liczby zamÃ³wieÅ„ w sklepie internetowym co 5 minut.\n\n\n\n\n2. Okno przesuwne (Sliding Window)\nObejmuje wszystkie zdarzenia nastÄ™pujÄ…ce w okreÅ›lonym przedziale czasu, gdzie okno przesuwa siÄ™ w sposÃ³b ciÄ…gÅ‚y.\nâœ… Charakterystyka:\n- KaÅ¼de zdarzenie moÅ¼e naleÅ¼eÄ‡ do kilku okien\n- Okno przesuwa siÄ™ o zadany interwaÅ‚\n- Przydatne do wykrywania trendÃ³w i anomalii\nğŸ“Œ PrzykÅ‚ad: Åšledzenie Å›redniej temperatury w ciÄ…gu ostatnich 10 minut, aktualizowane co 2 minuty.\n\n\n\n\n3. Okno skokowe (Hopping Window)\nJest podobne do okna rozÅ‚Ä…cznego, ale pozwala na nakÅ‚adanie siÄ™ okien na siebie, dziÄ™ki czemu jedno zdarzenie moÅ¼e naleÅ¼eÄ‡ do kilku okien. Jest stosowane do wygÅ‚adzania danych.\nâœ… Charakterystyka:\n- StaÅ‚a dÅ‚ugoÅ›Ä‡ okna\n- MoÅ¼liwoÅ›Ä‡ nakÅ‚adania siÄ™ na siebie\n- Przydatne do redukcji szumÃ³w w danych\nğŸ“Œ PrzykÅ‚ad: Analiza liczby odwiedzajÄ…cych stronÄ™ co 10 minut, ale aktualizowana co 5 minut, aby lepiej wychwytywaÄ‡ trendy.\n\n\n\n\n4. Okno sesyjne (Session Window)\nOkno sesyjne grupuje zdarzenia na podstawie okresÃ³w aktywnoÅ›ci i zamyka siÄ™ po okreÅ›lonym czasie braku aktywnoÅ›ci.\nâœ… Charakterystyka:\n- Dynamiczna dÅ‚ugoÅ›Ä‡ okna\n- Definiowane przez aktywnoÅ›Ä‡ uÅ¼ytkownika\n- Stosowane w analizie sesji uÅ¼ytkownikÃ³w\nğŸ“Œ PrzykÅ‚ad: Analiza sesji uÅ¼ytkownikÃ³w na stronie internetowej â€“ sesja trwa tak dÅ‚ugo, jak dÅ‚ugo uÅ¼ytkownik wykonuje akcje, ale koÅ„czy siÄ™ po 15 minutach braku aktywnoÅ›ci.\n\n\n\nPodsumowanie\nRÃ³Å¼ne rodzaje okien czasowych sÄ… stosowane w zaleÅ¼noÅ›ci od specyfiki danych i celÃ³w analizy. WybÃ³r odpowiedniego okna wpÅ‚ywa na dokÅ‚adnoÅ›Ä‡ wynikÃ³w i efektywnoÅ›Ä‡ systemu analitycznego.\n\n\n\n\n\n\n\n\nTyp okna\nCharakterystyka\nZastosowanie\n\n\n\n\nRozÅ‚Ä…czne (Tumbling)\nStaÅ‚a dÅ‚ugoÅ›Ä‡, brak nakÅ‚adania\nRaporty okresowe\n\n\nPrzesuwne (Sliding)\nStaÅ‚a dÅ‚ugoÅ›Ä‡, nakÅ‚adajÄ…ce siÄ™ okna\nTrendy, wykrywanie anomalii\n\n\nSkokowe (Hopping)\nStaÅ‚a dÅ‚ugoÅ›Ä‡, czÄ™Å›ciowe nakÅ‚adanie\nWygÅ‚adzanie danych\n\n\nSesyjne (Session)\nDynamiczna dÅ‚ugoÅ›Ä‡, zaleÅ¼na od aktywnoÅ›ci\nAnaliza sesji uÅ¼ytkownikÃ³w\n\n\n\nKaÅ¼dy typ okna ma swoje unikalne zastosowania i pomaga w lepszej interpretacji danych strumieniowych. WybÃ³r wÅ‚aÅ›ciwej metody zaleÅ¼y od potrzeb biznesowych i charakterystyki analizowanych danych.\nW analizie danych strumieniowych interpretacja czasu jest zÅ‚oÅ¼onym zagadnieniem, poniewaÅ¼: 1. RÃ³Å¼ne systemy majÄ… rÃ³Å¼ne zegary, co moÅ¼e prowadziÄ‡ do niespÃ³jnoÅ›ci, 2. Dane mogÄ… docieraÄ‡ z opÃ³Åºnieniem, co wymaga technik watermarkingu i okien czasowych, 3. RÃ³Å¼ne podejÅ›cia do analizy czasu zdarzenia i czasu przetwarzania wpÅ‚ywajÄ… na dokÅ‚adnoÅ›Ä‡ wynikÃ³w."
  },
  {
    "objectID": "wyklad1.html",
    "href": "wyklad1.html",
    "title": "WykÅ‚ad 1",
    "section": "",
    "text": "â³ Czas trwania: 1,5h\nğŸ¯ Cel wykÅ‚adu\nZapoznanie studentÃ³w z podstawami real-time analytics, rÃ³Å¼nicami miÄ™dzy trybami przetwarzania danych (batch, streaming, real-time) oraz kluczowymi zastosowaniami i wyzwaniami."
  },
  {
    "objectID": "wyklad1.html#czym-jest-analiza-danych-w-czasie-rzeczywistym",
    "href": "wyklad1.html#czym-jest-analiza-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 1",
    "section": "Czym jest analiza danych w czasie rzeczywistym?",
    "text": "Czym jest analiza danych w czasie rzeczywistym?\n\nDefinicja i kluczowe koncepcje\nAnaliza danych w czasie rzeczywistym (ang. Real-Time Data Analytics) to proces przetwarzania i analizy danych natychmiast po ich wygenerowaniu, bez koniecznoÅ›ci przechowywania i oczekiwania na pÃ³Åºniejsze przetworzenie. Celem jest uzyskanie natychmiastowych wnioskÃ³w i reakcji na zmieniajÄ…ce siÄ™ warunki w systemach biznesowych, technologicznych i naukowych.\n\n\nKluczowe cechy analizy danych w czasie rzeczywistym:\n\nNiska latencja (ang. low-latency) â€“ dane sÄ… analizowane w ciÄ…gu milisekund lub sekund od ich wygenerowania.\nStreaming vs.Â Batch Processing â€“ analiza danych moÅ¼e odbywaÄ‡ siÄ™ w sposÃ³b ciÄ…gÅ‚y (streaming) lub w z gÃ³ry okreÅ›lonych interwaÅ‚ach (batch).\nIntegracja z IoT, AI i ML â€“ real-time analytics czÄ™sto wspÃ³Å‚pracuje z Internetem Rzeczy (IoT) oraz algorytmami sztucznej inteligencji.\nPodejmowanie decyzji w czasie rzeczywistym â€“ np. natychmiastowa detekcja oszustw w transakcjach bankowych."
  },
  {
    "objectID": "wyklad1.html#zastosowanie-analizy-danych-w-czasie-rzeczywistym-w-biznesie",
    "href": "wyklad1.html#zastosowanie-analizy-danych-w-czasie-rzeczywistym-w-biznesie",
    "title": "WykÅ‚ad 1",
    "section": "Zastosowanie analizy danych w czasie rzeczywistym w biznesie",
    "text": "Zastosowanie analizy danych w czasie rzeczywistym w biznesie\n\nFinanse i bankowoÅ›Ä‡\n\nWykrywanie oszustw â€“ analiza transakcji w czasie rzeczywistym pozwala na wykrycie anomalii wskazujÄ…cych na oszustwa.\nAutomatyczny trading â€“ systemy HFT (High-Frequency Trading) analizujÄ… miliony danych w uÅ‚amkach sekundy.\nDynamiczne oceny kredytowe â€“ natychmiastowa analiza ryzyka kredytowego klienta.\n\n\n\nE-commerce i marketing cyfrowy\n\nPersonalizacja ofert w czasie rzeczywistym â€“ dynamiczne rekomendacje produktÃ³w na podstawie aktualnego zachowania uÅ¼ytkownika.\nDynamiczne ceny â€“ np. Uber, Amazon i hotele stosujÄ… dynamiczne ustalanie cen na podstawie popytu.\nMonitorowanie mediÃ³w spoÅ‚ecznoÅ›ciowych â€“ analiza nastrojÃ³w klientÃ³w i natychmiastowa reakcja na negatywne komentarze.\n\n\n\nTelekomunikacja i IoT\n\nMonitorowanie infrastruktury sieciowej â€“ analiza logÃ³w w czasie rzeczywistym pozwala na wykrywanie awarii przed ich wystÄ…pieniem.\nSmart Cities â€“ analiza ruchu drogowego i natychmiastowa optymalizacja sygnalizacji Å›wietlnej.\nAnalityka IoT â€“ urzÄ…dzenia IoT generujÄ… strumienie danych, ktÃ³re moÅ¼na analizowaÄ‡ w czasie rzeczywistym (np. inteligentne liczniki energii).\n\n\n\nOchrona zdrowia\n\nMonitorowanie pacjentÃ³w â€“ analiza sygnaÅ‚Ã³w z urzÄ…dzeÅ„ medycznych w celu natychmiastowego wykrycia zagroÅ¼enia Å¼ycia.\nAnalityka epidemiologiczna â€“ Å›ledzenie rozprzestrzeniania siÄ™ chorÃ³b na podstawie danych w czasie rzeczywistym.\n\nAnaliza danych w czasie rzeczywistym to kluczowy element nowoczesnych systemÃ³w informatycznych, ktÃ³ry umoÅ¼liwia firmom podejmowanie decyzji szybciej i bardziej precyzyjnie. Jest wykorzystywana w wielu branÅ¼ach â€“ od finansÃ³w, przez e-commerce, aÅ¼ po ochronÄ™ zdrowia i IoT."
  },
  {
    "objectID": "wyklad1.html#rÃ³Å¼nice-miÄ™dzy-batch-processing-near-real-time-analytics-real-time-analytics",
    "href": "wyklad1.html#rÃ³Å¼nice-miÄ™dzy-batch-processing-near-real-time-analytics-real-time-analytics",
    "title": "WykÅ‚ad 1",
    "section": "RÃ³Å¼nice miÄ™dzy Batch Processing, Near Real-Time Analytics, Real-Time Analytics",
    "text": "RÃ³Å¼nice miÄ™dzy Batch Processing, Near Real-Time Analytics, Real-Time Analytics\nIstniejÄ… trzy gÅ‚Ã³wne podejÅ›cia do przetwarzania informacji:\n\nBatch Processing (Przetwarzanie wsadowe)\nNear Real-Time Analytics (Analiza niemal w czasie rzeczywistym)\nReal-Time Analytics (Analiza w czasie rzeczywistym)\n\nKaÅ¼de z nich rÃ³Å¼ni siÄ™ szybkoÅ›ciÄ… przetwarzania, wymaganiami technologicznymi oraz zastosowaniami biznesowymi.\n\nBatch Processing â€“ Przetwarzanie wsadowe\nğŸ“Œ Definicja:\nBatch Processing polega na zbieraniu duÅ¼ych iloÅ›ci danych i ich przetwarzaniu w okreÅ›lonych odstÄ™pach czasu (np. co godzinÄ™, codziennie, co tydzieÅ„).\nğŸ“Œ Cechy:\n\nâœ… Wysoka wydajnoÅ›Ä‡ dla duÅ¼ych zbiorÃ³w danych\nâœ… Przetwarzanie danych po ich zgromadzeniu\nâœ… Nie wymaga natychmiastowej analizy\nâœ… Zwykle taÅ„sze niÅ¼ przetwarzanie w czasie rzeczywistym\nâŒ OpÃ³Åºnienia â€“ wyniki sÄ… dostÄ™pne dopiero po zakoÅ„czeniu przetwarzania\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nGenerowanie raportÃ³w finansowych na koniec dnia/miesiÄ…ca\nAnaliza trendÃ³w sprzedaÅ¼y na podstawie historycznych danych\nTworzenie modeli uczenia maszynowego offline\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nHadoop MapReduce\nApache Spark (w trybie batch)\nGoogle BigQuery\n\nimport pandas as pd  \ndf = pd.read_csv(\"transactions.csv\")  \n\ndf['transaction_date'] = pd.to_datetime(df['transaction_date'])\ndf['month'] = df['transaction_date'].dt.to_period('M')  # Ekstrakcja miesiÄ…ca\n\n# Agregacja danych - miesiÄ™czne sumy transakcji\nmonthly_sales = df.groupby(['month'])['amount'].sum()\n\n# Zapis wynikÃ³w do pliku (np. raportu)\nmonthly_sales.to_csv(\"monthly_report.csv\")  \n\nprint(\"Raport zapisany!\")\nGdybyÅ› chciaÅ‚ utworzyÄ‡ dane do przykÅ‚adu\nimport pandas as pd\nimport numpy as np\n\nnp.random.seed(42)\ndata = {\n    'transaction_id': [f'TX{str(i).zfill(4)}' for i in range(1, 1001)],\n    'amount': np.random.uniform(10, 10000, 1000), \n    'transaction_date': pd.date_range(start=\"2025-01-01\", periods=1000, freq='h'), \n    'merchant': np.random.choice(['Merchant_A', 'Merchant_B', 'Merchant_C', 'Merchant_D'], 1000),\n    'card_type': np.random.choice(['Visa', 'MasterCard', 'AmEx'], 1000)\n}\n\ndf = pd.DataFrame(data)\ncsv_file = 'transactions.csv'\ndf.to_csv(csv_file, index=False)\n\n\nNear Real-Time Analytics â€“ Analiza niemal w czasie rzeczywistym\nğŸ“Œ Definicja:\nNear Real-Time Analytics to analiza danych, ktÃ³ra odbywa siÄ™ z minimalnym opÃ³Åºnieniem (zazwyczaj od kilku sekund do kilku minut). Jest stosowana tam, gdzie peÅ‚na analiza w czasie rzeczywistym nie jest konieczna, ale zbyt duÅ¼e opÃ³Åºnienia mogÄ… wpÅ‚ynÄ…Ä‡ na biznes.\nğŸ“Œ Cechy:\n\nâœ… Przetwarzanie danych w krÃ³tkich odstÄ™pach czasu (kilka sekund â€“ minut)\nâœ… UmoÅ¼liwia szybkie podejmowanie decyzji, ale nie wymaga reakcji w milisekundach\nâœ… Optymalny balans miÄ™dzy kosztami a szybkoÅ›ciÄ…\nâŒ Nie nadaje siÄ™ do systemÃ³w wymagajÄ…cych natychmiastowej reakcji\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nMonitorowanie transakcji bankowych i wykrywanie oszustw (np. analiza w ciÄ…gu 30 sekund)\nDynamiczne dostosowywanie reklam online na podstawie zachowaÅ„ uÅ¼ytkownikÃ³w\nAnaliza logÃ³w serwerÃ³w i sieci w celu wykrycia anomalii\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nApache Kafka + Spark Streaming\nElasticsearch + Kibana (np. analiza logÃ³w IT)\nAmazon Kinesis\n\nPrzykÅ‚ad producenta danych realizujÄ…cego tranzakcje wysyÅ‚ane do systemu Apache Kafka.\nfrom kafka import KafkaProducer\nimport json\nimport random\nimport time\nfrom datetime import datetime\n\n# Ustawienia dla producenta\nbootstrap_servers = 'localhost:9092'\ntopic = 'transactions' \n\n# Funkcja generujÄ…ca przykÅ‚adowe dane transakcji\ndef generate_transaction():\n    transaction = {\n        'transaction_id': f'TX{random.randint(1000, 9999)}',\n        'amount': round(random.uniform(10, 10000), 2),  # Kwota miÄ™dzy 10 a 10 000\n        'transaction_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n        'merchant': random.choice(['Merchant_A', 'Merchant_B', 'Merchant_C', 'Merchant_D']),\n        'card_type': random.choice(['Visa', 'MasterCard', 'AmEx']),\n    }\n    return transaction\n\nproducer = KafkaProducer(\n    bootstrap_servers=bootstrap_servers,\n    value_serializer=lambda v: json.dumps(v).encode('utf-8') \n)\n\n\nfor _ in range(1000):  \n    transaction = generate_transaction()\n    producer.send(topic, value=transaction) \n    print(f\"Sent: {transaction}\")\n    time.sleep(1) \n\n# ZakoÅ„czenie dziaÅ‚ania producenta\nproducer.flush()\nproducer.close()\nPrzykÅ‚ad consumenta - programu sparawdzajÄ…cego zbyt duÅ¼e transakcje\nfrom kafka import KafkaConsumer\nimport json  \n\n# Konsumer do pobierania danych z Kafka\nconsumer = KafkaConsumer(\n    'transactions',\n    bootstrap_servers='localhost:9092',\n    auto_offset_reset='earliest',\n    value_deserializer=lambda x: json.loads(x.decode('utf-8'))\n)\n\n# Pobieranie transakcji w niemal real-time i analiza\nfor message in consumer:\n    transaction = message.value\n    if transaction[\"amount\"] &gt; 8000:\n        print(f\"ğŸš¨ Wykryto duÅ¼Ä… transakcjÄ™: {transaction}\")\nPrzykÅ‚adowy zestaw danych\n{\n    \"transaction_id\": \"TX1234\",\n    \"amount\": 523.47,\n    \"transaction_date\": \"2025-02-11 08:10:45\",\n    \"merchant\": \"Merchant_A\",\n    \"card_type\": \"Visa\"\n}\n\n\nReal-Time Analytics â€“ Analiza w czasie rzeczywistym\nğŸ“Œ Definicja:\nReal-Time Analytics to natychmiastowa analiza danych i podejmowanie decyzji w uÅ‚amku sekundy (milisekundy do jednej sekundy). Wykorzystywana w systemach wymagajÄ…cych reakcji w czasie rzeczywistym, np. w transakcjach gieÅ‚dowych, systemach IoT czy cyberbezpieczeÅ„stwie.\nğŸ“Œ Cechy:\n\nâœ… Bardzo niskie opÃ³Åºnienie (milliseconds-seconds)\nâœ… UmoÅ¼liwia natychmiastowÄ… reakcjÄ™ systemu\nâœ… Wymaga wysokiej mocy obliczeniowej i skalowalnej architektury\nâŒ DroÅ¼sze i bardziej zÅ‚oÅ¼one technologicznie niÅ¼ batch processing\n\nğŸ“Œ PrzykÅ‚ady zastosowaÅ„:\n\nHigh-Frequency Trading (HFT) â€“ analiza i podejmowanie decyzji w transakcjach gieÅ‚dowych w milisekundach\nAutonomiczne samochody â€“ analiza strumieni danych z kamer i sensorÃ³w w czasie rzeczywistym\nCyberbezpieczeÅ„stwo â€“ detekcja atakÃ³w w sieciach komputerowych w uÅ‚amku sekundy\nAnalityka IoT â€“ np. natychmiastowa detekcja anomalii w danych z czujnikÃ³w przemysÅ‚owych\n\nğŸ“Œ PrzykÅ‚adowe technologie:\n\nApache Flink\nApache Storm\nGoogle Dataflow\n\nğŸ” PorÃ³wnanie:\n\n\n\n\n\n\n\n\n\nCecha\nBatch Processing\nNear Real-Time Analytics\nReal-Time Analytics\n\n\n\n\nOpÃ³Åºnienie\nMinuty â€“ godziny â€“ dni\nSekundy â€“ minuty\nMilisekundy â€“ sekundy\n\n\nTyp przetwarzania\nWsadowe (offline)\nStrumieniowe (ale nie w peÅ‚ni natychmiastowe)\nStrumieniowe (prawdziwy real-time)\n\n\nKoszt infrastruktury\nğŸ“‰ Niski\nğŸ“ˆ Åšredni\nğŸ“ˆğŸ“ˆ Wysoki\n\n\nZÅ‚oÅ¼onoÅ›Ä‡ implementacji\nğŸ“‰ Prosta\nğŸ“ˆ Åšrednia\nğŸ“ˆğŸ“ˆ Trudna\n\n\nPrzykÅ‚ady zastosowaÅ„\nRaporty, ML offline, analizy historyczne\nMonitorowanie transakcji, dynamiczne reklamy\nHFT, IoT, detekcja oszustw w czasie rzeczywistym\n\n\n\nğŸ“Œ Kiedy stosowaÄ‡ Batch Processing?\n\nâœ… Gdy nie wymagasz natychmiastowej analizy\nâœ… Gdy masz duÅ¼e iloÅ›ci danych, ale przetwarzane sÄ… one okresowo\nâœ… Gdy chcesz obniÅ¼yÄ‡ koszty\n\nğŸ“Œ Kiedy stosowaÄ‡ Near Real-Time Analytics?\n\nâœ… Gdy wymagasz analizy w krÃ³tkim czasie (sekundy â€“ minuty)\nâœ… Gdy potrzebujesz bardziej aktualnych danych, ale nie w peÅ‚nym real-time\nâœ… Gdy szukasz kompromisu miÄ™dzy wydajnoÅ›ciÄ… a kosztami\n\nğŸ“Œ Kiedy stosowaÄ‡ Real-Time Analytics?\n\nâœ… Gdy kaÅ¼da milisekunda ma znaczenie (np. gieÅ‚da, autonomiczne pojazdy)\nâœ… Gdy chcesz wykrywaÄ‡ oszustwa, anomalie lub incydenty natychmiast\nâœ… Gdy system musi natychmiast reagowaÄ‡ na zdarzenia\n\nReal-time analytics nie zawsze jest konieczne â€“ w wielu przypadkach near real-time jest wystarczajÄ…ce i bardziej opÅ‚acalne. Kluczowe jest zrozumienie wymagaÅ„ biznesowych przed wyborem odpowiedniego rozwiÄ…zania."
  },
  {
    "objectID": "wyklad1.html#dlaczego-real-time-analytics-jest-waÅ¼ne",
    "href": "wyklad1.html#dlaczego-real-time-analytics-jest-waÅ¼ne",
    "title": "WykÅ‚ad 1",
    "section": "Dlaczego Real-Time Analytics jest waÅ¼ne?",
    "text": "Dlaczego Real-Time Analytics jest waÅ¼ne?\nReal-time analytics (analiza danych w czasie rzeczywistym) staje siÄ™ coraz bardziej istotna w wielu branÅ¼ach, poniewaÅ¼ umoÅ¼liwia organizacjom podejmowanie natychmiastowych decyzji na podstawie aktualnych danych. Oto kilka kluczowych powodÃ³w, dla ktÃ³rych real-time analytics jest waÅ¼ne:\n\nSzybkie podejmowanie decyzji\nReal-time analytics pozwala firmom reagowaÄ‡ na zmiany i wydarzenia w czasie rzeczywistym. DziÄ™ki temu moÅ¼na podejmowaÄ‡ decyzje szybciej, co jest kluczowe w dynamicznych Å›rodowiskach, takich jak:\n\nMarketing: Reklamy mogÄ… byÄ‡ dostosowane do zachowaÅ„ uÅ¼ytkownikÃ³w w czasie rzeczywistym (np. personalizacja treÅ›ci reklamowych).\nFinanse: Wykrywanie oszustw w czasie rzeczywistym, gdzie kaÅ¼da minuta moÅ¼e oznaczaÄ‡ rÃ³Å¼nicÄ™ w prewencji strat finansowych.\n\n\n\nMonitorowanie w czasie rzeczywistym\nFirmy mogÄ… monitorowaÄ‡ kluczowe wskaÅºniki operacyjne na bieÅ¼Ä…co. PrzykÅ‚ady:\n\nIoT (Internet of Things): Monitorowanie stanu maszyn i urzÄ…dzeÅ„ w fabrykach, aby natychmiast wykrywaÄ‡ awarie i zapobiegaÄ‡ przestojom.\nHealthtech: Åšledzenie parametrÃ³w Å¼yciowych pacjentÃ³w i wykrywanie anomalii, co moÅ¼e ratowaÄ‡ Å¼ycie.\n\n\n\nZwiÄ™kszenie efektywnoÅ›ci operacyjnej\nReal-time analytics umoÅ¼liwia natychmiastowe wykrywanie i eliminowanie problemÃ³w operacyjnych, zanim stanÄ… siÄ™ powaÅ¼niejsze. PrzykÅ‚ady:\n\nLogistyka: Åšledzenie przesyÅ‚ek i monitorowanie statusu transportu w czasie rzeczywistym, co poprawia efektywnoÅ›Ä‡ i zmniejsza opÃ³Åºnienia.\nRetail: Monitorowanie poziomu zapasÃ³w na bieÅ¼Ä…co i dostosowywanie zamÃ³wieÅ„ do aktualnych potrzeb.\n\n\n\nKonkurencyjnoÅ›Ä‡\nOrganizacje, ktÃ³re wykorzystujÄ… analitykÄ™ w czasie rzeczywistym, majÄ… przewagÄ™ nad konkurencjÄ…, poniewaÅ¼ mogÄ… szybciej reagowaÄ‡ na zmiany na rynku, nowe potrzeby klientÃ³w i sytuacje kryzysowe. DziÄ™ki natychmiastowym informacjom:\n\nMoÅ¼na podejmowaÄ‡ decyzje z wyprzedzeniem przed konkurentami.\nUtrzymywaÄ‡ lepsze relacje z klientami, reagujÄ…c na ich potrzeby w czasie rzeczywistym (np. dostosowywanie oferty).\n\n\n\nLepsze doÅ›wiadczenia uÅ¼ytkownikÃ³w (Customer Experience)\nAnaliza danych w czasie rzeczywistym pozwala na dostosowywanie interakcji z uÅ¼ytkownikami w trakcie ich trwania. PrzykÅ‚ady:\n\nE-commerce: Analiza koszyka zakupowego uÅ¼ytkownika w czasie rzeczywistym, aby np. zaoferowaÄ‡ rabat lub przypomnieÄ‡ o porzuconych produktach.\nStreaming: Optymalizacja jakoÅ›ci usÅ‚ugi wideo/streamingowej w zaleÅ¼noÅ›ci od dostÄ™pnej przepustowoÅ›ci Å‚Ä…cza.\n\n\n\nWykrywanie i reagowanie na anomalie\nW dzisiejszym Å›wiecie peÅ‚nym danych, wykrywanie anomalii w czasie rzeczywistym jest kluczowe dla bezpieczeÅ„stwa. PrzykÅ‚ady:\n\nCyberbezpieczeÅ„stwo: Real-time analytics umoÅ¼liwia wykrywanie podejrzanych dziaÅ‚aÅ„ w sieci i zapobieganie atakom w czasie rzeczywistym (np. ataki DDoS, nieautoryzowane logowanie).\nWykrywanie oszustw: Natychmiastowa identyfikacja podejrzanych transakcji w systemach bankowych i kartach kredytowych.\n\n\n\nOptymalizacja kosztÃ³w\nDziÄ™ki analizie w czasie rzeczywistym moÅ¼na optymalizowaÄ‡ zasoby i zmniejszaÄ‡ koszty. Na przykÅ‚ad:\n\nZarzÄ…dzanie energiÄ…: Analiza zuÅ¼ycia energii w czasie rzeczywistym, umoÅ¼liwiajÄ…ca optymalizacjÄ™ wydatkÃ³w na energiÄ™ w firmach.\nOptymalizacja Å‚aÅ„cucha dostaw: DziÄ™ki bieÅ¼Ä…cemu Å›ledzeniu zapasÃ³w i dostaw moÅ¼na lepiej zarzÄ…dzaÄ‡ kosztami magazynowania i transportu.\n\n\n\nZdolnoÅ›Ä‡ do przewidywania i zapobiegania\nAnaliza w czasie rzeczywistym wspiera procesy predykcyjne, ktÃ³re mogÄ… przewidywaÄ‡ przyszÅ‚e zachowania lub problemy, a takÅ¼e je eliminowaÄ‡ zanim siÄ™ pojawiÄ…. Na przykÅ‚ad:\n\nUtrzymanie predykcyjne w produkcji: Wykorzystanie analizy w czasie rzeczywistym w poÅ‚Ä…czeniu z modelami predykcyjnymi pozwala przewidywaÄ‡ awarie maszyn.\nPrognozy popytu: W czasie rzeczywistym moÅ¼na dostosowywaÄ‡ produkcjÄ™ lub zapasy na podstawie bieÅ¼Ä…cych trendÃ³w.\n\nReal-time analytics to nie tylko analiza danych â€“ to kluczowy element strategii firm w Å›wiecie, ktÃ³ry wymaga szybkich reakcji, elastycznoÅ›ci i dostosowywania siÄ™ do zmieniajÄ…cego siÄ™ otoczenia. Firmy, ktÃ³re wdraÅ¼ajÄ… te technologie, mogÄ… znaczÄ…co poprawiÄ‡ swoje wyniki finansowe, obsÅ‚ugÄ™ klienta, wydajnoÅ›Ä‡ operacyjnÄ…, a takÅ¼e przewagÄ™ konkurencyjnÄ…."
  },
  {
    "objectID": "wyklad1.html#wyzwania-i-problemy-analizy-danych-w-czasie-rzeczywistym",
    "href": "wyklad1.html#wyzwania-i-problemy-analizy-danych-w-czasie-rzeczywistym",
    "title": "WykÅ‚ad 1",
    "section": "Wyzwania i problemy analizy danych w czasie rzeczywistym",
    "text": "Wyzwania i problemy analizy danych w czasie rzeczywistym\nAnaliza danych w czasie rzeczywistym wiÄ…Å¼e siÄ™ z wieloma wyzwaniami i trudnoÅ›ciami, ktÃ³re trzeba rozwiÄ…zaÄ‡, aby systemy real-time dziaÅ‚aÅ‚y efektywnie i niezawodnie. Pomimo ogromnego potencjaÅ‚u, jaki daje moÅ¼liwoÅ›Ä‡ natychmiastowego przetwarzania danych, realizacja tych procesÃ³w w praktyce wiÄ…Å¼e siÄ™ z licznymi problemami technologicznymi, organizacyjnymi i dotyczÄ…cymi zarzÄ…dzania danymi.\nPoniÅ¼ej przedstawiamy najwaÅ¼niejsze wyzwania oraz moÅ¼liwe rozwiÄ…zania, ktÃ³re naleÅ¼y uwzglÄ™dniÄ‡ podczas implementacji systemÃ³w analizy danych w czasie rzeczywistym.\n\nSkalowalnoÅ›Ä‡ systemÃ³w\n\nWyzwanie:\nSkalowanie systemu analitycznego w czasie rzeczywistym jest jednym z najtrudniejszych zadaÅ„. W miarÄ™ jak iloÅ›Ä‡ generowanych danych roÅ›nie, systemy muszÄ… byÄ‡ w stanie obsÅ‚ugiwaÄ‡ wiÄ™ksze obciÄ…Å¼enie bez opÃ³Åºnienia w przetwarzaniu.\nZwiÄ™kszona iloÅ›Ä‡ danych: W systemach real-time, jak np. monitorowanie danych IoT czy transakcje w systemach finansowych, iloÅ›Ä‡ generowanych danych moÅ¼e byÄ‡ olbrzymia. Potrzebna jest elastycznoÅ›Ä‡: System musi automatycznie dostosowywaÄ‡ zasoby w zaleÅ¼noÅ›ci od obciÄ…Å¼enia.\n\n\nRozwiÄ…zanie:\nWykorzystanie skalowalnych systemÃ³w chmurowych, ktÃ³re pozwalajÄ… na dynamiczne zwiÄ™kszanie zasobÃ³w obliczeniowych (np. AWS, Azure, Google Cloud). Kubernetes do zarzÄ…dzania kontenerami i automatycznego skalowania mikroserwisÃ³w. Technologie strumieniowe (Apache Kafka, Apache Flink) umoÅ¼liwiajÄ…ce przetwarzanie danych w sposÃ³b wydajny i rozproszony.\n\n\n\nOpÃ³Åºnienia (Latency)\n\nWyzwanie:\nW systemach analizy danych w czasie rzeczywistym, kaÅ¼de opÃ³Åºnienie w przetwarzaniu danych moÅ¼e mieÄ‡ powaÅ¼ne konsekwencje. Dotyczy to zwÅ‚aszcza obszarÃ³w takich jak:\nWykrywanie oszustw: W przypadku systemÃ³w pÅ‚atnoÅ›ci online, opÃ³Åºnienie w analizie transakcji moÅ¼e oznaczaÄ‡ przegapienie nieautoryzowanej transakcji. Monitorowanie zdrowia pacjentÃ³w: OpÃ³Åºnienia mogÄ… wpÅ‚ynÄ…Ä‡ na skutecznoÅ›Ä‡ reakcji w sytuacjach kryzysowych.\n\n\nRozwiÄ…zanie:\nUÅ¼ywanie algorytmÃ³w optymalizujÄ…cych czas przetwarzania, np. stream processing z wykorzystaniem systemÃ³w takich jak Apache Kafka lub Apache Flink. Edge computing: Przesuwanie przetwarzania danych bliÅ¼ej ÅºrÃ³dÅ‚a (np. urzÄ…dzenia IoT), aby zmniejszyÄ‡ opÃ³Åºnienia w transmisji danych do chmury.\n\n\n\nJakoÅ›Ä‡ danych i zarzÄ…dzanie danymi\n\nWyzwanie:\nW systemach real-time musimy nie tylko analizowaÄ‡ dane w czasie rzeczywistym, ale takÅ¼e zapewniÄ‡ ich wysokÄ… jakoÅ›Ä‡. W przeciwnym razie analizy mogÄ… prowadziÄ‡ do bÅ‚Ä™dnych wnioskÃ³w lub opÃ³ÅºnieÅ„ w reagowaniu na nieprawidÅ‚owe dane.\nZanieczyszczone dane: W systemach real-time dane czÄ™sto sÄ… niepeÅ‚ne, brudne, bÅ‚Ä™dne lub nieuporzÄ…dkowane. Zmiana charakterystyki danych: Dane mogÄ… zmieniaÄ‡ siÄ™ w czasie, co moÅ¼e utrudniaÄ‡ ich przetwarzanie i analizÄ™. #### RozwiÄ…zanie:\nData cleansing i data validation na wstÄ™pnym etapie procesu. Automatyczne systemy monitorowania jakoÅ›ci danych w celu wykrywania bÅ‚Ä™dÃ³w w czasie rzeczywistym. ZarzÄ…dzanie danymi w strumieniu: NarzÄ™dzia takie jak Apache Kafka pozwalajÄ… na filtrowanie i oczyszczanie danych w locie.\n\n\n\nZÅ‚oÅ¼onoÅ›Ä‡ integracji systemÃ³w\n\nWyzwanie:\nSystemy analizy danych w czasie rzeczywistym czÄ™sto muszÄ… wspÃ³Å‚pracowaÄ‡ z istniejÄ…cymi systemami IT i ÅºrÃ³dÅ‚ami danych (np. bazami danych, czujnikami IoT, aplikacjami). Integracja tych systemÃ³w, zwÅ‚aszcza w rozproszonej architekturze, moÅ¼e byÄ‡ skomplikowana.\n\n\nRozwiÄ…zanie:\nUÅ¼ywanie API do Å‚atwiejszej integracji z zewnÄ™trznymi systemami. Mikroserwisy i konteneryzacja z pomocÄ… narzÄ™dzi takich jak Docker i Kubernetes. Przetwarzanie w chmurze, ktÃ³re umoÅ¼liwia Å‚atwÄ… integracjÄ™ rÃ³Å¼nych ÅºrÃ³deÅ‚ danych oraz zapewnia elastycznoÅ›Ä‡ w dostosowywaniu systemÃ³w do rosnÄ…cych potrzeb.\n\n\n\nBezpieczeÅ„stwo i prywatnoÅ›Ä‡\n\nWyzwanie:\nPrzetwarzanie danych w czasie rzeczywistym wiÄ…Å¼e siÄ™ z ogromnÄ… iloÅ›ciÄ… wraÅ¼liwych informacji, szczegÃ³lnie w branÅ¼ach takich jak finanse, zdrowie czy e-commerce. Zapewnienie, Å¼e dane sÄ… odpowiednio chronione przed nieautoryzowanym dostÄ™pem, jest kluczowe.\nOchrona danych w czasie transmisji: MuszÄ… byÄ‡ szyfrowane zarÃ³wno podczas przesyÅ‚ania, jak i przechowywania. Zabezpieczenia przed atakami: Przetwarzanie danych w czasie rzeczywistym moÅ¼e byÄ‡ celem atakÃ³w, takich jak DDoS czy SQL injection.\n\n\nRozwiÄ…zanie:\nSzyfrowanie danych zarÃ³wno w spoczynku, jak i podczas przesyÅ‚ania (np. TLS). Autentykacja i autoryzacja z wykorzystaniem nowoczesnych technologii bezpieczeÅ„stwa. ZgodnoÅ›Ä‡ z regulacjami prawnymi, np. RODO w Unii Europejskiej czy GDPR w przypadku danych osobowych.\n\n\n\nZarzÄ…dzanie bÅ‚Ä™dami i awariami\n\nWyzwanie:\nBÅ‚Ä™dy i awarie w systemach real-time mogÄ… prowadziÄ‡ do powaÅ¼nych konsekwencji, w tym utraty danych, opÃ³ÅºnieÅ„ w analizach czy nawet usuniÄ™cia usÅ‚ug. W systemach rozproszonych trudno jest osiÄ…gnÄ…Ä‡ peÅ‚nÄ… niezawodnoÅ›Ä‡.\n\n\nRozwiÄ…zanie:\nRedundancja: Tworzenie kopii zapasowych systemÃ³w i danych. Systemy monitorowania i alertowania (np. Prometheus, Grafana), ktÃ³re pozwalajÄ… na szybkie wykrycie i naprawienie problemÃ³w. ZarzÄ…dzanie stanem: DziÄ™ki uÅ¼yciu narzÄ™dzi jak Apache Kafka, moÅ¼na ponownie przetwarzaÄ‡ dane, jeÅ›li wystÄ…piÅ‚ bÅ‚Ä…d w transmisji.\n\n\n\nKoszty zwiÄ…zane z infrastrukturÄ…\n\nWyzwanie:\nPrzetwarzanie danych w czasie rzeczywistym wymaga odpowiedniej infrastruktury, ktÃ³ra zapewni odpowiedniÄ… moc obliczeniowÄ… i pamiÄ™Ä‡. To moÅ¼e wiÄ…zaÄ‡ siÄ™ z duÅ¼ymi kosztami, szczegÃ³lnie gdy dane muszÄ… byÄ‡ przechowywane i przetwarzane w czasie rzeczywistym na duÅ¼Ä… skalÄ™.\n\n\nRozwiÄ…zanie:\nChmura obliczeniowa: MoÅ¼liwoÅ›Ä‡ elastycznego skalowania zasobÃ³w w chmurze. Serverless computing: Technologie takie jak AWS Lambda pozwalajÄ… na uruchamianie procesÃ³w bez potrzeby utrzymywania staÅ‚ej infrastruktury.\nChociaÅ¼ analiza danych w czasie rzeczywistym oferuje ogromne korzyÅ›ci, wiÄ…Å¼e siÄ™ takÅ¼e z wieloma wyzwaniami. WÅ‚aÅ›ciwa architektura, narzÄ™dzia i technologie, takie jak Apache Kafka, Flink, Spark czy Kubernetes, mogÄ… pomÃ³c w przezwyciÄ™Å¼eniu wielu z tych trudnoÅ›ci. Warto rÃ³wnieÅ¼ pamiÄ™taÄ‡ o koniecznoÅ›ci zapewnienia wysokiej jakoÅ›ci danych, ich bezpieczeÅ„stwa, a takÅ¼e elastycznoÅ›ci i skalowalnoÅ›ci systemÃ³w, ktÃ³re bÄ™dÄ… w stanie sprostaÄ‡ rosnÄ…cym wymaganiom."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-D\nSemestr: 2024/2025 Uczelnia: SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nPodstawowe informacje o kursie znajdziesz w sylabusie.\nPolecane materiaÅ‚y znajdziesz na liÅ›cie ksiÄ…Å¼ek.\nMateriaÅ‚y z wykÅ‚adu i laboratoriÃ³w nie sÄ… wspierane przez Google. ObecnoÅ›Ä‡ na wykÅ‚adach i Ä‡wiczeniach nie zmniejszy Twoich 5 dolarÃ³w."
  },
  {
    "objectID": "index.html#analiza-danych-w-czasie-rzeczywistym",
    "href": "index.html#analiza-danych-w-czasie-rzeczywistym",
    "title": "Informacje ogÃ³lne",
    "section": "",
    "text": "Kod: 222890-D\nSemestr: 2024/2025 Uczelnia: SGH SzkoÅ‚a GÅ‚Ã³wna Handlowa w Warszawie\nPodstawowe informacje o kursie znajdziesz w sylabusie.\nPolecane materiaÅ‚y znajdziesz na liÅ›cie ksiÄ…Å¼ek.\nMateriaÅ‚y z wykÅ‚adu i laboratoriÃ³w nie sÄ… wspierane przez Google. ObecnoÅ›Ä‡ na wykÅ‚adach i Ä‡wiczeniach nie zmniejszy Twoich 5 dolarÃ³w."
  },
  {
    "objectID": "index.html#kalendarz",
    "href": "index.html#kalendarz",
    "title": "Informacje ogÃ³lne",
    "section": "Kalendarz",
    "text": "Kalendarz\n\nWykÅ‚ad\nWykÅ‚ad jest realizowany w trybie stacjonarnym. Jest on NIEOBOWIÄ„ZKOWY i odbywa siÄ™ w Auli VI bud G\n\n\n18-02-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 1\n\n25-02-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 2\n04-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 3\n11-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 4\n18-03-2025 (wtorek) 13:30-15:10 - WykÅ‚ad 5\n\nWykÅ‚ad 5 koÅ„czy siÄ™ TESTEM: 20 pytaÅ„ - 30 minut. Test przeprowadzany jest za poÅ›rednictwem MS Teams.\n\n\nLaboratoria\n\nLab1\n24-03-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n25-03-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab2\n31-03-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n01-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab3\n07-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n08-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab4\n14-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n15-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab5\n28-04-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n29-04-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab6\n05-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n06-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab7\n12-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n13-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab8\n19-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n20-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab9\n26-05-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n27-05-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\nLab10\n02-06-2025 (poniedziaÅ‚ek) 08:00-15:10 - G-235 grupy 11, 12, 13, 14\n03-06-2025 (wtorek) 11:40-15:10 - W-60 grupy 15, 16\n\n\n\nZaliczenie i Egzamin\nWykÅ‚ady zakoÅ„czÄ… siÄ™ testem (podczas ostatnich zajÄ™Ä‡).\nAby zaliczyÄ‡ test, naleÅ¼y zdobyÄ‡ wiÄ™cej niÅ¼ 13 punktÃ³w â€“ jest to warunek konieczny do uczestnictwa w Ä‡wiczeniach.\nLaboratoria\nPodczas laboratoriÃ³w bÄ™dÄ… zadawane prace domowe, ktÃ³re naleÅ¼y przesyÅ‚aÄ‡ za poÅ›rednictwem MS Teams. KaÅ¼dy brak pracy domowej obniÅ¼a koÅ„cowÄ… ocenÄ™ o 0,5 stopnia.\n\nProjekt\nProjekty naleÅ¼y realizowaÄ‡ w grupach maksymalnie 5-osobowych.\nWymagania projektu\n\nProjekt powinien rozwiÄ…zywaÄ‡ realny problem biznesowy, ktÃ³ry moÅ¼na opracowaÄ‡ przy uÅ¼yciu danych przetwarzanych w trybie online. (Nie wyklucza to uÅ¼ycia przetwarzania wsadowego, np. do generowania modelu).\nDane powinny byÄ‡ przesyÅ‚ane do Apache Kafka, skÄ…d bÄ™dÄ… poddawane dalszemu przetwarzaniu i analizie.\nMoÅ¼na uÅ¼ywaÄ‡ dowolnego jÄ™zyka programowania w kaÅ¼dym komponencie projektu.\nMoÅ¼na wykorzystaÄ‡ narzÄ™dzia BI.\nÅ¹rÃ³dÅ‚em danych moÅ¼e byÄ‡ dowolne API, sztucznie generowane dane, IoT itp."
  },
  {
    "objectID": "index.html#technologie",
    "href": "index.html#technologie",
    "title": "Informacje ogÃ³lne",
    "section": "Technologie",
    "text": "Technologie\nUczestniczÄ…c w zajÄ™ciach musisz opanowaÄ‡ i przynajmniej w podstawowym zakresie posÅ‚ugiwaÄ‡ siÄ™ nastÄ™pujÄ…cymi technologiami informatycznymi:\n\nGIT\nPython, Jupyter notebook, Jupyter lab, Colab\nDocker\nApache Spark, Apache Kafka\nDatabricks Community edition Web page."
  },
  {
    "objectID": "plan_wyklady.html",
    "href": "plan_wyklady.html",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "ğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej? 2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce. 3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym. 4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w. 5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych. ğŸ›  Laboratoria (praktyka + implementacja w Pythonie)\nğŸ”¹ Lab 1: Struktury danych w Pythonie â€“ Pandas, SQL (PostgreSQL, SQLite). ğŸ”¹ Lab 2: Dane grafowe w analizie relacji â€“ NetworkX i algorytmy grafowe. ğŸ”¹ Lab 3: Analiza tekstÃ³w i NLP â€“ przetwarzanie danych tekstowych (spaCy, TF-IDF). ğŸ”¹ Lab 4: Strumieniowanie danych w Apache Kafka â€“ pierwsza aplikacja Python + Kafka. ğŸ”¹ Lab 5: Uczenie maszynowe na strumieniu â€“ klasyfikacja w czasie rzeczywistym (SGDClassifier). ğŸ”¹ Lab 6: Przygotowanie API w FastAPI â€“ serwowanie modelu ML. ğŸ”¹ Lab 7: Zastosowanie modelu ML w reguÅ‚ach decyzyjnych â€“ integracja API z logikÄ… biznesowÄ…. ğŸ”¹ Lab 8: Przetwarzanie obrazÃ³w w czasie rzeczywistym â€“ OpenCV + klasyfikacja wideo. ğŸ”¹ Lab 9: Wykrywanie oszustw w transakcjach finansowych â€“ online learning na Kafka. ğŸ”¹ Lab 10: Projekt koÅ„cowy â€“ budowa mikroserwisu do analizy danych w czasie rzeczywistym."
  },
  {
    "objectID": "plan_wyklady.html#plan-wykÅ‚adu",
    "href": "plan_wyklady.html#plan-wykÅ‚adu",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "",
    "text": "ğŸ§‘â€ğŸ« WykÅ‚ady (teoria + case study z biznesu)\n1ï¸âƒ£ Wprowadzenie: Ewolucja analizy danych Dane strukturyzowane (SQL, Pandas) vs.Â nieustrukturyzowane (teksty, obrazy, grafy). Przetwarzanie wsadowe (batch processing) vs.Â strumieniowe (stream processing). Case study: Jak firmy przechodzÄ… od tabel do analizy strumieniowej? 2ï¸âƒ£ Systemy przetwarzania danych w czasie rzeczywistym Modele danych: relacyjne (PostgreSQL), grafowe (NetworkX), strumieniowe (Kafka). Lambda i Kappa Architecture â€“ rÃ³Å¼nice i zastosowania. Case study: Rekomendacje produktowe w e-commerce. 3ï¸âƒ£ Modele ML/DL dla danych w czasie rzeczywistym Uczenie wsadowe (batch) vs.Â przyrostowe (online learning). Stochastic Gradient Descent (SGD) â€“ podstawa ML na strumieniach. Case study: Klasyfikacja oszustw w czasie rzeczywistym. 4ï¸âƒ£ Obiektowe programowanie w Pythonie w kontekÅ›cie ML Struktury klasowe dla modeli ML. Tworzenie pipelineâ€™Ã³w ML w Pythonie. Case study: Klasyfikacja wiadomoÅ›ci jako SPAM/NON-SPAM w strumieniu tekstÃ³w. 5ï¸âƒ£ Tworzenie API z reguÅ‚ami decyzyjnymi i ML Budowa API w FastAPI dla modelu ML. Integracja modelu klasyfikacji z systemem decyzyjnym. Case study: System wykrywania anomalii w logach serwerowych. ğŸ›  Laboratoria (praktyka + implementacja w Pythonie)\nğŸ”¹ Lab 1: Struktury danych w Pythonie â€“ Pandas, SQL (PostgreSQL, SQLite). ğŸ”¹ Lab 2: Dane grafowe w analizie relacji â€“ NetworkX i algorytmy grafowe. ğŸ”¹ Lab 3: Analiza tekstÃ³w i NLP â€“ przetwarzanie danych tekstowych (spaCy, TF-IDF). ğŸ”¹ Lab 4: Strumieniowanie danych w Apache Kafka â€“ pierwsza aplikacja Python + Kafka. ğŸ”¹ Lab 5: Uczenie maszynowe na strumieniu â€“ klasyfikacja w czasie rzeczywistym (SGDClassifier). ğŸ”¹ Lab 6: Przygotowanie API w FastAPI â€“ serwowanie modelu ML. ğŸ”¹ Lab 7: Zastosowanie modelu ML w reguÅ‚ach decyzyjnych â€“ integracja API z logikÄ… biznesowÄ…. ğŸ”¹ Lab 8: Przetwarzanie obrazÃ³w w czasie rzeczywistym â€“ OpenCV + klasyfikacja wideo. ğŸ”¹ Lab 9: Wykrywanie oszustw w transakcjach finansowych â€“ online learning na Kafka. ğŸ”¹ Lab 10: Projekt koÅ„cowy â€“ budowa mikroserwisu do analizy danych w czasie rzeczywistym."
  },
  {
    "objectID": "plan_wyklady.html#moje",
    "href": "plan_wyklady.html#moje",
    "title": "Analiza danych w czasie rzeczywistym",
    "section": "Moje",
    "text": "Moje\n\nwprowadzenie\nBatch processing\n\n\ntypy danych\nBig data\nETL\nMAP Reduce\nSparkowe przetwarzanie klastrowe\nBazy SQL - OLTP, OLAP\n\n\nAPI online\n\n\nwystawienie serwisu LLM\nbatching\n\n\nNear Real-Time i Real Time\n\n\nStrumienie danych, definicje, biznes,\nLambda/Kappa\nPub Sub, Kafka"
  }
]